{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"/home/rakesh47/NNfromScratch/PreparedData/X_train.csv\", header=None)\n",
    "y_train = pd.read_csv(\"/home/rakesh47/NNfromScratch/PreparedData/y_train.csv\", header=None)\n",
    "\n",
    "X_test = pd.read_csv(\"/home/rakesh47/NNfromScratch/PreparedData/X_test.csv\", header=None)\n",
    "y_test = pd.read_csv(\"/home/rakesh47/NNfromScratch/PreparedData/y_test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. User-defined hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((354, 13), (354, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_in is input dimension; H is hidden dimension; D_out is output dimension.\n",
    "\n",
    "batch_size, D_in, H, D_out = 16, 13, 100, 1\n",
    "learning_rate = 1e-6\n",
    "n_epochs = 1000\n",
    "\n",
    "dtype = torch.float\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Random weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Perform training : CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, batch_size, model, n_epochs):\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = data\n",
    "    w1, w2 = model\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for t in range(n_epochs):\n",
    "\n",
    "        epoch_start = time.time()\n",
    "        train_loss = 0.\n",
    "        val_loss = 0.  \n",
    "        for state in ['train', 'val']:        \n",
    "\n",
    "            batch_start_idx = 0\n",
    "            n_samples = len(X_train) if state=='train' else len(X_test)        \n",
    "            while batch_start_idx < n_samples:\n",
    "\n",
    "                # Get next batch of data \n",
    "                batch_end_idx = batch_start_idx + batch_size\n",
    "                if batch_end_idx > n_samples:  batch_end_idx = n_samples\n",
    "                if state == 'train':  x, y = torch.Tensor(X_train.iloc[batch_start_idx:batch_end_idx, :].values), torch.Tensor(y_train.iloc[batch_start_idx:batch_end_idx, :].values)\n",
    "                else:  x, y = torch.Tensor(X_test.iloc[batch_start_idx:batch_end_idx, :].values), torch.Tensor(y_test.iloc[batch_start_idx:batch_end_idx, :].values)\n",
    "\n",
    "                # Forward pass: Compute output and loss\n",
    "                h = x.mm(w1)\n",
    "                h_relu = h.clamp(min=0)\n",
    "                y_pred = h_relu.mm(w2)\n",
    "                loss = (y_pred - y).pow(2).sum().item()\n",
    "                if state == 'train':  train_loss += loss\n",
    "                else:  val_loss += loss\n",
    "\n",
    "                # Backward pass: Compute gradients\n",
    "                if state == 'train':\n",
    "                    grad_y_pred = 2.0 * (y_pred - y)\n",
    "                    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "                    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "                    grad_h = grad_h_relu.clone()\n",
    "                    grad_h[h < 0] = 0\n",
    "                    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "                # Update weights using gradient descent\n",
    "                    w1 -= learning_rate * grad_w1\n",
    "                    w2 -= learning_rate * grad_w2\n",
    "\n",
    "                batch_start_idx = batch_end_idx\n",
    "\n",
    "        # Print statistics\n",
    "        train_loss /= len(X_train)\n",
    "        train_losses.append(train_loss)\n",
    "        val_loss /= len(X_test)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        epoch_end = time.time()\n",
    "        epoch_time = epoch_end - epoch_start\n",
    "        print(\"Epoch \", (t+1), \"/\", n_epochs, \" : Train-loss = \", train_loss, \", Val-loss = \", val_loss, \", Time for epoch = \", epoch_time, \"s\")\n",
    "\n",
    "    # Plot loss-curves\n",
    "    plt.figure()\n",
    "    plt.plot(range(2, n_epochs+1), train_losses[1:], label='Train-loss')\n",
    "    plt.plot(range(2, n_epochs+1), val_losses[1:], label='Val-loss')\n",
    "    plt.title('Loss curves')\n",
    "    plt.xlabel('No. of epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.grid(linestyle='dotted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 / 1000  : Train-loss =  9628175673958.03 , Val-loss =  532.9839252672697 , Time for epoch =  0.024486303329467773 s\n",
      "Epoch  2 / 1000  : Train-loss =  556.5368514411193 , Val-loss =  527.9073197214227 , Time for epoch =  0.014908552169799805 s\n",
      "Epoch  3 / 1000  : Train-loss =  348.7886156847248 , Val-loss =  121.50880833675987 , Time for epoch =  0.013933420181274414 s\n",
      "Epoch  4 / 1000  : Train-loss =  149.60300622282728 , Val-loss =  108.80851223594264 , Time for epoch =  0.014962196350097656 s\n",
      "Epoch  5 / 1000  : Train-loss =  134.27879600740422 , Val-loss =  102.30001389352898 , Time for epoch =  0.013482093811035156 s\n",
      "Epoch  6 / 1000  : Train-loss =  125.75166501837262 , Val-loss =  97.93124590421978 , Time for epoch =  0.013166189193725586 s\n",
      "Epoch  7 / 1000  : Train-loss =  119.71328743972347 , Val-loss =  94.96819666812294 , Time for epoch =  0.012553930282592773 s\n",
      "Epoch  8 / 1000  : Train-loss =  115.23233161538334 , Val-loss =  92.78923877916839 , Time for epoch =  0.012652158737182617 s\n",
      "Epoch  9 / 1000  : Train-loss =  111.75967631366967 , Val-loss =  91.02019460577714 , Time for epoch =  0.012656211853027344 s\n",
      "Epoch  10 / 1000  : Train-loss =  108.96319937840694 , Val-loss =  90.44834016498767 , Time for epoch =  0.01324152946472168 s\n",
      "Epoch  11 / 1000  : Train-loss =  106.57010344596905 , Val-loss =  89.37433503803454 , Time for epoch =  0.013073921203613281 s\n",
      "Epoch  12 / 1000  : Train-loss =  104.17921258096641 , Val-loss =  88.21198955335115 , Time for epoch =  0.012960433959960938 s\n",
      "Epoch  13 / 1000  : Train-loss =  102.43641335007834 , Val-loss =  87.34432421232525 , Time for epoch =  0.01354074478149414 s\n",
      "Epoch  14 / 1000  : Train-loss =  100.88156757246976 , Val-loss =  86.6171875 , Time for epoch =  0.013298273086547852 s\n",
      "Epoch  15 / 1000  : Train-loss =  99.52978912181099 , Val-loss =  85.97714072779605 , Time for epoch =  0.013215303421020508 s\n",
      "Epoch  16 / 1000  : Train-loss =  98.33941452112575 , Val-loss =  85.42922170538651 , Time for epoch =  0.015355825424194336 s\n",
      "Epoch  17 / 1000  : Train-loss =  97.2755419197729 , Val-loss =  84.93643509714227 , Time for epoch =  0.01921534538269043 s\n",
      "Epoch  18 / 1000  : Train-loss =  96.32718498962747 , Val-loss =  84.50404116981908 , Time for epoch =  0.013855695724487305 s\n",
      "Epoch  19 / 1000  : Train-loss =  95.67167853231484 , Val-loss =  83.9709183542352 , Time for epoch =  0.014205694198608398 s\n",
      "Epoch  20 / 1000  : Train-loss =  94.86811776888572 , Val-loss =  83.50225428531044 , Time for epoch =  0.013207435607910156 s\n",
      "Epoch  21 / 1000  : Train-loss =  94.13635728049412 , Val-loss =  83.07806878340871 , Time for epoch =  0.01320505142211914 s\n",
      "Epoch  22 / 1000  : Train-loss =  93.46554298185359 , Val-loss =  82.6871193333676 , Time for epoch =  0.013126373291015625 s\n",
      "Epoch  23 / 1000  : Train-loss =  92.84747219624492 , Val-loss =  82.32253425999691 , Time for epoch =  0.013883352279663086 s\n",
      "Epoch  24 / 1000  : Train-loss =  92.2043716516872 , Val-loss =  81.88881362111945 , Time for epoch =  0.01346588134765625 s\n",
      "Epoch  25 / 1000  : Train-loss =  91.64468263098075 , Val-loss =  81.51897831967003 , Time for epoch =  0.013580799102783203 s\n",
      "Epoch  26 / 1000  : Train-loss =  91.13107049801928 , Val-loss =  81.1923061170076 , Time for epoch =  0.013519048690795898 s\n",
      "Epoch  27 / 1000  : Train-loss =  90.65047760871845 , Val-loss =  81.21356080707751 , Time for epoch =  0.01322627067565918 s\n",
      "Epoch  28 / 1000  : Train-loss =  90.20840074787031 , Val-loss =  80.86973973324424 , Time for epoch =  0.013330698013305664 s\n",
      "Epoch  29 / 1000  : Train-loss =  89.7808205125022 , Val-loss =  80.55290302477385 , Time for epoch =  0.014358043670654297 s\n",
      "Epoch  30 / 1000  : Train-loss =  89.38016695356639 , Val-loss =  80.22682230096115 , Time for epoch =  0.014123678207397461 s\n",
      "Epoch  31 / 1000  : Train-loss =  88.9763614632989 , Val-loss =  79.9152109246505 , Time for epoch =  0.016861915588378906 s\n",
      "Epoch  32 / 1000  : Train-loss =  88.59373668088752 , Val-loss =  79.60477246736225 , Time for epoch =  0.017647981643676758 s\n",
      "Epoch  33 / 1000  : Train-loss =  88.2296752067609 , Val-loss =  79.30889571340461 , Time for epoch =  0.013395309448242188 s\n",
      "Epoch  34 / 1000  : Train-loss =  87.88566636769785 , Val-loss =  79.01874823319285 , Time for epoch =  0.012861013412475586 s\n",
      "Epoch  35 / 1000  : Train-loss =  87.51042783058296 , Val-loss =  78.66827994898746 , Time for epoch =  0.012766838073730469 s\n",
      "Epoch  36 / 1000  : Train-loss =  87.16833151262358 , Val-loss =  78.33458589252673 , Time for epoch =  0.01297616958618164 s\n",
      "Epoch  37 / 1000  : Train-loss =  86.84539751817951 , Val-loss =  78.0191754792866 , Time for epoch =  0.012736082077026367 s\n",
      "Epoch  38 / 1000  : Train-loss =  86.53998854470119 , Val-loss =  77.72048347874691 , Time for epoch =  0.012868881225585938 s\n",
      "Epoch  39 / 1000  : Train-loss =  86.25012198410465 , Val-loss =  77.43685872931229 , Time for epoch =  0.01316976547241211 s\n",
      "Epoch  40 / 1000  : Train-loss =  85.97415454239496 , Val-loss =  77.16679302014802 , Time for epoch =  0.012811899185180664 s\n",
      "Epoch  41 / 1000  : Train-loss =  85.71069573009082 , Val-loss =  76.90898172478927 , Time for epoch =  0.012970447540283203 s\n",
      "Epoch  42 / 1000  : Train-loss =  85.4585829912606 , Val-loss =  76.66225915206105 , Time for epoch =  0.012981653213500977 s\n",
      "Epoch  43 / 1000  : Train-loss =  85.14242592504469 , Val-loss =  76.34720290334602 , Time for epoch =  0.013303279876708984 s\n",
      "Epoch  44 / 1000  : Train-loss =  84.89348572122175 , Val-loss =  76.07616183632298 , Time for epoch =  0.013093233108520508 s\n",
      "Epoch  45 / 1000  : Train-loss =  84.66246446512513 , Val-loss =  75.76800938656456 , Time for epoch =  0.01445150375366211 s\n",
      "Epoch  46 / 1000  : Train-loss =  84.40750630696614 , Val-loss =  75.48936221474095 , Time for epoch =  0.015753507614135742 s\n",
      "Epoch  47 / 1000  : Train-loss =  84.18805276472017 , Val-loss =  75.2849783646433 , Time for epoch =  0.013091802597045898 s\n",
      "Epoch  48 / 1000  : Train-loss =  83.95830540199064 , Val-loss =  75.0702237580952 , Time for epoch =  0.01305699348449707 s\n",
      "Epoch  49 / 1000  : Train-loss =  83.73678347485213 , Val-loss =  74.86098921926398 , Time for epoch =  0.013073205947875977 s\n",
      "Epoch  50 / 1000  : Train-loss =  83.52375116725426 , Val-loss =  74.65776222630551 , Time for epoch =  0.013045072555541992 s\n",
      "Epoch  51 / 1000  : Train-loss =  83.31842588435458 , Val-loss =  74.46124548661082 , Time for epoch =  0.013136625289916992 s\n",
      "Epoch  52 / 1000  : Train-loss =  83.120109256378 , Val-loss =  74.27107078150699 , Time for epoch =  0.013045310974121094 s\n",
      "Epoch  53 / 1000  : Train-loss =  82.92820843195511 , Val-loss =  74.08689037122224 , Time for epoch =  0.01312112808227539 s\n",
      "Epoch  54 / 1000  : Train-loss =  82.74216866358525 , Val-loss =  73.90828022203948 , Time for epoch =  0.013028860092163086 s\n",
      "Epoch  55 / 1000  : Train-loss =  82.56150917010119 , Val-loss =  73.73489339728104 , Time for epoch =  0.013287067413330078 s\n",
      "Epoch  56 / 1000  : Train-loss =  82.38605908754855 , Val-loss =  73.56648535477488 , Time for epoch =  0.013633251190185547 s\n",
      "Epoch  57 / 1000  : Train-loss =  82.21534315206237 , Val-loss =  73.40267864026521 , Time for epoch =  0.013005733489990234 s\n",
      "Epoch  58 / 1000  : Train-loss =  82.04899187680692 , Val-loss =  73.24315964548211 , Time for epoch =  0.01317286491394043 s\n",
      "Epoch  59 / 1000  : Train-loss =  81.88670556019929 , Val-loss =  73.08765973542866 , Time for epoch =  0.01412510871887207 s\n",
      "Epoch  60 / 1000  : Train-loss =  81.71391589493402 , Val-loss =  72.91923804032176 , Time for epoch =  0.016102313995361328 s\n",
      "Epoch  61 / 1000  : Train-loss =  81.51589569264213 , Val-loss =  72.75276304546155 , Time for epoch =  0.017469167709350586 s\n",
      "Epoch  62 / 1000  : Train-loss =  81.32508681992353 , Val-loss =  72.5904685572574 , Time for epoch =  0.013554096221923828 s\n",
      "Epoch  63 / 1000  : Train-loss =  81.14099172818459 , Val-loss =  72.4324722290039 , Time for epoch =  0.013242959976196289 s\n",
      "Epoch  64 / 1000  : Train-loss =  80.96211346125199 , Val-loss =  72.30062304045025 , Time for epoch =  0.013131141662597656 s\n",
      "Epoch  65 / 1000  : Train-loss =  80.67565090373411 , Val-loss =  72.18222286826686 , Time for epoch =  0.013407468795776367 s\n",
      "Epoch  66 / 1000  : Train-loss =  80.50525941148317 , Val-loss =  72.04683323910362 , Time for epoch =  0.014024734497070312 s\n",
      "Epoch  67 / 1000  : Train-loss =  80.34264369468904 , Val-loss =  71.8659688046104 , Time for epoch =  0.013406515121459961 s\n",
      "Epoch  68 / 1000  : Train-loss =  80.1842491882669 , Val-loss =  71.674274043033 , Time for epoch =  0.013542890548706055 s\n",
      "Epoch  69 / 1000  : Train-loss =  80.02965834450588 , Val-loss =  71.4884187798751 , Time for epoch =  0.013383150100708008 s\n",
      "Epoch  70 / 1000  : Train-loss =  79.8786307297184 , Val-loss =  71.30806551481548 , Time for epoch =  0.013573169708251953 s\n",
      "Epoch  71 / 1000  : Train-loss =  79.7309220308638 , Val-loss =  71.1329231262207 , Time for epoch =  0.012944698333740234 s\n",
      "Epoch  72 / 1000  : Train-loss =  79.58634215963762 , Val-loss =  70.96261596679688 , Time for epoch =  0.013045072555541992 s\n",
      "Epoch  73 / 1000  : Train-loss =  79.44470766573976 , Val-loss =  70.79689567967465 , Time for epoch =  0.013000965118408203 s\n",
      "Epoch  74 / 1000  : Train-loss =  79.30584458173331 , Val-loss =  70.63549463372482 , Time for epoch =  0.012820005416870117 s\n",
      "Epoch  75 / 1000  : Train-loss =  79.16961264744991 , Val-loss =  70.47814580013878 , Time for epoch =  0.014782428741455078 s\n",
      "Epoch  76 / 1000  : Train-loss =  79.03702937411722 , Val-loss =  70.3255211679559 , Time for epoch =  0.018251895904541016 s\n",
      "Epoch  77 / 1000  : Train-loss =  78.90678987664691 , Val-loss =  70.1765769155402 , Time for epoch =  0.01746058464050293 s\n",
      "Epoch  78 / 1000  : Train-loss =  78.77886023225084 , Val-loss =  70.03106147364566 , Time for epoch =  0.013254880905151367 s\n",
      "Epoch  79 / 1000  : Train-loss =  78.65314065534517 , Val-loss =  69.8888218528346 , Time for epoch =  0.012891292572021484 s\n",
      "Epoch  80 / 1000  : Train-loss =  78.52952092919647 , Val-loss =  69.7496317813271 , Time for epoch =  0.013176202774047852 s\n",
      "Epoch  81 / 1000  : Train-loss =  78.4079066993153 , Val-loss =  69.61338243986431 , Time for epoch =  0.012792825698852539 s\n",
      "Epoch  82 / 1000  : Train-loss =  78.28821236130881 , Val-loss =  69.47990879259612 , Time for epoch =  0.012802362442016602 s\n",
      "Epoch  83 / 1000  : Train-loss =  78.17034735383287 , Val-loss =  69.34908656070107 , Time for epoch =  0.012743949890136719 s\n",
      "Epoch  84 / 1000  : Train-loss =  78.05425745215119 , Val-loss =  69.22081214503238 , Time for epoch =  0.012921333312988281 s\n",
      "Epoch  85 / 1000  : Train-loss =  77.93984752590373 , Val-loss =  69.09496548301296 , Time for epoch =  0.012702226638793945 s\n",
      "Epoch  86 / 1000  : Train-loss =  77.827060074456 , Val-loss =  68.96952759592156 , Time for epoch =  0.012701272964477539 s\n",
      "Epoch  87 / 1000  : Train-loss =  77.7158289763887 , Val-loss =  68.84360986006887 , Time for epoch =  0.013202428817749023 s\n",
      "Epoch  88 / 1000  : Train-loss =  77.60610880016607 , Val-loss =  68.71988015425832 , Time for epoch =  0.012652158737182617 s\n",
      "Epoch  89 / 1000  : Train-loss =  77.49782014836026 , Val-loss =  68.59830776013825 , Time for epoch =  0.013104677200317383 s\n",
      "Epoch  90 / 1000  : Train-loss =  77.3909185377218 , Val-loss =  68.47879710950349 , Time for epoch =  0.016643524169921875 s\n",
      "Epoch  91 / 1000  : Train-loss =  77.28535267458123 , Val-loss =  68.36124982331928 , Time for epoch =  0.01547098159790039 s\n",
      "Epoch  92 / 1000  : Train-loss =  77.18108484300517 , Val-loss =  68.24560787803249 , Time for epoch =  0.013187646865844727 s\n",
      "Epoch  93 / 1000  : Train-loss =  77.07804918019785 , Val-loss =  68.1317656667609 , Time for epoch =  0.013011455535888672 s\n",
      "Epoch  94 / 1000  : Train-loss =  76.97621831516761 , Val-loss =  68.0196916680587 , Time for epoch =  0.014301300048828125 s\n",
      "Epoch  95 / 1000  : Train-loss =  76.87554035079008 , Val-loss =  67.90929151836194 , Time for epoch =  0.013683557510375977 s\n",
      "Epoch  96 / 1000  : Train-loss =  76.77598155824478 , Val-loss =  67.80051402041786 , Time for epoch =  0.013345956802368164 s\n",
      "Epoch  97 / 1000  : Train-loss =  76.67749359648107 , Val-loss =  67.68891364649723 , Time for epoch =  0.013323545455932617 s\n",
      "Epoch  98 / 1000  : Train-loss =  76.58004702551891 , Val-loss =  67.57327953137849 , Time for epoch =  0.01323699951171875 s\n",
      "Epoch  99 / 1000  : Train-loss =  76.483606327725 , Val-loss =  67.45929537321392 , Time for epoch =  0.013398885726928711 s\n",
      "Epoch  100 / 1000  : Train-loss =  76.3881392398123 , Val-loss =  67.34691178171258 , Time for epoch =  0.013870000839233398 s\n",
      "Epoch  101 / 1000  : Train-loss =  76.29361349849377 , Val-loss =  67.23606772171824 , Time for epoch =  0.012705564498901367 s\n",
      "Epoch  102 / 1000  : Train-loss =  76.19998587053374 , Val-loss =  67.12670878360146 , Time for epoch =  0.013581991195678711 s\n",
      "Epoch  103 / 1000  : Train-loss =  76.10724739031603 , Val-loss =  67.01876369275544 , Time for epoch =  0.012736082077026367 s\n",
      "Epoch  104 / 1000  : Train-loss =  76.01535019093315 , Val-loss =  66.91219349911339 , Time for epoch =  0.012623786926269531 s\n",
      "Epoch  105 / 1000  : Train-loss =  75.91676173237084 , Val-loss =  66.78393414146022 , Time for epoch =  0.014828920364379883 s\n",
      "Epoch  106 / 1000  : Train-loss =  75.83124098265912 , Val-loss =  66.61680422331158 , Time for epoch =  0.017070770263671875 s\n",
      "Epoch  107 / 1000  : Train-loss =  75.72748231618418 , Val-loss =  66.47396027414422 , Time for epoch =  0.01736617088317871 s\n",
      "Epoch  108 / 1000  : Train-loss =  75.62818494893737 , Val-loss =  66.34530157791941 , Time for epoch =  0.013426542282104492 s\n",
      "Epoch  109 / 1000  : Train-loss =  75.53141248024116 , Val-loss =  66.22513761018452 , Time for epoch =  0.012816190719604492 s\n",
      "Epoch  110 / 1000  : Train-loss =  75.43634214239606 , Val-loss =  66.11033449674908 , Time for epoch =  0.013268470764160156 s\n",
      "Epoch  111 / 1000  : Train-loss =  75.34259037513517 , Val-loss =  65.99916919909026 , Time for epoch =  0.012888431549072266 s\n",
      "Epoch  112 / 1000  : Train-loss =  75.24993633550439 , Val-loss =  65.89068061427066 , Time for epoch =  0.01307535171508789 s\n",
      "Epoch  113 / 1000  : Train-loss =  75.1582539876302 , Val-loss =  65.78428308587326 , Time for epoch =  0.012641429901123047 s\n",
      "Epoch  114 / 1000  : Train-loss =  75.06746350304554 , Val-loss =  65.67966862728721 , Time for epoch =  0.012621164321899414 s\n",
      "Epoch  115 / 1000  : Train-loss =  74.97657420271534 , Val-loss =  65.57647403917815 , Time for epoch =  0.01316523551940918 s\n",
      "Epoch  116 / 1000  : Train-loss =  74.8880479888054 , Val-loss =  65.47505890695672 , Time for epoch =  0.013164758682250977 s\n",
      "Epoch  117 / 1000  : Train-loss =  74.80175035552116 , Val-loss =  65.37524534526624 , Time for epoch =  0.01303720474243164 s\n",
      "Epoch  118 / 1000  : Train-loss =  74.71337603983906 , Val-loss =  65.27668742129677 , Time for epoch =  0.012577056884765625 s\n",
      "Epoch  119 / 1000  : Train-loss =  74.6273068142476 , Val-loss =  65.17958229466488 , Time for epoch =  0.012672901153564453 s\n",
      "Epoch  120 / 1000  : Train-loss =  74.54200188588288 , Val-loss =  65.08390225862202 , Time for epoch =  0.016726255416870117 s\n",
      "Epoch  121 / 1000  : Train-loss =  74.45742948715296 , Val-loss =  64.98953307302375 , Time for epoch =  0.01505589485168457 s\n",
      "Epoch  122 / 1000  : Train-loss =  74.37356739798508 , Val-loss =  64.89643357929431 , Time for epoch =  0.017011165618896484 s\n",
      "Epoch  123 / 1000  : Train-loss =  74.29038225594213 , Val-loss =  64.80455559178402 , Time for epoch =  0.013858795166015625 s\n",
      "Epoch  124 / 1000  : Train-loss =  74.20784287533517 , Val-loss =  64.7138288397538 , Time for epoch =  0.012635946273803711 s\n",
      "Epoch  125 / 1000  : Train-loss =  74.12592912663175 , Val-loss =  64.62419710661236 , Time for epoch =  0.012637853622436523 s\n",
      "Epoch  126 / 1000  : Train-loss =  74.04461275520971 , Val-loss =  64.53561582063374 , Time for epoch =  0.013370513916015625 s\n",
      "Epoch  127 / 1000  : Train-loss =  73.9638746660308 , Val-loss =  64.44802836367958 , Time for epoch =  0.012711286544799805 s\n",
      "Epoch  128 / 1000  : Train-loss =  73.8836987166755 , Val-loss =  64.36141967773438 , Time for epoch =  0.012985944747924805 s\n",
      "Epoch  129 / 1000  : Train-loss =  73.80404570412502 , Val-loss =  64.27572912918895 , Time for epoch =  0.012841463088989258 s\n",
      "Epoch  130 / 1000  : Train-loss =  73.72491465854105 , Val-loss =  64.19091335095857 , Time for epoch =  0.016742944717407227 s\n",
      "Epoch  131 / 1000  : Train-loss =  73.64628678661282 , Val-loss =  64.1069564819336 , Time for epoch =  0.013254642486572266 s\n",
      "Epoch  132 / 1000  : Train-loss =  73.5681389630851 , Val-loss =  64.02381234419973 , Time for epoch =  0.014292001724243164 s\n",
      "Epoch  133 / 1000  : Train-loss =  73.49045123084117 , Val-loss =  63.94145664415861 , Time for epoch =  0.01363062858581543 s\n",
      "Epoch  134 / 1000  : Train-loss =  73.41321921483272 , Val-loss =  63.859847821687396 , Time for epoch =  0.01392507553100586 s\n",
      "Epoch  135 / 1000  : Train-loss =  73.33642681574418 , Val-loss =  63.778973027279505 , Time for epoch =  0.014399528503417969 s\n",
      "Epoch  136 / 1000  : Train-loss =  73.26005498164118 , Val-loss =  63.69880897120426 , Time for epoch =  0.0211331844329834 s\n",
      "Epoch  137 / 1000  : Train-loss =  73.1840911477299 , Val-loss =  63.619302448473476 , Time for epoch =  0.015031814575195312 s\n",
      "Epoch  138 / 1000  : Train-loss =  73.1085236759509 , Val-loss =  63.5404610884817 , Time for epoch =  0.013075590133666992 s\n",
      "Epoch  139 / 1000  : Train-loss =  73.03334661796268 , Val-loss =  63.46224714580335 , Time for epoch =  0.013190746307373047 s\n",
      "Epoch  140 / 1000  : Train-loss =  72.95854055544751 , Val-loss =  63.38464596396998 , Time for epoch =  0.013025522232055664 s\n",
      "Epoch  141 / 1000  : Train-loss =  72.88409979868743 , Val-loss =  63.30764569734272 , Time for epoch =  0.012733936309814453 s\n",
      "Epoch  142 / 1000  : Train-loss =  72.8100112440896 , Val-loss =  63.23122145000257 , Time for epoch =  0.012732744216918945 s\n",
      "Epoch  143 / 1000  : Train-loss =  72.73626969763114 , Val-loss =  63.15535033376593 , Time for epoch =  0.012863397598266602 s\n",
      "Epoch  144 / 1000  : Train-loss =  72.66286543937726 , Val-loss =  63.08002371537058 , Time for epoch =  0.012728691101074219 s\n",
      "Epoch  145 / 1000  : Train-loss =  72.5897818958692 , Val-loss =  63.00522392674496 , Time for epoch =  0.012986421585083008 s\n",
      "Epoch  146 / 1000  : Train-loss =  72.51702589907889 , Val-loss =  62.930949562474304 , Time for epoch =  0.012714624404907227 s\n",
      "Epoch  147 / 1000  : Train-loss =  72.44457671601893 , Val-loss =  62.85716608950966 , Time for epoch =  0.013501405715942383 s\n",
      "Epoch  148 / 1000  : Train-loss =  72.37242602763203 , Val-loss =  62.78388675890471 , Time for epoch =  0.01379847526550293 s\n",
      "Epoch  149 / 1000  : Train-loss =  72.30057698050462 , Val-loss =  62.71107623451635 , Time for epoch =  0.01661229133605957 s\n",
      "Epoch  150 / 1000  : Train-loss =  72.22901660035559 , Val-loss =  62.63874294883326 , Time for epoch =  0.016289949417114258 s\n",
      "Epoch  151 / 1000  : Train-loss =  72.15773980092195 , Val-loss =  62.56685999820107 , Time for epoch =  0.014636993408203125 s\n",
      "Epoch  152 / 1000  : Train-loss =  72.08674059075824 , Val-loss =  62.49544665687963 , Time for epoch =  0.013641119003295898 s\n",
      "Epoch  153 / 1000  : Train-loss =  72.01600840940314 , Val-loss =  62.42445795159591 , Time for epoch =  0.013496637344360352 s\n",
      "Epoch  154 / 1000  : Train-loss =  71.9455484293275 , Val-loss =  62.35391556589227 , Time for epoch =  0.013433456420898438 s\n",
      "Epoch  155 / 1000  : Train-loss =  71.87533379678672 , Val-loss =  62.2837875767758 , Time for epoch =  0.01371145248413086 s\n",
      "Epoch  156 / 1000  : Train-loss =  71.80538472752113 , Val-loss =  62.21409948248612 , Time for epoch =  0.013356208801269531 s\n",
      "Epoch  157 / 1000  : Train-loss =  71.73567885059421 , Val-loss =  62.144797676487975 , Time for epoch =  0.013230085372924805 s\n",
      "Epoch  158 / 1000  : Train-loss =  71.6662146789206 , Val-loss =  62.075922313489414 , Time for epoch =  0.013181686401367188 s\n",
      "Epoch  159 / 1000  : Train-loss =  71.5969887426344 , Val-loss =  62.00744468287418 , Time for epoch =  0.013239622116088867 s\n",
      "Epoch  160 / 1000  : Train-loss =  71.52800647283004 , Val-loss =  61.93936518618935 , Time for epoch =  0.013461112976074219 s\n",
      "Epoch  161 / 1000  : Train-loss =  71.45925271847827 , Val-loss =  61.87169004741468 , Time for epoch =  0.013276338577270508 s\n",
      "Epoch  162 / 1000  : Train-loss =  71.39072008725614 , Val-loss =  61.8043989884226 , Time for epoch =  0.013955354690551758 s\n",
      "Epoch  163 / 1000  : Train-loss =  71.3225196795275 , Val-loss =  61.737473136500306 , Time for epoch =  0.013702869415283203 s\n",
      "Epoch  164 / 1000  : Train-loss =  71.25448326067736 , Val-loss =  61.67083097759046 , Time for epoch =  0.016765594482421875 s\n",
      "Epoch  165 / 1000  : Train-loss =  71.18661115398515 , Val-loss =  61.604481747275905 , Time for epoch =  0.014000177383422852 s\n",
      "Epoch  166 / 1000  : Train-loss =  71.11889303606108 , Val-loss =  61.538385692395664 , Time for epoch =  0.013414859771728516 s\n",
      "Epoch  167 / 1000  : Train-loss =  71.0513247042726 , Val-loss =  61.47256449649208 , Time for epoch =  0.013227224349975586 s\n",
      "Epoch  168 / 1000  : Train-loss =  70.98390583534025 , Val-loss =  61.40700008994654 , Time for epoch =  0.013224601745605469 s\n",
      "Epoch  169 / 1000  : Train-loss =  70.91663160162457 , Val-loss =  61.34169387817383 , Time for epoch =  0.013165950775146484 s\n",
      "Epoch  170 / 1000  : Train-loss =  70.84949420131532 , Val-loss =  61.276636224044 , Time for epoch =  0.013755321502685547 s\n",
      "Epoch  171 / 1000  : Train-loss =  70.7824885481495 , Val-loss =  61.21181869506836 , Time for epoch =  0.012753725051879883 s\n",
      "Epoch  172 / 1000  : Train-loss =  70.71561621542031 , Val-loss =  61.14724349975586 , Time for epoch =  0.013437032699584961 s\n",
      "Epoch  173 / 1000  : Train-loss =  70.64886985390874 , Val-loss =  61.08290180407072 , Time for epoch =  0.013141870498657227 s\n",
      "Epoch  174 / 1000  : Train-loss =  70.58223989454366 , Val-loss =  61.0187998319927 , Time for epoch =  0.013221979141235352 s\n",
      "Epoch  175 / 1000  : Train-loss =  70.51573000115863 , Val-loss =  60.95492834793894 , Time for epoch =  0.012709617614746094 s\n",
      "Epoch  176 / 1000  : Train-loss =  70.44933687630346 , Val-loss =  60.89128454107987 , Time for epoch =  0.01292729377746582 s\n",
      "Epoch  177 / 1000  : Train-loss =  70.38305733028778 , Val-loss =  60.827864395944694 , Time for epoch =  0.01613640785217285 s\n",
      "Epoch  178 / 1000  : Train-loss =  70.31688379837294 , Val-loss =  60.76466168855366 , Time for epoch =  0.01408839225769043 s\n",
      "Epoch  179 / 1000  : Train-loss =  70.25081315552447 , Val-loss =  60.70169348465769 , Time for epoch =  0.01622462272644043 s\n",
      "Epoch  180 / 1000  : Train-loss =  70.1848480957376 , Val-loss =  60.63893709684673 , Time for epoch =  0.01349782943725586 s\n",
      "Epoch  181 / 1000  : Train-loss =  70.11897461023707 , Val-loss =  60.5764045715332 , Time for epoch =  0.01303243637084961 s\n",
      "Epoch  182 / 1000  : Train-loss =  70.05319724648686 , Val-loss =  60.51409048783152 , Time for epoch =  0.016246795654296875 s\n",
      "Epoch  183 / 1000  : Train-loss =  69.98752085367839 , Val-loss =  60.452009301436576 , Time for epoch =  0.013384580612182617 s\n",
      "Epoch  184 / 1000  : Train-loss =  69.92564120535123 , Val-loss =  60.35509229961195 , Time for epoch =  0.012848377227783203 s\n",
      "Epoch  185 / 1000  : Train-loss =  69.82391947945632 , Val-loss =  60.25314511750874 , Time for epoch =  0.013091564178466797 s\n",
      "Epoch  186 / 1000  : Train-loss =  69.70906204827088 , Val-loss =  60.12433624267578 , Time for epoch =  0.013510704040527344 s\n",
      "Epoch  187 / 1000  : Train-loss =  69.60498240842658 , Val-loss =  60.009909981175475 , Time for epoch =  0.013135194778442383 s\n",
      "Epoch  188 / 1000  : Train-loss =  69.50449222629354 , Val-loss =  59.90431835776881 , Time for epoch =  0.013097286224365234 s\n",
      "Epoch  189 / 1000  : Train-loss =  69.40542759868384 , Val-loss =  59.80396090055767 , Time for epoch =  0.013077259063720703 s\n",
      "Epoch  190 / 1000  : Train-loss =  69.30717591107901 , Val-loss =  59.70684071591026 , Time for epoch =  0.013119220733642578 s\n",
      "Epoch  191 / 1000  : Train-loss =  69.20951584638175 , Val-loss =  59.611821024041426 , Time for epoch =  0.013123750686645508 s\n",
      "Epoch  192 / 1000  : Train-loss =  69.1123554423704 , Val-loss =  59.52091417814556 , Time for epoch =  0.015625715255737305 s\n",
      "Epoch  193 / 1000  : Train-loss =  69.01562853452177 , Val-loss =  59.45198962562963 , Time for epoch =  0.016005754470825195 s\n",
      "Epoch  194 / 1000  : Train-loss =  68.82233763010488 , Val-loss =  59.279423563103926 , Time for epoch =  0.016355037689208984 s\n",
      "Epoch  195 / 1000  : Train-loss =  68.73586458540233 , Val-loss =  59.17848004792866 , Time for epoch =  0.013937950134277344 s\n",
      "Epoch  196 / 1000  : Train-loss =  68.64243473979712 , Val-loss =  59.09908776534231 , Time for epoch =  0.014091253280639648 s\n",
      "Epoch  197 / 1000  : Train-loss =  68.54635863654357 , Val-loss =  59.02934686761154 , Time for epoch =  0.013150691986083984 s\n",
      "Epoch  198 / 1000  : Train-loss =  68.44952097316246 , Val-loss =  58.96420167621813 , Time for epoch =  0.014999628067016602 s\n",
      "Epoch  199 / 1000  : Train-loss =  68.35257003266932 , Val-loss =  58.901528207879316 , Time for epoch =  0.014217853546142578 s\n",
      "Epoch  200 / 1000  : Train-loss =  68.27845684417898 , Val-loss =  58.82299021670693 , Time for epoch =  0.014638423919677734 s\n",
      "Epoch  201 / 1000  : Train-loss =  68.19416563389665 , Val-loss =  58.747905931974714 , Time for epoch =  0.01519012451171875 s\n",
      "Epoch  202 / 1000  : Train-loss =  68.11057546583272 , Val-loss =  58.675751535516035 , Time for epoch =  0.013628482818603516 s\n",
      "Epoch  203 / 1000  : Train-loss =  68.02757810603427 , Val-loss =  58.606169851202715 , Time for epoch =  0.013760805130004883 s\n",
      "Epoch  204 / 1000  : Train-loss =  67.94507698015978 , Val-loss =  58.53890027497944 , Time for epoch =  0.012693643569946289 s\n",
      "Epoch  205 / 1000  : Train-loss =  67.86298915625966 , Val-loss =  58.47369043450607 , Time for epoch =  0.013761281967163086 s\n",
      "Epoch  206 / 1000  : Train-loss =  67.78125400866492 , Val-loss =  58.410357425087376 , Time for epoch =  0.01427316665649414 s\n",
      "Epoch  207 / 1000  : Train-loss =  67.69983138607047 , Val-loss =  58.34874584800318 , Time for epoch =  0.016036033630371094 s\n",
      "Epoch  208 / 1000  : Train-loss =  67.61868010267699 , Val-loss =  58.288700706080384 , Time for epoch =  0.013549566268920898 s\n",
      "Epoch  209 / 1000  : Train-loss =  67.53776852020437 , Val-loss =  58.230127033434414 , Time for epoch =  0.017881155014038086 s\n",
      "Epoch  210 / 1000  : Train-loss =  67.45706456933318 , Val-loss =  58.1729073775442 , Time for epoch =  0.01500082015991211 s\n",
      "Epoch  211 / 1000  : Train-loss =  67.3765743923726 , Val-loss =  58.11695118954307 , Time for epoch =  0.01337289810180664 s\n",
      "Epoch  212 / 1000  : Train-loss =  67.29626273031289 , Val-loss =  58.062189403333164 , Time for epoch =  0.013326644897460938 s\n",
      "Epoch  213 / 1000  : Train-loss =  67.21613212628553 , Val-loss =  58.0085459257427 , Time for epoch =  0.013332843780517578 s\n",
      "Epoch  214 / 1000  : Train-loss =  67.13617199827722 , Val-loss =  57.95594426205284 , Time for epoch =  0.013523578643798828 s\n",
      "Epoch  215 / 1000  : Train-loss =  67.05637842383088 , Val-loss =  57.90435891402395 , Time for epoch =  0.013030529022216797 s\n",
      "Epoch  216 / 1000  : Train-loss =  66.97673967867921 , Val-loss =  57.853730051141035 , Time for epoch =  0.013494014739990234 s\n",
      "Epoch  217 / 1000  : Train-loss =  66.8972663663875 , Val-loss =  57.80402093184622 , Time for epoch =  0.01349020004272461 s\n",
      "Epoch  218 / 1000  : Train-loss =  66.81794986617093 , Val-loss =  57.75521127801193 , Time for epoch =  0.013791322708129883 s\n",
      "Epoch  219 / 1000  : Train-loss =  66.73878511331849 , Val-loss =  57.694030360171666 , Time for epoch =  0.013583183288574219 s\n",
      "Epoch  220 / 1000  : Train-loss =  66.6597878838663 , Val-loss =  57.62356527228104 , Time for epoch =  0.01581096649169922 s\n",
      "Epoch  221 / 1000  : Train-loss =  66.58094656130689 , Val-loss =  57.55420604505037 , Time for epoch =  0.017101049423217773 s\n",
      "Epoch  222 / 1000  : Train-loss =  66.50226834399552 , Val-loss =  57.48710311086554 , Time for epoch =  0.013818740844726562 s\n",
      "Epoch  223 / 1000  : Train-loss =  66.42426360394322 , Val-loss =  57.42967003270199 , Time for epoch =  0.018613100051879883 s\n",
      "Epoch  224 / 1000  : Train-loss =  66.3447810027559 , Val-loss =  57.36776673166376 , Time for epoch =  0.015225410461425781 s\n",
      "Epoch  225 / 1000  : Train-loss =  66.26630949031161 , Val-loss =  57.304594341077305 , Time for epoch =  0.014083147048950195 s\n",
      "Epoch  226 / 1000  : Train-loss =  66.18832395305742 , Val-loss =  57.24140388087223 , Time for epoch =  0.013840675354003906 s\n",
      "Epoch  227 / 1000  : Train-loss =  66.11063906567244 , Val-loss =  57.178707925896894 , Time for epoch =  0.014127731323242188 s\n",
      "Epoch  228 / 1000  : Train-loss =  65.99863321767688 , Val-loss =  57.01134571276213 , Time for epoch =  0.014176130294799805 s\n",
      "Epoch  229 / 1000  : Train-loss =  65.93188366647495 , Val-loss =  56.90956436960321 , Time for epoch =  0.013933420181274414 s\n",
      "Epoch  230 / 1000  : Train-loss =  65.85254475221795 , Val-loss =  56.809594003777754 , Time for epoch =  0.01490020751953125 s\n",
      "Epoch  231 / 1000  : Train-loss =  65.78086044828771 , Val-loss =  56.75116950587223 , Time for epoch =  0.017406940460205078 s\n",
      "Epoch  232 / 1000  : Train-loss =  65.70402957894707 , Val-loss =  56.70305211920487 , Time for epoch =  0.013918399810791016 s\n",
      "Epoch  233 / 1000  : Train-loss =  65.601678621971 , Val-loss =  56.667599527459394 , Time for epoch =  0.015683889389038086 s\n",
      "Epoch  234 / 1000  : Train-loss =  65.53708053847491 , Val-loss =  56.62149148238333 , Time for epoch =  0.016266584396362305 s\n",
      "Epoch  235 / 1000  : Train-loss =  65.43994601836985 , Val-loss =  56.587796662983145 , Time for epoch =  0.014000892639160156 s\n",
      "Epoch  236 / 1000  : Train-loss =  65.35424550374348 , Val-loss =  56.55168091623407 , Time for epoch =  0.01617264747619629 s\n",
      "Epoch  237 / 1000  : Train-loss =  65.27256779212736 , Val-loss =  56.5144032930073 , Time for epoch =  0.013621807098388672 s\n",
      "Epoch  238 / 1000  : Train-loss =  65.19286247296522 , Val-loss =  56.47691586143092 , Time for epoch =  0.014423131942749023 s\n",
      "Epoch  239 / 1000  : Train-loss =  65.11425740301273 , Val-loss =  56.43976472553454 , Time for epoch =  0.014542579650878906 s\n",
      "Epoch  240 / 1000  : Train-loss =  65.03638072471834 , Val-loss =  56.40325425800524 , Time for epoch =  0.015007734298706055 s\n",
      "Epoch  241 / 1000  : Train-loss =  64.94208358506025 , Val-loss =  56.362523530658926 , Time for epoch =  0.018468379974365234 s\n",
      "Epoch  242 / 1000  : Train-loss =  64.86625740352997 , Val-loss =  56.32601748014751 , Time for epoch =  0.01419830322265625 s\n",
      "Epoch  243 / 1000  : Train-loss =  64.79069717321019 , Val-loss =  56.29179803948654 , Time for epoch =  0.019004106521606445 s\n",
      "Epoch  244 / 1000  : Train-loss =  64.7153344666217 , Val-loss =  56.259108894749694 , Time for epoch =  0.021366596221923828 s\n",
      "Epoch  245 / 1000  : Train-loss =  64.64761369780632 , Val-loss =  56.230732566431946 , Time for epoch =  0.021286725997924805 s\n",
      "Epoch  246 / 1000  : Train-loss =  64.57016157161044 , Val-loss =  56.20155414782072 , Time for epoch =  0.018102169036865234 s\n",
      "Epoch  247 / 1000  : Train-loss =  64.49478224845929 , Val-loss =  56.17290095279091 , Time for epoch =  0.014711141586303711 s\n",
      "Epoch  248 / 1000  : Train-loss =  64.4205726149392 , Val-loss =  56.14520504600123 , Time for epoch =  0.016962766647338867 s\n",
      "Epoch  249 / 1000  : Train-loss =  64.3471292829783 , Val-loss =  56.117080086155944 , Time for epoch =  0.018800020217895508 s\n",
      "Epoch  250 / 1000  : Train-loss =  64.27426953504315 , Val-loss =  56.08647999010588 , Time for epoch =  0.0210113525390625 s\n",
      "Epoch  251 / 1000  : Train-loss =  64.20187987850211 , Val-loss =  56.05667254799291 , Time for epoch =  0.01886916160583496 s\n",
      "Epoch  252 / 1000  : Train-loss =  64.12991688615185 , Val-loss =  56.02774027774208 , Time for epoch =  0.016626834869384766 s\n",
      "Epoch  253 / 1000  : Train-loss =  64.05835357493599 , Val-loss =  55.99969582808645 , Time for epoch =  0.018302440643310547 s\n",
      "Epoch  254 / 1000  : Train-loss =  63.9871742334743 , Val-loss =  55.97254923770302 , Time for epoch =  0.016675472259521484 s\n",
      "Epoch  255 / 1000  : Train-loss =  63.91636797802597 , Val-loss =  55.9463398582057 , Time for epoch =  0.01984429359436035 s\n",
      "Epoch  256 / 1000  : Train-loss =  63.84592187741382 , Val-loss =  55.92104199058131 , Time for epoch =  0.01895618438720703 s\n",
      "Epoch  257 / 1000  : Train-loss =  63.77583491869566 , Val-loss =  55.89668193616365 , Time for epoch =  0.018770694732666016 s\n",
      "Epoch  258 / 1000  : Train-loss =  63.706088955119505 , Val-loss =  55.873226968865644 , Time for epoch =  0.014363288879394531 s\n",
      "Epoch  259 / 1000  : Train-loss =  63.63669814632437 , Val-loss =  55.85069535907946 , Time for epoch =  0.01692795753479004 s\n",
      "Epoch  260 / 1000  : Train-loss =  63.56763208249195 , Val-loss =  55.82907224956312 , Time for epoch =  0.018216848373413086 s\n",
      "Epoch  261 / 1000  : Train-loss =  63.498897768009854 , Val-loss =  55.80835804186369 , Time for epoch =  0.014950990676879883 s\n",
      "Epoch  262 / 1000  : Train-loss =  63.4304883493542 , Val-loss =  55.78855253520765 , Time for epoch =  0.013567924499511719 s\n",
      "Epoch  263 / 1000  : Train-loss =  63.36238848152807 , Val-loss =  55.76964147467362 , Time for epoch =  0.013675928115844727 s\n",
      "Epoch  264 / 1000  : Train-loss =  63.29460475943183 , Val-loss =  55.75163851286236 , Time for epoch =  0.013689279556274414 s\n",
      "Epoch  265 / 1000  : Train-loss =  63.227119381144895 , Val-loss =  55.734527587890625 , Time for epoch =  0.013431310653686523 s\n",
      "Epoch  266 / 1000  : Train-loss =  63.15993161390057 , Val-loss =  55.71831612837942 , Time for epoch =  0.012811660766601562 s\n",
      "Epoch  267 / 1000  : Train-loss =  63.093023806642 , Val-loss =  55.70297542371248 , Time for epoch =  0.013768434524536133 s\n",
      "Epoch  268 / 1000  : Train-loss =  63.026401562879315 , Val-loss =  55.68852374428197 , Time for epoch =  0.013375520706176758 s\n",
      "Epoch  269 / 1000  : Train-loss =  62.99902529096873 , Val-loss =  55.62320970234118 , Time for epoch =  0.01339578628540039 s\n",
      "Epoch  270 / 1000  : Train-loss =  62.93701107219114 , Val-loss =  55.621316608629726 , Time for epoch =  0.017422199249267578 s\n",
      "Epoch  271 / 1000  : Train-loss =  62.86634723210739 , Val-loss =  55.614850295217416 , Time for epoch =  0.014194011688232422 s\n",
      "Epoch  272 / 1000  : Train-loss =  62.79708396782309 , Val-loss =  55.608609651264395 , Time for epoch =  0.013379812240600586 s\n",
      "Epoch  273 / 1000  : Train-loss =  62.78752539252157 , Val-loss =  55.62498976054945 , Time for epoch =  0.0171053409576416 s\n",
      "Epoch  274 / 1000  : Train-loss =  62.6897318780759 , Val-loss =  55.58026624980726 , Time for epoch =  0.013164043426513672 s\n",
      "Epoch  275 / 1000  : Train-loss =  62.623487892797435 , Val-loss =  55.56436378077457 , Time for epoch =  0.01297903060913086 s\n",
      "Epoch  276 / 1000  : Train-loss =  62.61095549157784 , Val-loss =  55.57920857479698 , Time for epoch =  0.013148069381713867 s\n",
      "Epoch  277 / 1000  : Train-loss =  62.51949448235291 , Val-loss =  55.536262913754115 , Time for epoch =  0.01296854019165039 s\n",
      "Epoch  278 / 1000  : Train-loss =  62.46983087399585 , Val-loss =  55.59399474294562 , Time for epoch =  0.013068914413452148 s\n",
      "Epoch  279 / 1000  : Train-loss =  62.40440898830608 , Val-loss =  55.494161103901114 , Time for epoch =  0.013127565383911133 s\n",
      "Epoch  280 / 1000  : Train-loss =  62.37195735866741 , Val-loss =  55.556744023373255 , Time for epoch =  0.013684749603271484 s\n",
      "Epoch  281 / 1000  : Train-loss =  62.284097876252424 , Val-loss =  55.58325255544562 , Time for epoch =  0.013117551803588867 s\n",
      "Epoch  282 / 1000  : Train-loss =  62.2438355354266 , Val-loss =  55.55064693250154 , Time for epoch =  0.01333165168762207 s\n",
      "Epoch  283 / 1000  : Train-loss =  62.17853563384148 , Val-loss =  55.56368797703793 , Time for epoch =  0.013589859008789062 s\n",
      "Epoch  284 / 1000  : Train-loss =  62.09872518420893 , Val-loss =  55.5677241275185 , Time for epoch =  0.01383829116821289 s\n",
      "Epoch  285 / 1000  : Train-loss =  62.06610855274955 , Val-loss =  55.52555887322677 , Time for epoch =  0.017191171646118164 s\n",
      "Epoch  286 / 1000  : Train-loss =  61.99823491586804 , Val-loss =  55.53383295159591 , Time for epoch =  0.014463663101196289 s\n",
      "Epoch  287 / 1000  : Train-loss =  61.952532924501234 , Val-loss =  55.50778158087479 , Time for epoch =  0.013484477996826172 s\n",
      "Epoch  288 / 1000  : Train-loss =  61.889285696428374 , Val-loss =  55.526802464535365 , Time for epoch =  0.01607489585876465 s\n",
      "Epoch  289 / 1000  : Train-loss =  61.80529364892992 , Val-loss =  55.53684836939762 , Time for epoch =  0.013267278671264648 s\n",
      "Epoch  290 / 1000  : Train-loss =  61.76735790705277 , Val-loss =  55.50251529091283 , Time for epoch =  0.013776779174804688 s\n",
      "Epoch  291 / 1000  : Train-loss =  61.698180462680966 , Val-loss =  55.51697178890831 , Time for epoch =  0.013878583908081055 s\n",
      "Epoch  292 / 1000  : Train-loss =  61.6498504035217 , Val-loss =  55.48457798204924 , Time for epoch =  0.016332626342773438 s\n",
      "Epoch  293 / 1000  : Train-loss =  61.58716007814569 , Val-loss =  55.5023771587171 , Time for epoch =  0.014264583587646484 s\n",
      "Epoch  294 / 1000  : Train-loss =  61.50274528891353 , Val-loss =  55.51447215833162 , Time for epoch =  0.013555288314819336 s\n",
      "Epoch  295 / 1000  : Train-loss =  61.467898891470526 , Val-loss =  55.484642831902754 , Time for epoch =  0.01372385025024414 s\n",
      "Epoch  296 / 1000  : Train-loss =  61.394915650793386 , Val-loss =  55.502826289126745 , Time for epoch =  0.014985084533691406 s\n",
      "Epoch  297 / 1000  : Train-loss =  61.35060401959608 , Val-loss =  55.47579333656713 , Time for epoch =  0.013416528701782227 s\n",
      "Epoch  298 / 1000  : Train-loss =  61.28297402764444 , Val-loss =  55.49767986096834 , Time for epoch =  0.013999700546264648 s\n",
      "Epoch  299 / 1000  : Train-loss =  61.23244903047206 , Val-loss =  55.47311280903063 , Time for epoch =  0.015900135040283203 s\n",
      "Epoch  300 / 1000  : Train-loss =  61.168589446504235 , Val-loss =  55.49660050241571 , Time for epoch =  0.016900062561035156 s\n",
      "Epoch  301 / 1000  : Train-loss =  61.113571468719655 , Val-loss =  55.47049311587685 , Time for epoch =  0.014316558837890625 s\n",
      "Epoch  302 / 1000  : Train-loss =  61.0523454482946 , Val-loss =  55.49513244628906 , Time for epoch =  0.017812490463256836 s\n",
      "Epoch  303 / 1000  : Train-loss =  60.965149184404794 , Val-loss =  55.51280232479698 , Time for epoch =  0.017599105834960938 s\n",
      "Epoch  304 / 1000  : Train-loss =  60.92872949373924 , Val-loss =  55.48938650833933 , Time for epoch =  0.013541460037231445 s\n",
      "Epoch  305 / 1000  : Train-loss =  60.854339384089755 , Val-loss =  55.51243089374743 , Time for epoch =  0.013494491577148438 s\n",
      "Epoch  306 / 1000  : Train-loss =  60.81095146998174 , Val-loss =  55.49083810103567 , Time for epoch =  0.013501405715942383 s\n",
      "Epoch  307 / 1000  : Train-loss =  60.74016176644018 , Val-loss =  55.51699929488333 , Time for epoch =  0.013463020324707031 s\n",
      "Epoch  308 / 1000  : Train-loss =  60.69246677894377 , Val-loss =  55.497156645122324 , Time for epoch =  0.013295412063598633 s\n",
      "Epoch  309 / 1000  : Train-loss =  60.624212577518094 , Val-loss =  55.526098552503086 , Time for epoch =  0.013722896575927734 s\n",
      "Epoch  310 / 1000  : Train-loss =  60.57341188764842 , Val-loss =  55.50778479325144 , Time for epoch =  0.013319253921508789 s\n",
      "Epoch  311 / 1000  : Train-loss =  60.50694199470477 , Val-loss =  55.53915445428146 , Time for epoch =  0.016297578811645508 s\n",
      "Epoch  312 / 1000  : Train-loss =  60.45394259522864 , Val-loss =  55.522190495541224 , Time for epoch =  0.01815652847290039 s\n",
      "Epoch  313 / 1000  : Train-loss =  60.3887008192849 , Val-loss =  55.55566245631168 , Time for epoch =  0.016585826873779297 s\n",
      "Epoch  314 / 1000  : Train-loss =  60.33420168343237 , Val-loss =  55.53988848234478 , Time for epoch =  0.015353202819824219 s\n",
      "Epoch  315 / 1000  : Train-loss =  60.269781338966496 , Val-loss =  55.57520274112099 , Time for epoch =  0.014376163482666016 s\n",
      "Epoch  316 / 1000  : Train-loss =  60.21704265357411 , Val-loss =  55.60566590961657 , Time for epoch =  0.018577098846435547 s\n",
      "Epoch  317 / 1000  : Train-loss =  60.14633066640735 , Val-loss =  55.616382799650495 , Time for epoch =  0.013698101043701172 s\n",
      "Epoch  318 / 1000  : Train-loss =  60.09129361513644 , Val-loss =  55.587738037109375 , Time for epoch =  0.01389765739440918 s\n",
      "Epoch  319 / 1000  : Train-loss =  60.02857699636686 , Val-loss =  55.61813495033666 , Time for epoch =  0.013777017593383789 s\n",
      "Epoch  320 / 1000  : Train-loss =  59.97626411308676 , Val-loss =  55.64772174232885 , Time for epoch =  0.013370275497436523 s\n",
      "Epoch  321 / 1000  : Train-loss =  59.90580191315904 , Val-loss =  55.65832700227436 , Time for epoch =  0.013676166534423828 s\n",
      "Epoch  322 / 1000  : Train-loss =  59.850317270742295 , Val-loss =  55.62985209414833 , Time for epoch =  0.014026403427124023 s\n",
      "Epoch  323 / 1000  : Train-loss =  59.79196003197276 , Val-loss =  55.710085818642064 , Time for epoch =  0.01396489143371582 s\n",
      "Epoch  324 / 1000  : Train-loss =  59.728334200584285 , Val-loss =  55.66654988339073 , Time for epoch =  0.014226436614990234 s\n",
      "Epoch  325 / 1000  : Train-loss =  59.66617107930156 , Val-loss =  55.69069330315841 , Time for epoch =  0.013610601425170898 s\n",
      "Epoch  326 / 1000  : Train-loss =  59.61541407525876 , Val-loss =  55.719523781224304 , Time for epoch =  0.014739513397216797 s\n",
      "Epoch  327 / 1000  : Train-loss =  59.54462982436358 , Val-loss =  55.72959679051449 , Time for epoch =  0.014553546905517578 s\n",
      "Epoch  328 / 1000  : Train-loss =  59.4941218747931 , Val-loss =  55.751251220703125 , Time for epoch =  0.013952970504760742 s\n",
      "Epoch  329 / 1000  : Train-loss =  59.4239800447798 , Val-loss =  55.75662934152704 , Time for epoch =  0.01707005500793457 s\n",
      "Epoch  330 / 1000  : Train-loss =  59.362136452885 , Val-loss =  55.685217807167454 , Time for epoch =  0.015210390090942383 s\n",
      "Epoch  331 / 1000  : Train-loss =  59.31467110154319 , Val-loss =  55.79605825323807 , Time for epoch =  0.014869451522827148 s\n",
      "Epoch  332 / 1000  : Train-loss =  59.24267233293609 , Val-loss =  55.72311602140728 , Time for epoch =  0.015334129333496094 s\n",
      "Epoch  333 / 1000  : Train-loss =  59.19489350830768 , Val-loss =  55.83037085282175 , Time for epoch =  0.014905929565429688 s\n",
      "Epoch  334 / 1000  : Train-loss =  59.123638713427184 , Val-loss =  55.75590555291427 , Time for epoch =  0.015800952911376953 s\n",
      "Epoch  335 / 1000  : Train-loss =  59.07560249371717 , Val-loss =  55.86252172369706 , Time for epoch =  0.013401031494140625 s\n",
      "Epoch  336 / 1000  : Train-loss =  59.004927597476936 , Val-loss =  55.787270395379316 , Time for epoch =  0.013499021530151367 s\n",
      "Epoch  337 / 1000  : Train-loss =  58.956624004126944 , Val-loss =  55.89419515509354 , Time for epoch =  0.013845682144165039 s\n",
      "Epoch  338 / 1000  : Train-loss =  58.886496635480114 , Val-loss =  55.818443499113386 , Time for epoch =  0.013384342193603516 s\n",
      "Epoch  339 / 1000  : Train-loss =  58.83792989267468 , Val-loss =  55.92584730449476 , Time for epoch =  0.013714313507080078 s\n",
      "Epoch  340 / 1000  : Train-loss =  58.768346344683806 , Val-loss =  55.84969450298109 , Time for epoch =  0.014373779296875 s\n",
      "Epoch  341 / 1000  : Train-loss =  58.71951065494516 , Val-loss =  55.95745187056692 , Time for epoch =  0.013802289962768555 s\n",
      "Epoch  342 / 1000  : Train-loss =  58.662104590464445 , Val-loss =  55.973783794202305 , Time for epoch =  0.0137176513671875 s\n",
      "Epoch  343 / 1000  : Train-loss =  58.58473091341008 , Val-loss =  55.94396631341232 , Time for epoch =  0.014173030853271484 s\n",
      "Epoch  344 / 1000  : Train-loss =  58.54575287554897 , Val-loss =  55.97774204454924 , Time for epoch =  0.018355607986450195 s\n",
      "Epoch  345 / 1000  : Train-loss =  58.46754149528547 , Val-loss =  55.95532547800165 , Time for epoch =  0.013837575912475586 s\n",
      "Epoch  346 / 1000  : Train-loss =  58.428935810671014 , Val-loss =  56.00028409455952 , Time for epoch =  0.013610124588012695 s\n",
      "Epoch  347 / 1000  : Train-loss =  58.3505552906101 , Val-loss =  55.978192580373666 , Time for epoch =  0.013808012008666992 s\n",
      "Epoch  348 / 1000  : Train-loss =  58.31204579240185 , Val-loss =  56.01476649234169 , Time for epoch =  0.013494491577148438 s\n",
      "Epoch  349 / 1000  : Train-loss =  58.24498007391806 , Val-loss =  56.07820129394531 , Time for epoch =  0.014232635498046875 s\n",
      "Epoch  350 / 1000  : Train-loss =  58.17975506540072 , Val-loss =  55.98192596435547 , Time for epoch =  0.013916492462158203 s\n",
      "Epoch  351 / 1000  : Train-loss =  58.12929828018792 , Val-loss =  56.059549030504726 , Time for epoch =  0.013968706130981445 s\n",
      "Epoch  352 / 1000  : Train-loss =  58.06380704028458 , Val-loss =  55.97203304893092 , Time for epoch =  0.013784170150756836 s\n",
      "Epoch  353 / 1000  : Train-loss =  58.00813302077816 , Val-loss =  56.03617899041427 , Time for epoch =  0.01392817497253418 s\n",
      "Epoch  354 / 1000  : Train-loss =  57.95991363094351 , Val-loss =  56.05055979678505 , Time for epoch =  0.014355182647705078 s\n",
      "Epoch  355 / 1000  : Train-loss =  57.883632078009136 , Val-loss =  56.01710289403012 , Time for epoch =  0.014821529388427734 s\n",
      "Epoch  356 / 1000  : Train-loss =  57.84490014200156 , Val-loss =  56.04062331350226 , Time for epoch =  0.013826370239257812 s\n",
      "Epoch  357 / 1000  : Train-loss =  57.76849095834851 , Val-loss =  56.014183847527754 , Time for epoch =  0.013635635375976562 s\n",
      "Epoch  358 / 1000  : Train-loss =  57.725100910596254 , Val-loss =  56.019004219456725 , Time for epoch =  0.016416311264038086 s\n",
      "Epoch  359 / 1000  : Train-loss =  57.66480824098749 , Val-loss =  56.09218918649774 , Time for epoch =  0.014610528945922852 s\n",
      "Epoch  360 / 1000  : Train-loss =  57.60175737283998 , Val-loss =  55.99741885536596 , Time for epoch =  0.015143632888793945 s\n",
      "Epoch  361 / 1000  : Train-loss =  57.545791884600106 , Val-loss =  56.05732184962223 , Time for epoch =  0.013860940933227539 s\n",
      "Epoch  362 / 1000  : Train-loss =  57.49823146755413 , Val-loss =  56.067573948910365 , Time for epoch =  0.016473054885864258 s\n",
      "Epoch  363 / 1000  : Train-loss =  57.42377256404209 , Val-loss =  56.02925531487716 , Time for epoch =  0.014024972915649414 s\n",
      "Epoch  364 / 1000  : Train-loss =  57.380021046783966 , Val-loss =  56.02806352314196 , Time for epoch =  0.013550281524658203 s\n",
      "Epoch  365 / 1000  : Train-loss =  57.32041847099692 , Val-loss =  56.09756509881271 , Time for epoch =  0.013225555419921875 s\n",
      "Epoch  366 / 1000  : Train-loss =  57.25900949596685 , Val-loss =  55.99659106605932 , Time for epoch =  0.01273965835571289 s\n",
      "Epoch  367 / 1000  : Train-loss =  57.20292256242138 , Val-loss =  56.05588651958265 , Time for epoch =  0.01295161247253418 s\n",
      "Epoch  368 / 1000  : Train-loss =  57.155866676804706 , Val-loss =  56.06352474814967 , Time for epoch =  0.013950347900390625 s\n",
      "Epoch  369 / 1000  : Train-loss =  57.08308242539228 , Val-loss =  56.02195358276367 , Time for epoch =  0.013963937759399414 s\n",
      "Epoch  370 / 1000  : Train-loss =  57.03913491459216 , Val-loss =  56.019346939890006 , Time for epoch =  0.013918399810791016 s\n",
      "Epoch  371 / 1000  : Train-loss =  56.971297334142996 , Val-loss =  55.99569220291941 , Time for epoch =  0.013447046279907227 s\n",
      "Epoch  372 / 1000  : Train-loss =  56.92837216221007 , Val-loss =  56.00463003861277 , Time for epoch =  0.016213655471801758 s\n",
      "Epoch  373 / 1000  : Train-loss =  56.86876594414145 , Val-loss =  56.08093422337582 , Time for epoch =  0.01354360580444336 s\n",
      "Epoch  374 / 1000  : Train-loss =  56.809149639754644 , Val-loss =  55.97826064260382 , Time for epoch =  0.012789249420166016 s\n",
      "Epoch  375 / 1000  : Train-loss =  56.753476719398286 , Val-loss =  56.03990434345446 , Time for epoch =  0.012993574142456055 s\n",
      "Epoch  376 / 1000  : Train-loss =  56.69830787788003 , Val-loss =  55.95114276283666 , Time for epoch =  0.012923717498779297 s\n",
      "Epoch  377 / 1000  : Train-loss =  56.64363858928788 , Val-loss =  56.02315179925216 , Time for epoch =  0.012928962707519531 s\n",
      "Epoch  378 / 1000  : Train-loss =  56.596088495631676 , Val-loss =  56.03481071873715 , Time for epoch =  0.01352548599243164 s\n",
      "Epoch  379 / 1000  : Train-loss =  56.5263075963252 , Val-loss =  55.99232221904554 , Time for epoch =  0.013217687606811523 s\n",
      "Epoch  380 / 1000  : Train-loss =  56.482033314677956 , Val-loss =  55.98890585648386 , Time for epoch =  0.012733221054077148 s\n",
      "Epoch  381 / 1000  : Train-loss =  56.41665942520745 , Val-loss =  55.960824263723275 , Time for epoch =  0.012768268585205078 s\n",
      "Epoch  382 / 1000  : Train-loss =  56.37318681188896 , Val-loss =  55.96724600540964 , Time for epoch =  0.013148069381713867 s\n",
      "Epoch  383 / 1000  : Train-loss =  56.307706886765644 , Val-loss =  55.94505671450966 , Time for epoch =  0.01604485511779785 s\n",
      "Epoch  384 / 1000  : Train-loss =  56.264411322814595 , Val-loss =  55.95465670133892 , Time for epoch =  0.015351533889770508 s\n",
      "Epoch  385 / 1000  : Train-loss =  56.199255043503925 , Val-loss =  55.93362145674856 , Time for epoch =  0.013994932174682617 s\n",
      "Epoch  386 / 1000  : Train-loss =  56.15590797036381 , Val-loss =  55.94365672061318 , Time for epoch =  0.013815164566040039 s\n",
      "Epoch  387 / 1000  : Train-loss =  56.09124714910647 , Val-loss =  55.922035819605775 , Time for epoch =  0.01618027687072754 s\n",
      "Epoch  388 / 1000  : Train-loss =  56.047771281441726 , Val-loss =  55.931603281121504 , Time for epoch =  0.013620376586914062 s\n",
      "Epoch  389 / 1000  : Train-loss =  55.98369268643654 , Val-loss =  55.9088702954744 , Time for epoch =  0.013556480407714844 s\n",
      "Epoch  390 / 1000  : Train-loss =  55.94006520071946 , Val-loss =  55.917680037649056 , Time for epoch =  0.013684749603271484 s\n",
      "Epoch  391 / 1000  : Train-loss =  55.876618616998535 , Val-loss =  55.893721329538444 , Time for epoch =  0.01317906379699707 s\n",
      "Epoch  392 / 1000  : Train-loss =  55.832809081858834 , Val-loss =  55.901763916015625 , Time for epoch =  0.01322793960571289 s\n",
      "Epoch  393 / 1000  : Train-loss =  55.77004032889329 , Val-loss =  55.8765206587942 , Time for epoch =  0.013347387313842773 s\n",
      "Epoch  394 / 1000  : Train-loss =  55.72604738655737 , Val-loss =  55.88380893908049 , Time for epoch =  0.016065359115600586 s\n",
      "Epoch  395 / 1000  : Train-loss =  55.663992391467765 , Val-loss =  55.85739677830746 , Time for epoch =  0.013876676559448242 s\n",
      "Epoch  396 / 1000  : Train-loss =  55.61979433910995 , Val-loss =  55.86396769473427 , Time for epoch =  0.013480663299560547 s\n",
      "Epoch  397 / 1000  : Train-loss =  55.55848083927133 , Val-loss =  55.83641493947882 , Time for epoch =  0.014837026596069336 s\n",
      "Epoch  398 / 1000  : Train-loss =  55.51408218125165 , Val-loss =  55.84231928775185 , Time for epoch =  0.016557693481445312 s\n",
      "Epoch  399 / 1000  : Train-loss =  55.453539185604804 , Val-loss =  55.81367733604029 , Time for epoch =  0.014147281646728516 s\n",
      "Epoch  400 / 1000  : Train-loss =  55.408915115615066 , Val-loss =  55.81893278423109 , Time for epoch =  0.014312267303466797 s\n",
      "Epoch  401 / 1000  : Train-loss =  55.34917346501754 , Val-loss =  55.78925805342825 , Time for epoch =  0.016409873962402344 s\n",
      "Epoch  402 / 1000  : Train-loss =  55.3043307503738 , Val-loss =  55.79392423127827 , Time for epoch =  0.01732635498046875 s\n",
      "Epoch  403 / 1000  : Train-loss =  55.24541772960943 , Val-loss =  55.763286992123255 , Time for epoch =  0.014403343200683594 s\n",
      "Epoch  404 / 1000  : Train-loss =  55.20033139158777 , Val-loss =  55.767405459755345 , Time for epoch =  0.013598203659057617 s\n",
      "Epoch  405 / 1000  : Train-loss =  55.142256785247284 , Val-loss =  55.7358129400956 , Time for epoch =  0.013379335403442383 s\n",
      "Epoch  406 / 1000  : Train-loss =  55.096927750582076 , Val-loss =  55.7394067864669 , Time for epoch =  0.013502120971679688 s\n",
      "Epoch  407 / 1000  : Train-loss =  55.03972005035918 , Val-loss =  55.706939697265625 , Time for epoch =  0.01334238052368164 s\n",
      "Epoch  408 / 1000  : Train-loss =  54.992286660576944 , Val-loss =  55.6248076589484 , Time for epoch =  0.015411853790283203 s\n",
      "Epoch  409 / 1000  : Train-loss =  54.942113650047176 , Val-loss =  55.715678566380554 , Time for epoch =  0.013694047927856445 s\n",
      "Epoch  410 / 1000  : Train-loss =  54.89047161468678 , Val-loss =  55.62027118080541 , Time for epoch =  0.013368368148803711 s\n",
      "Epoch  411 / 1000  : Train-loss =  54.83994918219787 , Val-loss =  55.700948213276114 , Time for epoch =  0.014634132385253906 s\n",
      "Epoch  412 / 1000  : Train-loss =  54.78930405438957 , Val-loss =  55.59697382073654 , Time for epoch =  0.014687776565551758 s\n",
      "Epoch  413 / 1000  : Train-loss =  54.73731570055256 , Val-loss =  55.58642156500565 , Time for epoch =  0.013742208480834961 s\n",
      "Epoch  414 / 1000  : Train-loss =  54.69236201485671 , Val-loss =  55.605036886114824 , Time for epoch =  0.013943672180175781 s\n",
      "Epoch  415 / 1000  : Train-loss =  54.637264057741326 , Val-loss =  55.58015943828382 , Time for epoch =  0.01512765884399414 s\n",
      "Epoch  416 / 1000  : Train-loss =  54.59019718062406 , Val-loss =  55.49944405806692 , Time for epoch =  0.018820762634277344 s\n",
      "Epoch  417 / 1000  : Train-loss =  54.5413236025363 , Val-loss =  55.5935203150699 , Time for epoch =  0.015381336212158203 s\n",
      "Epoch  418 / 1000  : Train-loss =  54.49073769951944 , Val-loss =  55.494965402703535 , Time for epoch =  0.015566825866699219 s\n",
      "Epoch  419 / 1000  : Train-loss =  54.44044667044602 , Val-loss =  55.487184624922904 , Time for epoch =  0.013637542724609375 s\n",
      "Epoch  420 / 1000  : Train-loss =  54.39508944581458 , Val-loss =  55.50730996382864 , Time for epoch =  0.013459920883178711 s\n",
      "Epoch  421 / 1000  : Train-loss =  54.34216136178054 , Val-loss =  55.48141539724249 , Time for epoch =  0.013599634170532227 s\n",
      "Epoch  422 / 1000  : Train-loss =  54.29518767534676 , Val-loss =  55.39803535059879 , Time for epoch =  0.013498067855834961 s\n",
      "Epoch  423 / 1000  : Train-loss =  54.247184602554235 , Val-loss =  55.492231268631784 , Time for epoch =  0.013403892517089844 s\n",
      "Epoch  424 / 1000  : Train-loss =  54.19752799858481 , Val-loss =  55.390357971191406 , Time for epoch =  0.013068914413452148 s\n",
      "Epoch  425 / 1000  : Train-loss =  54.14881112481241 , Val-loss =  55.38024300023129 , Time for epoch =  0.0156705379486084 s\n",
      "Epoch  426 / 1000  : Train-loss =  54.10282859155687 , Val-loss =  55.399282355057565 , Time for epoch =  0.01758575439453125 s\n",
      "Epoch  427 / 1000  : Train-loss =  54.05239366003349 , Val-loss =  55.37098653692948 , Time for epoch =  0.013805866241455078 s\n",
      "Epoch  428 / 1000  : Train-loss =  54.00554874657237 , Val-loss =  55.28460291812294 , Time for epoch =  0.013729333877563477 s\n",
      "Epoch  429 / 1000  : Train-loss =  53.95810895585744 , Val-loss =  55.287501084177116 , Time for epoch =  0.01510763168334961 s\n",
      "Epoch  430 / 1000  : Train-loss =  53.91224700582903 , Val-loss =  55.31465650859632 , Time for epoch =  0.014581680297851562 s\n",
      "Epoch  431 / 1000  : Train-loss =  53.862934090996866 , Val-loss =  55.29048377589176 , Time for epoch =  0.016951560974121094 s\n",
      "Epoch  432 / 1000  : Train-loss =  53.81626034321758 , Val-loss =  55.205344350714434 , Time for epoch =  0.01352381706237793 s\n",
      "Epoch  433 / 1000  : Train-loss =  53.76992030601717 , Val-loss =  55.2086824115954 , Time for epoch =  0.013524770736694336 s\n",
      "Epoch  434 / 1000  : Train-loss =  53.72372171434306 , Val-loss =  55.23620525159334 , Time for epoch =  0.013451814651489258 s\n",
      "Epoch  435 / 1000  : Train-loss =  53.675939225881116 , Val-loss =  55.211104945132604 , Time for epoch =  0.013466596603393555 s\n",
      "Epoch  436 / 1000  : Train-loss =  53.62935312993109 , Val-loss =  55.124392660040606 , Time for epoch =  0.01341104507446289 s\n",
      "Epoch  437 / 1000  : Train-loss =  53.58408866494389 , Val-loss =  55.12663349352385 , Time for epoch =  0.014779090881347656 s\n",
      "Epoch  438 / 1000  : Train-loss =  53.53750259054583 , Val-loss =  55.153772052965664 , Time for epoch =  0.01327967643737793 s\n",
      "Epoch  439 / 1000  : Train-loss =  53.49136199520132 , Val-loss =  55.127401653089024 , Time for epoch =  0.01863241195678711 s\n",
      "Epoch  440 / 1000  : Train-loss =  53.444868766655354 , Val-loss =  55.039091411389805 , Time for epoch =  0.013944864273071289 s\n",
      "Epoch  441 / 1000  : Train-loss =  53.40072595197602 , Val-loss =  55.04022216796875 , Time for epoch =  0.013583898544311523 s\n",
      "Epoch  442 / 1000  : Train-loss =  53.35453401985815 , Val-loss =  54.97290561073705 , Time for epoch =  0.013636589050292969 s\n",
      "Epoch  443 / 1000  : Train-loss =  53.31042635642876 , Val-loss =  55.081256464907995 , Time for epoch =  0.013637065887451172 s\n",
      "Epoch  444 / 1000  : Train-loss =  53.26304708362299 , Val-loss =  54.979490982858756 , Time for epoch =  0.020937442779541016 s\n",
      "Epoch  445 / 1000  : Train-loss =  53.219907383460786 , Val-loss =  54.967955338327506 , Time for epoch =  0.01811957359313965 s\n",
      "Epoch  446 / 1000  : Train-loss =  53.17373424465374 , Val-loss =  54.89162726151316 , Time for epoch =  0.020758628845214844 s\n",
      "Epoch  447 / 1000  : Train-loss =  53.131320673193635 , Val-loss =  54.90025630750154 , Time for epoch =  0.017299175262451172 s\n",
      "Epoch  448 / 1000  : Train-loss =  53.05632506117309 , Val-loss =  54.899795933773646 , Time for epoch =  0.01965808868408203 s\n",
      "Epoch  449 / 1000  : Train-loss =  53.03256576882917 , Val-loss =  54.925111067922494 , Time for epoch =  0.01852560043334961 s\n",
      "Epoch  450 / 1000  : Train-loss =  52.975608071364924 , Val-loss =  54.90193417197779 , Time for epoch =  0.021410465240478516 s\n",
      "Epoch  451 / 1000  : Train-loss =  52.9474733428093 , Val-loss =  54.804583499306126 , Time for epoch =  0.022245407104492188 s\n",
      "Epoch  452 / 1000  : Train-loss =  52.89421881120757 , Val-loss =  54.80567691200658 , Time for epoch =  0.019765615463256836 s\n",
      "Epoch  453 / 1000  : Train-loss =  52.86282930535785 , Val-loss =  54.72968794170179 , Time for epoch =  0.013913154602050781 s\n",
      "Epoch  454 / 1000  : Train-loss =  52.812166979083905 , Val-loss =  54.74322851080643 , Time for epoch =  0.013825654983520508 s\n",
      "Epoch  455 / 1000  : Train-loss =  52.77832119613044 , Val-loss =  54.67560577392578 , Time for epoch =  0.013880014419555664 s\n",
      "Epoch  456 / 1000  : Train-loss =  52.72960044300489 , Val-loss =  54.69299818340101 , Time for epoch =  0.026192188262939453 s\n",
      "Epoch  457 / 1000  : Train-loss =  52.693845479501846 , Val-loss =  54.628135881925886 , Time for epoch =  0.021778106689453125 s\n",
      "Epoch  458 / 1000  : Train-loss =  52.64667209258861 , Val-loss =  54.646295848645664 , Time for epoch =  0.01513528823852539 s\n",
      "Epoch  459 / 1000  : Train-loss =  52.609461832854706 , Val-loss =  54.5822061237536 , Time for epoch =  0.013819217681884766 s\n",
      "Epoch  460 / 1000  : Train-loss =  52.563578740351616 , Val-loss =  54.600118135151114 , Time for epoch =  0.01505589485168457 s\n",
      "Epoch  461 / 1000  : Train-loss =  52.5252866798875 , Val-loss =  54.53608482762387 , Time for epoch =  0.013958454132080078 s\n",
      "Epoch  462 / 1000  : Train-loss =  52.78603660454184 , Val-loss =  54.35205921373869 , Time for epoch =  0.013843536376953125 s\n",
      "Epoch  463 / 1000  : Train-loss =  52.735220311051705 , Val-loss =  54.34427241275185 , Time for epoch =  0.014349937438964844 s\n",
      "Epoch  464 / 1000  : Train-loss =  52.68834957834017 , Val-loss =  54.31189386468185 , Time for epoch =  0.01457071304321289 s\n",
      "Epoch  465 / 1000  : Train-loss =  52.646843021198855 , Val-loss =  54.21669548436215 , Time for epoch =  0.015968799591064453 s\n",
      "Epoch  466 / 1000  : Train-loss =  52.60244725114208 , Val-loss =  54.21641078748201 , Time for epoch =  0.014153242111206055 s\n",
      "Epoch  467 / 1000  : Train-loss =  52.5572607180493 , Val-loss =  54.2395846718236 , Time for epoch =  0.013872385025024414 s\n",
      "Epoch  468 / 1000  : Train-loss =  52.51449822032519 , Val-loss =  54.2097571523566 , Time for epoch =  0.014423847198486328 s\n",
      "Epoch  469 / 1000  : Train-loss =  52.471541560975844 , Val-loss =  54.11170136301141 , Time for epoch =  0.019988298416137695 s\n",
      "Epoch  470 / 1000  : Train-loss =  52.429545084635414 , Val-loss =  54.10863253944799 , Time for epoch =  0.013949394226074219 s\n",
      "Epoch  471 / 1000  : Train-loss =  52.38303360157767 , Val-loss =  54.1311543113307 , Time for epoch =  0.013409852981567383 s\n",
      "Epoch  472 / 1000  : Train-loss =  52.34247263676703 , Val-loss =  54.09951842458624 , Time for epoch =  0.01352548599243164 s\n",
      "Epoch  473 / 1000  : Train-loss =  52.29889743610964 , Val-loss =  54.00020057276676 , Time for epoch =  0.01339864730834961 s\n",
      "Epoch  474 / 1000  : Train-loss =  52.25864362986074 , Val-loss =  53.99563638787521 , Time for epoch =  0.013995885848999023 s\n",
      "Epoch  475 / 1000  : Train-loss =  52.180374382579394 , Val-loss =  54.08534200567948 , Time for epoch =  0.013962268829345703 s\n",
      "Epoch  476 / 1000  : Train-loss =  52.16272802406785 , Val-loss =  53.95932107222708 , Time for epoch =  0.01430058479309082 s\n",
      "Epoch  477 / 1000  : Train-loss =  52.10762834279551 , Val-loss =  53.94479570890728 , Time for epoch =  0.016254663467407227 s\n",
      "Epoch  478 / 1000  : Train-loss =  52.08361275452005 , Val-loss =  53.84744222540604 , Time for epoch =  0.016065597534179688 s\n",
      "Epoch  479 / 1000  : Train-loss =  52.03185155836202 , Val-loss =  53.85413621601305 , Time for epoch =  0.014313220977783203 s\n",
      "Epoch  480 / 1000  : Train-loss =  52.000334184722036 , Val-loss =  53.87244495592619 , Time for epoch =  0.01432490348815918 s\n",
      "Epoch  481 / 1000  : Train-loss =  51.952220571916655 , Val-loss =  53.84504780016447 , Time for epoch =  0.01434469223022461 s\n",
      "Epoch  482 / 1000  : Train-loss =  51.92196043197718 , Val-loss =  53.73911004317434 , Time for epoch =  0.01600813865661621 s\n",
      "Epoch  483 / 1000  : Train-loss =  51.874898059219966 , Val-loss =  53.73668951737253 , Time for epoch =  0.014689207077026367 s\n",
      "Epoch  484 / 1000  : Train-loss =  51.842731001686914 , Val-loss =  53.65280091135126 , Time for epoch =  0.013455390930175781 s\n",
      "Epoch  485 / 1000  : Train-loss =  51.797271944035245 , Val-loss =  53.6635617707905 , Time for epoch =  0.013542652130126953 s\n",
      "Epoch  486 / 1000  : Train-loss =  51.759411375401385 , Val-loss =  53.68821836772718 , Time for epoch =  0.013848543167114258 s\n",
      "Epoch  487 / 1000  : Train-loss =  51.71666889944993 , Val-loss =  53.661482560007194 , Time for epoch =  0.01723027229309082 s\n",
      "Epoch  488 / 1000  : Train-loss =  51.68236951235324 , Val-loss =  53.558189392089844 , Time for epoch =  0.015241861343383789 s\n",
      "Epoch  489 / 1000  : Train-loss =  51.63934110652256 , Val-loss =  53.55527938039679 , Time for epoch =  0.013628244400024414 s\n",
      "Epoch  490 / 1000  : Train-loss =  51.604363953326384 , Val-loss =  53.472612481368216 , Time for epoch =  0.013525962829589844 s\n",
      "Epoch  491 / 1000  : Train-loss =  51.562252173989506 , Val-loss =  53.48270938270971 , Time for epoch =  0.014667272567749023 s\n",
      "Epoch  492 / 1000  : Train-loss =  51.526845770367125 , Val-loss =  53.40790698402807 , Time for epoch =  0.013971567153930664 s\n",
      "Epoch  493 / 1000  : Train-loss =  51.485444300592285 , Val-loss =  53.422324531956725 , Time for epoch =  0.0137786865234375 s\n",
      "Epoch  494 / 1000  : Train-loss =  51.44969813028971 , Val-loss =  53.349986829255755 , Time for epoch =  0.014250993728637695 s\n",
      "Epoch  495 / 1000  : Train-loss =  51.40891612855728 , Val-loss =  53.36551525718287 , Time for epoch =  0.013898134231567383 s\n",
      "Epoch  496 / 1000  : Train-loss =  51.372965602551474 , Val-loss =  53.293659812525696 , Time for epoch =  0.014653205871582031 s\n",
      "Epoch  497 / 1000  : Train-loss =  51.332746990656446 , Val-loss =  53.309281600149056 , Time for epoch =  0.01717662811279297 s\n",
      "Epoch  498 / 1000  : Train-loss =  51.29668262718761 , Val-loss =  53.2372902318051 , Time for epoch =  0.012861251831054688 s\n",
      "Epoch  499 / 1000  : Train-loss =  51.25698796503961 , Val-loss =  53.25272088301809 , Time for epoch =  0.014014244079589844 s\n",
      "Epoch  500 / 1000  : Train-loss =  51.220898299567445 , Val-loss =  53.18035226119192 , Time for epoch =  0.016096115112304688 s\n",
      "Epoch  501 / 1000  : Train-loss =  51.181704634327 , Val-loss =  53.1956249036287 , Time for epoch =  0.013536930084228516 s\n",
      "Epoch  502 / 1000  : Train-loss =  51.1456541287697 , Val-loss =  53.12292139153732 , Time for epoch =  0.013662099838256836 s\n",
      "Epoch  503 / 1000  : Train-loss =  51.106922386729785 , Val-loss =  53.137982619436166 , Time for epoch =  0.016267061233520508 s\n",
      "Epoch  504 / 1000  : Train-loss =  51.07096998570329 , Val-loss =  53.06494461862665 , Time for epoch =  0.02007293701171875 s\n",
      "Epoch  505 / 1000  : Train-loss =  51.03270061945511 , Val-loss =  53.07992172241211 , Time for epoch =  0.02419447898864746 s\n",
      "Epoch  506 / 1000  : Train-loss =  50.99686281021032 , Val-loss =  53.00662030671772 , Time for epoch =  0.019917726516723633 s\n",
      "Epoch  507 / 1000  : Train-loss =  50.95903321174578 , Val-loss =  53.02149923224198 , Time for epoch =  0.0211639404296875 s\n",
      "Epoch  508 / 1000  : Train-loss =  50.92333911098329 , Val-loss =  52.94796110454359 , Time for epoch =  0.014189004898071289 s\n",
      "Epoch  509 / 1000  : Train-loss =  50.885928655074814 , Val-loss =  52.96284565172697 , Time for epoch =  0.013926506042480469 s\n",
      "Epoch  510 / 1000  : Train-loss =  50.850423155531374 , Val-loss =  52.889119599994864 , Time for epoch =  0.01642608642578125 s\n",
      "Epoch  511 / 1000  : Train-loss =  50.81342628177276 , Val-loss =  52.904037074038854 , Time for epoch =  0.01736760139465332 s\n",
      "Epoch  512 / 1000  : Train-loss =  50.77809987903315 , Val-loss =  52.83009318301552 , Time for epoch =  0.019654273986816406 s\n",
      "Epoch  513 / 1000  : Train-loss =  50.74149466907911 , Val-loss =  52.84509217111688 , Time for epoch =  0.022382736206054688 s\n",
      "Epoch  514 / 1000  : Train-loss =  50.706374734135 , Val-loss =  52.7709442941766 , Time for epoch =  0.01659369468688965 s\n",
      "Epoch  515 / 1000  : Train-loss =  50.67013952826376 , Val-loss =  52.786033028050475 , Time for epoch =  0.020994901657104492 s\n",
      "Epoch  516 / 1000  : Train-loss =  50.635232505151784 , Val-loss =  52.71174601504677 , Time for epoch =  0.02125859260559082 s\n",
      "Epoch  517 / 1000  : Train-loss =  50.59938861825372 , Val-loss =  52.72696966873972 , Time for epoch =  0.014251232147216797 s\n",
      "Epoch  518 / 1000  : Train-loss =  50.5646809507898 , Val-loss =  52.652545728181536 , Time for epoch =  0.014390945434570312 s\n",
      "Epoch  519 / 1000  : Train-loss =  50.529193964381676 , Val-loss =  52.6678974753932 , Time for epoch =  0.01454305648803711 s\n",
      "Epoch  520 / 1000  : Train-loss =  50.49470261395988 , Val-loss =  52.593304684287624 , Time for epoch =  0.015820741653442383 s\n",
      "Epoch  521 / 1000  : Train-loss =  50.459571407339666 , Val-loss =  52.608801791542454 , Time for epoch =  0.014667987823486328 s\n",
      "Epoch  522 / 1000  : Train-loss =  50.42531271034715 , Val-loss =  52.534124876323496 , Time for epoch =  0.013422012329101562 s\n",
      "Epoch  523 / 1000  : Train-loss =  50.390528404106526 , Val-loss =  52.54981452540348 , Time for epoch =  0.017088651657104492 s\n",
      "Epoch  524 / 1000  : Train-loss =  50.35649156301035 , Val-loss =  52.47495611090409 , Time for epoch =  0.013571500778198242 s\n",
      "Epoch  525 / 1000  : Train-loss =  50.32204001906228 , Val-loss =  52.49081621671978 , Time for epoch =  0.016392946243286133 s\n",
      "Epoch  526 / 1000  : Train-loss =  50.28821727515614 , Val-loss =  52.415832921078334 , Time for epoch =  0.013585329055786133 s\n",
      "Epoch  527 / 1000  : Train-loss =  50.254103665971485 , Val-loss =  52.43189119037829 , Time for epoch =  0.012935400009155273 s\n",
      "Epoch  528 / 1000  : Train-loss =  50.22051210996121 , Val-loss =  52.35678722983912 , Time for epoch =  0.01821112632751465 s\n",
      "Epoch  529 / 1000  : Train-loss =  50.18671945259396 , Val-loss =  52.37303683632299 , Time for epoch =  0.017321109771728516 s\n",
      "Epoch  530 / 1000  : Train-loss =  50.15336001121392 , Val-loss =  52.297802573756165 , Time for epoch =  0.014143705368041992 s\n",
      "Epoch  531 / 1000  : Train-loss =  50.11988130127643 , Val-loss =  52.31423910040604 , Time for epoch =  0.014187097549438477 s\n",
      "Epoch  532 / 1000  : Train-loss =  50.086746474443856 , Val-loss =  52.238931354723476 , Time for epoch =  0.013999223709106445 s\n",
      "Epoch  533 / 1000  : Train-loss =  50.05357171182578 , Val-loss =  52.25557427657278 , Time for epoch =  0.016190052032470703 s\n",
      "Epoch  534 / 1000  : Train-loss =  50.02066221075543 , Val-loss =  52.18013221339176 , Time for epoch =  0.015291452407836914 s\n",
      "Epoch  535 / 1000  : Train-loss =  49.98779594292075 , Val-loss =  52.19699538381476 , Time for epoch =  0.013262271881103516 s\n",
      "Epoch  536 / 1000  : Train-loss =  49.95510700462901 , Val-loss =  52.12141880236174 , Time for epoch =  0.013357162475585938 s\n",
      "Epoch  537 / 1000  : Train-loss =  49.92254507204907 , Val-loss =  52.13848134091026 , Time for epoch =  0.013637065887451172 s\n",
      "Epoch  538 / 1000  : Train-loss =  49.89008178279898 , Val-loss =  52.062848141318874 , Time for epoch =  0.013849496841430664 s\n",
      "Epoch  539 / 1000  : Train-loss =  49.85781379742811 , Val-loss =  52.080112858822474 , Time for epoch =  0.013322830200195312 s\n",
      "Epoch  540 / 1000  : Train-loss =  49.82557365719208 , Val-loss =  52.00433369686729 , Time for epoch =  0.01354670524597168 s\n",
      "Epoch  541 / 1000  : Train-loss =  49.79359811039294 , Val-loss =  52.02185379831415 , Time for epoch =  0.013524770736694336 s\n",
      "Epoch  542 / 1000  : Train-loss =  49.761575903596174 , Val-loss =  51.945963407817636 , Time for epoch =  0.01580190658569336 s\n",
      "Epoch  543 / 1000  : Train-loss =  49.72987854952193 , Val-loss =  51.963682877390006 , Time for epoch =  0.01768660545349121 s\n",
      "Epoch  544 / 1000  : Train-loss =  49.698075439970374 , Val-loss =  51.88769270244398 , Time for epoch =  0.013956308364868164 s\n",
      "Epoch  545 / 1000  : Train-loss =  49.66666675287451 , Val-loss =  51.905637640702096 , Time for epoch =  0.013771533966064453 s\n",
      "Epoch  546 / 1000  : Train-loss =  49.63507689998648 , Val-loss =  51.8295370403089 , Time for epoch =  0.013715505599975586 s\n",
      "Epoch  547 / 1000  : Train-loss =  49.603942375398624 , Val-loss =  51.847718690571035 , Time for epoch =  0.01391744613647461 s\n",
      "Epoch  548 / 1000  : Train-loss =  49.57257698619433 , Val-loss =  51.771529950593646 , Time for epoch =  0.016559362411499023 s\n",
      "Epoch  549 / 1000  : Train-loss =  49.541716451698775 , Val-loss =  51.7899169921875 , Time for epoch =  0.013908863067626953 s\n",
      "Epoch  550 / 1000  : Train-loss =  49.51055878030378 , Val-loss =  51.7136116027832 , Time for epoch =  0.013795852661132812 s\n",
      "Epoch  551 / 1000  : Train-loss =  49.08414301899193 , Val-loss =  51.59130618446752 , Time for epoch =  0.01564812660217285 s\n",
      "Epoch  552 / 1000  : Train-loss =  49.06968891553286 , Val-loss =  51.56996777183131 , Time for epoch =  0.014138460159301758 s\n",
      "Epoch  553 / 1000  : Train-loss =  49.062093422237766 , Val-loss =  51.682557356984994 , Time for epoch =  0.013828277587890625 s\n",
      "Epoch  554 / 1000  : Train-loss =  49.05347981426002 , Val-loss =  51.69734091507761 , Time for epoch =  0.013835668563842773 s\n",
      "Epoch  555 / 1000  : Train-loss =  49.043491945428364 , Val-loss =  51.79606708727385 , Time for epoch =  0.0182497501373291 s\n",
      "Epoch  556 / 1000  : Train-loss =  49.03044143504342 , Val-loss =  51.79000232094213 , Time for epoch =  0.018326759338378906 s\n",
      "Epoch  557 / 1000  : Train-loss =  49.01637321946311 , Val-loss =  51.868192973889805 , Time for epoch =  0.014497756958007812 s\n",
      "Epoch  558 / 1000  : Train-loss =  48.999189624678614 , Val-loss =  51.84412444265265 , Time for epoch =  0.014156818389892578 s\n",
      "Epoch  559 / 1000  : Train-loss =  48.98171602669409 , Val-loss =  51.90629678023489 , Time for epoch =  0.013870477676391602 s\n",
      "Epoch  560 / 1000  : Train-loss =  48.961141424664 , Val-loss =  51.86854794150904 , Time for epoch =  0.013992071151733398 s\n",
      "Epoch  561 / 1000  : Train-loss =  48.940978637522896 , Val-loss =  51.91867165816458 , Time for epoch =  0.014480113983154297 s\n",
      "Epoch  562 / 1000  : Train-loss =  48.917739458676785 , Val-loss =  51.87069400988127 , Time for epoch =  0.019861698150634766 s\n",
      "Epoch  563 / 1000  : Train-loss =  48.895534795556365 , Val-loss =  51.9119220532869 , Time for epoch =  0.014226198196411133 s\n",
      "Epoch  564 / 1000  : Train-loss =  48.87026029252736 , Val-loss =  51.85641218486585 , Time for epoch =  0.013681650161743164 s\n",
      "Epoch  565 / 1000  : Train-loss =  48.846541668735654 , Val-loss =  51.89110765959087 , Time for epoch =  0.013341665267944336 s\n",
      "Epoch  566 / 1000  : Train-loss =  48.81968456203655 , Val-loss =  51.83005824841951 , Time for epoch =  0.013392448425292969 s\n",
      "Epoch  567 / 1000  : Train-loss =  48.794912801624015 , Val-loss =  51.85997812371505 , Time for epoch =  0.013633966445922852 s\n",
      "Epoch  568 / 1000  : Train-loss =  48.76687941039349 , Val-loss =  51.79432738454718 , Time for epoch =  0.013597726821899414 s\n",
      "Epoch  569 / 1000  : Train-loss =  48.74137706002273 , Val-loss =  51.82014304713199 , Time for epoch =  0.013526439666748047 s\n",
      "Epoch  570 / 1000  : Train-loss =  48.71246296941897 , Val-loss =  51.751427700645046 , Time for epoch =  0.015487909317016602 s\n",
      "Epoch  571 / 1000  : Train-loss =  48.68649136818061 , Val-loss =  51.77476702238384 , Time for epoch =  0.016722917556762695 s\n",
      "Epoch  572 / 1000  : Train-loss =  48.65694731372898 , Val-loss =  51.70392829493473 , Time for epoch =  0.013802528381347656 s\n",
      "Epoch  573 / 1000  : Train-loss =  48.63070508450438 , Val-loss =  51.72553996035927 , Time for epoch =  0.013611316680908203 s\n",
      "Epoch  574 / 1000  : Train-loss =  48.56830146487823 , Val-loss =  51.73389595433285 , Time for epoch =  0.013828754425048828 s\n",
      "Epoch  575 / 1000  : Train-loss =  48.563836954407776 , Val-loss =  51.63541211579975 , Time for epoch =  0.013792991638183594 s\n",
      "Epoch  576 / 1000  : Train-loss =  48.52129310133767 , Val-loss =  51.67196334035773 , Time for epoch =  0.015605926513671875 s\n",
      "Epoch  577 / 1000  : Train-loss =  48.51111818302822 , Val-loss =  51.57670834189967 , Time for epoch =  0.015073776245117188 s\n",
      "Epoch  578 / 1000  : Train-loss =  48.47148520259534 , Val-loss =  51.60923907631322 , Time for epoch =  0.013689279556274414 s\n",
      "Epoch  579 / 1000  : Train-loss =  48.456957822465625 , Val-loss =  51.51784495303505 , Time for epoch =  0.013196945190429688 s\n",
      "Epoch  580 / 1000  : Train-loss =  48.41955266833979 , Val-loss =  51.54777828015779 , Time for epoch =  0.014425039291381836 s\n",
      "Epoch  581 / 1000  : Train-loss =  48.40189557695119 , Val-loss =  51.45926706414474 , Time for epoch =  0.013634204864501953 s\n",
      "Epoch  582 / 1000  : Train-loss =  48.366212403033416 , Val-loss =  51.48736672652395 , Time for epoch =  0.014024734497070312 s\n",
      "Epoch  583 / 1000  : Train-loss =  48.34626567431089 , Val-loss =  51.400958613345495 , Time for epoch =  0.013878583908081055 s\n",
      "Epoch  584 / 1000  : Train-loss =  48.31195486467437 , Val-loss =  51.42780022872122 , Time for epoch =  0.015513181686401367 s\n",
      "Epoch  585 / 1000  : Train-loss =  48.290327751030354 , Val-loss =  51.342973608719674 , Time for epoch =  0.01743483543395996 s\n",
      "Epoch  586 / 1000  : Train-loss =  48.25714152276853 , Val-loss =  51.3688396654631 , Time for epoch =  0.014011383056640625 s\n",
      "Epoch  587 / 1000  : Train-loss =  48.234277757547666 , Val-loss =  51.2852130689119 , Time for epoch =  0.013961553573608398 s\n",
      "Epoch  588 / 1000  : Train-loss =  48.20204899674755 , Val-loss =  51.31040452655993 , Time for epoch =  0.014017343521118164 s\n",
      "Epoch  589 / 1000  : Train-loss =  48.178243432341326 , Val-loss =  51.2276994805587 , Time for epoch =  0.014058351516723633 s\n",
      "Epoch  590 / 1000  : Train-loss =  48.1468563618633 , Val-loss =  51.25240607010691 , Time for epoch =  0.017421483993530273 s\n",
      "Epoch  591 / 1000  : Train-loss =  48.12234126376567 , Val-loss =  51.17040614077919 , Time for epoch =  0.014498710632324219 s\n",
      "Epoch  592 / 1000  : Train-loss =  48.09170780074125 , Val-loss =  51.19474912944593 , Time for epoch =  0.013661384582519531 s\n",
      "Epoch  593 / 1000  : Train-loss =  48.06662918349444 , Val-loss =  51.113322609349304 , Time for epoch =  0.013668060302734375 s\n",
      "Epoch  594 / 1000  : Train-loss =  48.03668553411624 , Val-loss =  51.137369657817636 , Time for epoch =  0.013091802597045898 s\n",
      "Epoch  595 / 1000  : Train-loss =  48.01115402394095 , Val-loss =  51.05648763556229 , Time for epoch =  0.014040470123291016 s\n",
      "Epoch  596 / 1000  : Train-loss =  47.98185958431265 , Val-loss =  51.08033411126388 , Time for epoch =  0.013545036315917969 s\n",
      "Epoch  597 / 1000  : Train-loss =  47.95597136761509 , Val-loss =  50.999838979620684 , Time for epoch =  0.013788223266601562 s\n",
      "Epoch  598 / 1000  : Train-loss =  47.927284348482466 , Val-loss =  51.02354933086195 , Time for epoch =  0.014256954193115234 s\n",
      "Epoch  599 / 1000  : Train-loss =  47.90108358523266 , Val-loss =  50.94342683490954 , Time for epoch =  0.013499975204467773 s\n",
      "Epoch  600 / 1000  : Train-loss =  47.872992973543155 , Val-loss =  50.967047239604746 , Time for epoch =  0.013584136962890625 s\n",
      "Epoch  601 / 1000  : Train-loss =  47.846544556698554 , Val-loss =  50.88722128617136 , Time for epoch =  0.013684749603271484 s\n",
      "Epoch  602 / 1000  : Train-loss =  47.81900233468093 , Val-loss =  50.91077684101305 , Time for epoch =  0.013953208923339844 s\n",
      "Epoch  603 / 1000  : Train-loss =  47.79233770855402 , Val-loss =  50.83124642623098 , Time for epoch =  0.014315128326416016 s\n",
      "Epoch  604 / 1000  : Train-loss =  47.76533986754337 , Val-loss =  50.85475138614052 , Time for epoch =  0.015724658966064453 s\n",
      "Epoch  605 / 1000  : Train-loss =  47.73847482972226 , Val-loss =  50.77446144505551 , Time for epoch =  0.013340950012207031 s\n",
      "Epoch  606 / 1000  : Train-loss =  47.71201925762629 , Val-loss =  50.797019356175475 , Time for epoch =  0.013344526290893555 s\n",
      "Epoch  607 / 1000  : Train-loss =  47.684977429061284 , Val-loss =  50.71682558561626 , Time for epoch =  0.013483047485351562 s\n",
      "Epoch  608 / 1000  : Train-loss =  47.65903972905908 , Val-loss =  50.73941140425833 , Time for epoch =  0.01419210433959961 s\n",
      "Epoch  609 / 1000  : Train-loss =  47.631849191956604 , Val-loss =  50.65941559640985 , Time for epoch =  0.01548624038696289 s\n",
      "Epoch  610 / 1000  : Train-loss =  47.60640580775374 , Val-loss =  50.682007237484584 , Time for epoch =  0.0172426700592041 s\n",
      "Epoch  611 / 1000  : Train-loss =  47.57907281218276 , Val-loss =  50.60222384804174 , Time for epoch =  0.017675161361694336 s\n",
      "Epoch  612 / 1000  : Train-loss =  47.55413163179732 , Val-loss =  50.62484921907124 , Time for epoch =  0.0205843448638916 s\n",
      "Epoch  613 / 1000  : Train-loss =  47.52665934589623 , Val-loss =  50.54524110492907 , Time for epoch =  0.014718055725097656 s\n",
      "Epoch  614 / 1000  : Train-loss =  47.50221230889444 , Val-loss =  50.56789859972502 , Time for epoch =  0.013954401016235352 s\n",
      "Epoch  615 / 1000  : Train-loss =  47.47462726312842 , Val-loss =  50.48848362972862 , Time for epoch =  0.013645648956298828 s\n",
      "Epoch  616 / 1000  : Train-loss =  47.45064673989506 , Val-loss =  50.511181480006165 , Time for epoch =  0.01395273208618164 s\n",
      "Epoch  617 / 1000  : Train-loss =  47.390652737375035 , Val-loss =  50.518287457917864 , Time for epoch =  0.014010906219482422 s\n",
      "Epoch  618 / 1000  : Train-loss =  47.388449889791886 , Val-loss =  50.41330056441458 , Time for epoch =  0.01871204376220703 s\n",
      "Epoch  619 / 1000  : Train-loss =  47.3493855147712 , Val-loss =  50.45220264635588 , Time for epoch =  0.02432990074157715 s\n",
      "Epoch  620 / 1000  : Train-loss =  47.34168726172151 , Val-loss =  50.35185261776573 , Time for epoch =  0.016738176345825195 s\n",
      "Epoch  621 / 1000  : Train-loss =  47.30587645708504 , Val-loss =  50.38748470105623 , Time for epoch =  0.013805150985717773 s\n",
      "Epoch  622 / 1000  : Train-loss =  47.29391427767479 , Val-loss =  50.29192512913754 , Time for epoch =  0.014535188674926758 s\n",
      "Epoch  623 / 1000  : Train-loss =  47.260591517733985 , Val-loss =  50.32551795557926 , Time for epoch =  0.013108015060424805 s\n",
      "Epoch  624 / 1000  : Train-loss =  47.245560252733824 , Val-loss =  50.23345927188271 , Time for epoch =  0.012852191925048828 s\n",
      "Epoch  625 / 1000  : Train-loss =  47.21416699684272 , Val-loss =  50.265621386076276 , Time for epoch =  0.014430522918701172 s\n",
      "Epoch  626 / 1000  : Train-loss =  47.19689557781327 , Val-loss =  50.17614043386359 , Time for epoch =  0.013280153274536133 s\n",
      "Epoch  627 / 1000  : Train-loss =  47.167047058795134 , Val-loss =  50.207283421566615 , Time for epoch =  0.013677358627319336 s\n",
      "Epoch  628 / 1000  : Train-loss =  47.148116375766904 , Val-loss =  50.11967729267321 , Time for epoch =  0.014196634292602539 s\n",
      "Epoch  629 / 1000  : Train-loss =  47.11954011216675 , Val-loss =  50.15003826743678 , Time for epoch =  0.014377593994140625 s\n",
      "Epoch  630 / 1000  : Train-loss =  47.099362195548366 , Val-loss =  50.063842371890416 , Time for epoch =  0.013859272003173828 s\n",
      "Epoch  631 / 1000  : Train-loss =  47.07186671973622 , Val-loss =  50.09367410760177 , Time for epoch =  0.013797521591186523 s\n",
      "Epoch  632 / 1000  : Train-loss =  47.05072719767942 , Val-loss =  50.00857865182977 , Time for epoch =  0.01826310157775879 s\n",
      "Epoch  633 / 1000  : Train-loss =  47.02418500824837 , Val-loss =  50.03792933413857 , Time for epoch =  0.020371675491333008 s\n",
      "Epoch  634 / 1000  : Train-loss =  47.00228575798078 , Val-loss =  49.953654640599304 , Time for epoch =  0.021552324295043945 s\n",
      "Epoch  635 / 1000  : Train-loss =  46.97658836235434 , Val-loss =  49.982703359503496 , Time for epoch =  0.021363019943237305 s\n",
      "Epoch  636 / 1000  : Train-loss =  46.954078221725204 , Val-loss =  49.89908379002621 , Time for epoch =  0.02294635772705078 s\n",
      "Epoch  637 / 1000  : Train-loss =  46.929161524368546 , Val-loss =  49.9278947930587 , Time for epoch =  0.020715951919555664 s\n",
      "Epoch  638 / 1000  : Train-loss =  46.906150386831854 , Val-loss =  49.84481630827251 , Time for epoch =  0.013858318328857422 s\n",
      "Epoch  639 / 1000  : Train-loss =  46.88194749045507 , Val-loss =  49.873388591565586 , Time for epoch =  0.013617277145385742 s\n",
      "Epoch  640 / 1000  : Train-loss =  46.85850882664912 , Val-loss =  49.79078834935238 , Time for epoch =  0.014352083206176758 s\n",
      "Epoch  641 / 1000  : Train-loss =  46.834973997988946 , Val-loss =  49.819195195248255 , Time for epoch =  0.014655113220214844 s\n",
      "Epoch  642 / 1000  : Train-loss =  46.81117123533777 , Val-loss =  49.73695795159591 , Time for epoch =  0.013991355895996094 s\n",
      "Epoch  643 / 1000  : Train-loss =  46.78829242684747 , Val-loss =  49.765270032380755 , Time for epoch =  0.015262603759765625 s\n",
      "Epoch  644 / 1000  : Train-loss =  46.764171147750595 , Val-loss =  49.683386150159336 , Time for epoch =  0.03176236152648926 s\n",
      "Epoch  645 / 1000  : Train-loss =  46.74189807870294 , Val-loss =  49.7115757590846 , Time for epoch =  0.02022099494934082 s\n",
      "Epoch  646 / 1000  : Train-loss =  46.717477184231 , Val-loss =  49.62999424181486 , Time for epoch =  0.014588117599487305 s\n",
      "Epoch  647 / 1000  : Train-loss =  46.695802677822655 , Val-loss =  49.65811558773643 , Time for epoch =  0.012866497039794922 s\n",
      "Epoch  648 / 1000  : Train-loss =  46.67113025040276 , Val-loss =  49.576798689992806 , Time for epoch =  0.013039350509643555 s\n",
      "Epoch  649 / 1000  : Train-loss =  46.65001990970245 , Val-loss =  49.60487847579153 , Time for epoch =  0.01301121711730957 s\n",
      "Epoch  650 / 1000  : Train-loss =  46.592951111874335 , Val-loss =  49.61451138948139 , Time for epoch =  0.016252517700195312 s\n",
      "Epoch  651 / 1000  : Train-loss =  46.59743417858404 , Val-loss =  49.49876082570929 , Time for epoch =  0.01526188850402832 s\n",
      "Epoch  652 / 1000  : Train-loss =  46.56560089628575 , Val-loss =  49.53228579069439 , Time for epoch =  0.016910314559936523 s\n",
      "Epoch  653 / 1000  : Train-loss =  46.56550003310382 , Val-loss =  49.42003691823859 , Time for epoch =  0.014193534851074219 s\n",
      "Epoch  654 / 1000  : Train-loss =  46.53416037694209 , Val-loss =  49.45292904502467 , Time for epoch =  0.013829469680786133 s\n",
      "Epoch  655 / 1000  : Train-loss =  46.53109133445611 , Val-loss =  49.34462798269171 , Time for epoch =  0.01381826400756836 s\n",
      "Epoch  656 / 1000  : Train-loss =  46.499057058560645 , Val-loss =  49.379094776354336 , Time for epoch =  0.015876054763793945 s\n",
      "Epoch  657 / 1000  : Train-loss =  46.49497046174302 , Val-loss =  49.27271612066971 , Time for epoch =  0.013948917388916016 s\n",
      "Epoch  658 / 1000  : Train-loss =  46.46147015673966 , Val-loss =  49.30951911524723 , Time for epoch =  0.013591527938842773 s\n",
      "Epoch  659 / 1000  : Train-loss =  46.45764634299413 , Val-loss =  49.20352895636307 , Time for epoch =  0.013459205627441406 s\n",
      "Epoch  660 / 1000  : Train-loss =  46.45380871444099 , Val-loss =  49.15785438136051 , Time for epoch =  0.012857198715209961 s\n",
      "Epoch  661 / 1000  : Train-loss =  46.432407034319 , Val-loss =  49.1817771510074 , Time for epoch =  0.013098478317260742 s\n",
      "Epoch  662 / 1000  : Train-loss =  46.408995569089036 , Val-loss =  49.09680517096268 , Time for epoch =  0.01373910903930664 s\n",
      "Epoch  663 / 1000  : Train-loss =  46.382716529113424 , Val-loss =  49.128314771150286 , Time for epoch =  0.01474308967590332 s\n",
      "Epoch  664 / 1000  : Train-loss =  46.365793282029315 , Val-loss =  49.03697987606651 , Time for epoch =  0.01720142364501953 s\n",
      "Epoch  665 / 1000  : Train-loss =  46.33547361557093 , Val-loss =  49.07374412135074 , Time for epoch =  0.015135526657104492 s\n",
      "Epoch  666 / 1000  : Train-loss =  46.323814930888894 , Val-loss =  48.97700259560033 , Time for epoch =  0.01348733901977539 s\n",
      "Epoch  667 / 1000  : Train-loss =  46.28997263935326 , Val-loss =  49.0182991027832 , Time for epoch =  0.013496160507202148 s\n",
      "Epoch  668 / 1000  : Train-loss =  46.28270986524679 , Val-loss =  48.916995199103106 , Time for epoch =  0.013558626174926758 s\n",
      "Epoch  669 / 1000  : Train-loss =  46.278497383419406 , Val-loss =  48.87516704358553 , Time for epoch =  0.013834714889526367 s\n",
      "Epoch  670 / 1000  : Train-loss =  46.25422560697221 , Val-loss =  48.90557299162212 , Time for epoch =  0.014300823211669922 s\n",
      "Epoch  671 / 1000  : Train-loss =  46.23153341692046 , Val-loss =  48.82014304713199 , Time for epoch =  0.019015789031982422 s\n",
      "Epoch  672 / 1000  : Train-loss =  46.20217804989572 , Val-loss =  48.858579334459804 , Time for epoch =  0.016407012939453125 s\n",
      "Epoch  673 / 1000  : Train-loss =  46.18720251826917 , Val-loss =  48.765473215203535 , Time for epoch =  0.016308069229125977 s\n",
      "Epoch  674 / 1000  : Train-loss =  46.1538396932311 , Val-loss =  48.809216147974915 , Time for epoch =  0.02182316780090332 s\n",
      "Epoch  675 / 1000  : Train-loss =  46.14483396885759 , Val-loss =  48.70979630319696 , Time for epoch =  0.017841577529907227 s\n",
      "Epoch  676 / 1000  : Train-loss =  46.14066769443663 , Val-loss =  48.66954482229132 , Time for epoch =  0.023976564407348633 s\n",
      "Epoch  677 / 1000  : Train-loss =  46.11595610710187 , Val-loss =  48.703245865671256 , Time for epoch =  0.02086806297302246 s\n",
      "Epoch  678 / 1000  : Train-loss =  46.093219821735964 , Val-loss =  48.61778761211195 , Time for epoch =  0.0203704833984375 s\n",
      "Epoch  679 / 1000  : Train-loss =  46.06345380362818 , Val-loss =  48.659500523617396 , Time for epoch =  0.0159912109375 s\n",
      "Epoch  680 / 1000  : Train-loss =  46.04883321126302 , Val-loss =  48.56587881790964 , Time for epoch =  0.013783931732177734 s\n",
      "Epoch  681 / 1000  : Train-loss =  46.04457786258331 , Val-loss =  48.52645693327251 , Time for epoch =  0.01399993896484375 s\n",
      "Epoch  682 / 1000  : Train-loss =  46.0220665150443 , Val-loss =  48.56011782194439 , Time for epoch =  0.014057159423828125 s\n",
      "Epoch  683 / 1000  : Train-loss =  45.99596577444993 , Val-loss =  48.4780014439633 , Time for epoch =  0.015020370483398438 s\n",
      "Epoch  684 / 1000  : Train-loss =  45.96843258270436 , Val-loss =  48.5194350794742 , Time for epoch =  0.018923282623291016 s\n",
      "Epoch  685 / 1000  : Train-loss =  45.95116681028894 , Val-loss =  48.42825257150751 , Time for epoch =  0.014223575592041016 s\n",
      "Epoch  686 / 1000  : Train-loss =  45.91958016864324 , Val-loss =  48.47501895302221 , Time for epoch =  0.01390528678894043 s\n",
      "Epoch  687 / 1000  : Train-loss =  45.908970784332794 , Val-loss =  48.376740305047285 , Time for epoch =  0.013759374618530273 s\n",
      "Epoch  688 / 1000  : Train-loss =  45.90544654285841 , Val-loss =  48.33757179661801 , Time for epoch =  0.014266729354858398 s\n",
      "Epoch  689 / 1000  : Train-loss =  45.8819167142534 , Val-loss =  48.374923304507604 , Time for epoch =  0.01548004150390625 s\n",
      "Epoch  690 / 1000  : Train-loss =  45.858655315334516 , Val-loss =  48.28948633294357 , Time for epoch =  0.016475439071655273 s\n",
      "Epoch  691 / 1000  : Train-loss =  45.83027312715175 , Val-loss =  48.33438130428917 , Time for epoch =  0.013891935348510742 s\n",
      "Epoch  692 / 1000  : Train-loss =  45.81517627953136 , Val-loss =  48.24062708804482 , Time for epoch =  0.013704538345336914 s\n",
      "Epoch  693 / 1000  : Train-loss =  45.81166108988099 , Val-loss =  48.20193621986791 , Time for epoch =  0.014009714126586914 s\n",
      "Epoch  694 / 1000  : Train-loss =  45.790347600387314 , Val-loss =  48.23901708502518 , Time for epoch =  0.013892889022827148 s\n",
      "Epoch  695 / 1000  : Train-loss =  45.7641897255418 , Val-loss =  48.15646000912315 , Time for epoch =  0.013880014419555664 s\n",
      "Epoch  696 / 1000  : Train-loss =  45.73809420052221 , Val-loss =  48.20076049001593 , Time for epoch =  0.01644134521484375 s\n",
      "Epoch  697 / 1000  : Train-loss =  45.720581550382626 , Val-loss =  48.109291076660156 , Time for epoch =  0.014057159423828125 s\n",
      "Epoch  698 / 1000  : Train-loss =  45.690675056586834 , Val-loss =  48.158516331722865 , Time for epoch =  0.014241218566894531 s\n",
      "Epoch  699 / 1000  : Train-loss =  45.6797406902421 , Val-loss =  48.05813578555458 , Time for epoch =  0.013593435287475586 s\n",
      "Epoch  700 / 1000  : Train-loss =  45.67809093065855 , Val-loss =  48.01994765432257 , Time for epoch =  0.016583919525146484 s\n",
      "Epoch  701 / 1000  : Train-loss =  45.65614127035195 , Val-loss =  48.05790148283306 , Time for epoch =  0.013437747955322266 s\n",
      "Epoch  702 / 1000  : Train-loss =  45.63355479267357 , Val-loss =  47.9711406105443 , Time for epoch =  0.013864278793334961 s\n",
      "Epoch  703 / 1000  : Train-loss =  45.607810995673056 , Val-loss =  48.01683626676861 , Time for epoch =  0.017688989639282227 s\n",
      "Epoch  704 / 1000  : Train-loss =  45.59299818135924 , Val-loss =  47.922337983783926 , Time for epoch =  0.014389991760253906 s\n",
      "Epoch  705 / 1000  : Train-loss =  45.56358397747837 , Val-loss =  47.97419558073345 , Time for epoch =  0.013863801956176758 s\n",
      "Epoch  706 / 1000  : Train-loss =  45.55395027203748 , Val-loss =  47.87277442530582 , Time for epoch =  0.014113664627075195 s\n",
      "Epoch  707 / 1000  : Train-loss =  45.552648296463964 , Val-loss =  47.83325355931332 , Time for epoch =  0.01477670669555664 s\n",
      "Epoch  708 / 1000  : Train-loss =  45.53103484676382 , Val-loss =  47.87587597495631 , Time for epoch =  0.013784408569335938 s\n",
      "Epoch  709 / 1000  : Train-loss =  45.5088896670584 , Val-loss =  47.78728023328279 , Time for epoch =  0.013792753219604492 s\n",
      "Epoch  710 / 1000  : Train-loss =  45.48247028070654 , Val-loss =  47.83506293045847 , Time for epoch =  0.015118598937988281 s\n",
      "Epoch  711 / 1000  : Train-loss =  45.469007395081604 , Val-loss =  47.73969449495014 , Time for epoch =  0.017151832580566406 s\n",
      "Epoch  712 / 1000  : Train-loss =  45.46764871629618 , Val-loss =  47.702614633660566 , Time for epoch =  0.01418757438659668 s\n",
      "Epoch  713 / 1000  : Train-loss =  45.44680010262182 , Val-loss =  47.74198351408306 , Time for epoch =  0.013534784317016602 s\n",
      "Epoch  714 / 1000  : Train-loss =  45.4227624020334 , Val-loss =  47.65745644820364 , Time for epoch =  0.013668537139892578 s\n",
      "Epoch  715 / 1000  : Train-loss =  45.39828486900545 , Val-loss =  47.70614844874332 , Time for epoch =  0.013749361038208008 s\n",
      "Epoch  716 / 1000  : Train-loss =  45.381771841965154 , Val-loss =  47.61229525114361 , Time for epoch =  0.014303445816040039 s\n",
      "Epoch  717 / 1000  : Train-loss =  45.3535229311151 , Val-loss =  47.66347885131836 , Time for epoch =  0.022869110107421875 s\n",
      "Epoch  718 / 1000  : Train-loss =  45.34424073817366 , Val-loss =  47.564170034308184 , Time for epoch =  0.02041482925415039 s\n",
      "Epoch  719 / 1000  : Train-loss =  45.34357935156526 , Val-loss =  47.52716727005808 , Time for epoch =  0.020447969436645508 s\n",
      "Epoch  720 / 1000  : Train-loss =  45.32160376424844 , Val-loss =  47.56881432784231 , Time for epoch =  0.014673471450805664 s\n",
      "Epoch  721 / 1000  : Train-loss =  45.300589825473935 , Val-loss =  47.48150554456209 , Time for epoch =  0.013766050338745117 s\n",
      "Epoch  722 / 1000  : Train-loss =  45.27501646138854 , Val-loss =  47.530517578125 , Time for epoch =  0.013880729675292969 s\n",
      "Epoch  723 / 1000  : Train-loss =  45.26170553864732 , Val-loss =  47.435776359156556 , Time for epoch =  0.013539314270019531 s\n",
      "Epoch  724 / 1000  : Train-loss =  45.26099639289123 , Val-loss =  47.39920064022667 , Time for epoch =  0.014009952545166016 s\n",
      "Epoch  725 / 1000  : Train-loss =  45.24069537146617 , Val-loss =  47.44019819560804 , Time for epoch =  0.015995264053344727 s\n",
      "Epoch  726 / 1000  : Train-loss =  45.21720853902526 , Val-loss =  47.35578536987305 , Time for epoch =  0.013522148132324219 s\n",
      "Epoch  727 / 1000  : Train-loss =  45.19339478487349 , Val-loss =  47.403894123278164 , Time for epoch =  0.013132572174072266 s\n",
      "Epoch  728 / 1000  : Train-loss =  45.17819425076414 , Val-loss =  47.31356450131065 , Time for epoch =  0.01377415657043457 s\n",
      "Epoch  729 / 1000  : Train-loss =  45.176502788134215 , Val-loss =  47.27410386738024 , Time for epoch =  0.015565633773803711 s\n",
      "Epoch  730 / 1000  : Train-loss =  45.15873489810922 , Val-loss =  47.31565114071495 , Time for epoch =  0.014595746994018555 s\n",
      "Epoch  731 / 1000  : Train-loss =  45.13394074520822 , Val-loss =  47.232846109490644 , Time for epoch =  0.01572394371032715 s\n",
      "Epoch  732 / 1000  : Train-loss =  45.111485648289914 , Val-loss =  47.28242311979595 , Time for epoch =  0.014068365097045898 s\n",
      "Epoch  733 / 1000  : Train-loss =  45.09427681615797 , Val-loss =  47.19030581022564 , Time for epoch =  0.013790607452392578 s\n",
      "Epoch  734 / 1000  : Train-loss =  45.06803012567725 , Val-loss =  47.24201804713199 , Time for epoch =  0.014327526092529297 s\n",
      "Epoch  735 / 1000  : Train-loss =  45.05825866009556 , Val-loss =  47.14453185232062 , Time for epoch =  0.013780832290649414 s\n",
      "Epoch  736 / 1000  : Train-loss =  45.05855650820975 , Val-loss =  47.107884858783926 , Time for epoch =  0.014124631881713867 s\n",
      "Epoch  737 / 1000  : Train-loss =  45.03803791972877 , Val-loss =  47.150876697741054 , Time for epoch =  0.014267206192016602 s\n",
      "Epoch  738 / 1000  : Train-loss =  45.01710727928722 , Val-loss =  47.064551303261204 , Time for epoch =  0.017310380935668945 s\n",
      "Epoch  739 / 1000  : Train-loss =  44.993168847035555 , Val-loss =  47.114422246029505 , Time for epoch =  0.01577615737915039 s\n",
      "Epoch  740 / 1000  : Train-loss =  44.97991145936783 , Val-loss =  47.0231943632427 , Time for epoch =  0.01343226432800293 s\n",
      "Epoch  741 / 1000  : Train-loss =  44.9789913845601 , Val-loss =  46.98372308831466 , Time for epoch =  0.013627767562866211 s\n",
      "Epoch  742 / 1000  : Train-loss =  44.96124364561954 , Val-loss =  47.02702371697677 , Time for epoch =  0.01311182975769043 s\n",
      "Epoch  743 / 1000  : Train-loss =  44.93812821813896 , Val-loss =  46.94334271079615 , Time for epoch =  0.013664722442626953 s\n",
      "Epoch  744 / 1000  : Train-loss =  44.91572480282541 , Val-loss =  46.9944425884046 , Time for epoch =  0.014220714569091797 s\n",
      "Epoch  745 / 1000  : Train-loss =  44.899863981257724 , Val-loss =  46.901897831967005 , Time for epoch =  0.015400171279907227 s\n",
      "Epoch  746 / 1000  : Train-loss =  44.900168100992836 , Val-loss =  46.863686411004316 , Time for epoch =  0.013533353805541992 s\n",
      "Epoch  747 / 1000  : Train-loss =  44.883563973809366 , Val-loss =  46.90666198730469 , Time for epoch =  0.013628244400024414 s\n",
      "Epoch  748 / 1000  : Train-loss =  44.85929230512199 , Val-loss =  46.826820373535156 , Time for epoch =  0.013933897018432617 s\n",
      "Epoch  749 / 1000  : Train-loss =  44.836908523645775 , Val-loss =  46.87427179436935 , Time for epoch =  0.014485597610473633 s\n",
      "Epoch  750 / 1000  : Train-loss =  44.82117110861223 , Val-loss =  46.78403111508018 , Time for epoch =  0.01390838623046875 s\n",
      "Epoch  751 / 1000  : Train-loss =  44.796221673825364 , Val-loss =  46.836298290051914 , Time for epoch =  0.016254901885986328 s\n",
      "Epoch  752 / 1000  : Train-loss =  44.786783660199006 , Val-loss =  46.74005809583162 , Time for epoch =  0.013608217239379883 s\n",
      "Epoch  753 / 1000  : Train-loss =  44.78796977242507 , Val-loss =  46.70371266415245 , Time for epoch =  0.013479948043823242 s\n",
      "Epoch  754 / 1000  : Train-loss =  44.768395009013894 , Val-loss =  46.747974596525495 , Time for epoch =  0.014114856719970703 s\n",
      "Epoch  755 / 1000  : Train-loss =  44.74817075567731 , Val-loss =  46.662375600714434 , Time for epoch =  0.014225244522094727 s\n",
      "Epoch  756 / 1000  : Train-loss =  44.725305697338726 , Val-loss =  46.71300847906815 , Time for epoch =  0.016042232513427734 s\n",
      "Epoch  757 / 1000  : Train-loss =  44.68408397092657 , Val-loss =  46.45485406172903 , Time for epoch =  0.013894796371459961 s\n",
      "Epoch  758 / 1000  : Train-loss =  44.75888798600536 , Val-loss =  46.600756996556335 , Time for epoch =  0.01467585563659668 s\n",
      "Epoch  759 / 1000  : Train-loss =  44.76659296326718 , Val-loss =  46.5980483607242 , Time for epoch =  0.013903141021728516 s\n",
      "Epoch  760 / 1000  : Train-loss =  44.75361010449081 , Val-loss =  46.532445204885384 , Time for epoch =  0.013883590698242188 s\n",
      "Epoch  761 / 1000  : Train-loss =  44.74305718632068 , Val-loss =  46.61323005274723 , Time for epoch =  0.013857603073120117 s\n",
      "Epoch  762 / 1000  : Train-loss =  44.73819321023542 , Val-loss =  46.55561667994449 , Time for epoch =  0.014128446578979492 s\n",
      "Epoch  763 / 1000  : Train-loss =  44.72111929338531 , Val-loss =  46.632899033395866 , Time for epoch =  0.014002084732055664 s\n",
      "Epoch  764 / 1000  : Train-loss =  44.72182374081369 , Val-loss =  46.56743200201737 , Time for epoch =  0.01403355598449707 s\n",
      "Epoch  765 / 1000  : Train-loss =  44.73001501654501 , Val-loss =  46.547181581196035 , Time for epoch =  0.01570725440979004 s\n",
      "Epoch  766 / 1000  : Train-loss =  44.715697337005096 , Val-loss =  46.614035957737975 , Time for epoch =  0.014471054077148438 s\n",
      "Epoch  767 / 1000  : Train-loss =  44.70216192902818 , Val-loss =  46.546167072496914 , Time for epoch =  0.013569355010986328 s\n",
      "Epoch  768 / 1000  : Train-loss =  44.68248535414874 , Val-loss =  46.611222518117806 , Time for epoch =  0.013729572296142578 s\n",
      "Epoch  769 / 1000  : Train-loss =  44.67512288066627 , Val-loss =  46.53328985916941 , Time for epoch =  0.013731718063354492 s\n",
      "Epoch  770 / 1000  : Train-loss =  44.67961368453031 , Val-loss =  46.49966249967876 , Time for epoch =  0.013574600219726562 s\n",
      "Epoch  771 / 1000  : Train-loss =  44.66464063137938 , Val-loss =  46.558868408203125 , Time for epoch =  0.013220787048339844 s\n",
      "Epoch  772 / 1000  : Train-loss =  44.64596475719732 , Val-loss =  46.481546903911386 , Time for epoch =  0.014081001281738281 s\n",
      "Epoch  773 / 1000  : Train-loss =  44.62483355419784 , Val-loss =  46.53629664370888 , Time for epoch =  0.01941680908203125 s\n",
      "Epoch  774 / 1000  : Train-loss =  44.61564808646165 , Val-loss =  46.45315451371042 , Time for epoch =  0.014252901077270508 s\n",
      "Epoch  775 / 1000  : Train-loss =  44.618567989370916 , Val-loss =  46.416422392192636 , Time for epoch =  0.01383662223815918 s\n",
      "Epoch  776 / 1000  : Train-loss =  44.601271958000915 , Val-loss =  46.46736064710115 , Time for epoch =  0.013756752014160156 s\n",
      "Epoch  777 / 1000  : Train-loss =  44.58226877417268 , Val-loss =  46.387080543919616 , Time for epoch =  0.013874292373657227 s\n",
      "Epoch  778 / 1000  : Train-loss =  44.56036676525396 , Val-loss =  46.43834846898129 , Time for epoch =  0.014030933380126953 s\n",
      "Epoch  779 / 1000  : Train-loss =  44.550219433455815 , Val-loss =  46.35230235049599 , Time for epoch =  0.014542579650878906 s\n",
      "Epoch  780 / 1000  : Train-loss =  44.55258933029606 , Val-loss =  46.313104930676914 , Time for epoch =  0.016030073165893555 s\n",
      "Epoch  781 / 1000  : Train-loss =  44.53460512322894 , Val-loss =  46.36216414602179 , Time for epoch =  0.013664007186889648 s\n",
      "Epoch  782 / 1000  : Train-loss =  44.515334673520535 , Val-loss =  46.2800871196546 , Time for epoch =  0.013468503952026367 s\n",
      "Epoch  783 / 1000  : Train-loss =  44.492950116173695 , Val-loss =  46.33006286621094 , Time for epoch =  0.014592170715332031 s\n",
      "Epoch  784 / 1000  : Train-loss =  44.48277306422002 , Val-loss =  46.245274794729134 , Time for epoch =  0.014448404312133789 s\n",
      "Epoch  785 / 1000  : Train-loss =  44.48375667421158 , Val-loss =  46.201601931923314 , Time for epoch =  0.014015674591064453 s\n",
      "Epoch  786 / 1000  : Train-loss =  44.46677362043305 , Val-loss =  46.25093138845343 , Time for epoch =  0.014934539794921875 s\n",
      "Epoch  787 / 1000  : Train-loss =  44.447680694235245 , Val-loss =  46.16812073557001 , Time for epoch =  0.01612567901611328 s\n",
      "Epoch  788 / 1000  : Train-loss =  44.42498158600371 , Val-loss =  46.22019476639597 , Time for epoch =  0.014978408813476562 s\n",
      "Epoch  789 / 1000  : Train-loss =  44.414091401180976 , Val-loss =  46.131127407676296 , Time for epoch =  0.014281749725341797 s\n",
      "Epoch  790 / 1000  : Train-loss =  44.416358818442134 , Val-loss =  46.088311647114004 , Time for epoch =  0.013821840286254883 s\n",
      "Epoch  791 / 1000  : Train-loss =  44.399051666259766 , Val-loss =  46.13764833149157 , Time for epoch =  0.013634204864501953 s\n",
      "Epoch  792 / 1000  : Train-loss =  44.38037607225321 , Val-loss =  46.05716283697831 , Time for epoch =  0.013735771179199219 s\n",
      "Epoch  793 / 1000  : Train-loss =  44.35609485604669 , Val-loss =  46.105917278089024 , Time for epoch =  0.015983104705810547 s\n",
      "Epoch  794 / 1000  : Train-loss =  44.34686710336114 , Val-loss =  46.017696581388776 , Time for epoch =  0.01372075080871582 s\n",
      "Epoch  795 / 1000  : Train-loss =  44.349239478677006 , Val-loss =  45.97499486019737 , Time for epoch =  0.013659954071044922 s\n",
      "Epoch  796 / 1000  : Train-loss =  44.33166340111339 , Val-loss =  46.026981152986224 , Time for epoch =  0.013796806335449219 s\n",
      "Epoch  797 / 1000  : Train-loss =  44.3125028879629 , Val-loss =  45.9426259492573 , Time for epoch =  0.013396501541137695 s\n",
      "Epoch  798 / 1000  : Train-loss =  44.28928657574842 , Val-loss =  45.992756492213196 , Time for epoch =  0.013140678405761719 s\n",
      "Epoch  799 / 1000  : Train-loss =  44.28050921596376 , Val-loss =  45.90458117033306 , Time for epoch =  0.013301372528076172 s\n",
      "Epoch  800 / 1000  : Train-loss =  44.28302885583565 , Val-loss =  45.86458888806795 , Time for epoch =  0.014247894287109375 s\n",
      "Epoch  801 / 1000  : Train-loss =  44.26379114355745 , Val-loss =  45.91349571629574 , Time for epoch =  0.01363682746887207 s\n",
      "Epoch  802 / 1000  : Train-loss =  44.24649190094512 , Val-loss =  45.830159639057364 , Time for epoch =  0.013631343841552734 s\n",
      "Epoch  803 / 1000  : Train-loss =  44.22300724525236 , Val-loss =  45.8807124087685 , Time for epoch =  0.014226436614990234 s\n",
      "Epoch  804 / 1000  : Train-loss =  44.21479301668156 , Val-loss =  45.7926159908897 , Time for epoch =  0.013998985290527344 s\n",
      "Epoch  805 / 1000  : Train-loss =  44.21752431837179 , Val-loss =  45.75281444348787 , Time for epoch =  0.013769865036010742 s\n",
      "Epoch  806 / 1000  : Train-loss =  44.197914317502814 , Val-loss =  45.802188873291016 , Time for epoch =  0.013714790344238281 s\n",
      "Epoch  807 / 1000  : Train-loss =  44.181269090727895 , Val-loss =  45.71892085828279 , Time for epoch =  0.014266014099121094 s\n",
      "Epoch  808 / 1000  : Train-loss =  44.157486630024884 , Val-loss =  45.769859313964844 , Time for epoch =  0.017181873321533203 s\n",
      "Epoch  809 / 1000  : Train-loss =  44.149910878326935 , Val-loss =  45.684451053017064 , Time for epoch =  0.013561248779296875 s\n",
      "Epoch  810 / 1000  : Train-loss =  44.15152410733498 , Val-loss =  45.64111247815584 , Time for epoch =  0.013665437698364258 s\n",
      "Epoch  811 / 1000  : Train-loss =  44.13307314942786 , Val-loss =  45.69186381289833 , Time for epoch =  0.013048171997070312 s\n",
      "Epoch  812 / 1000  : Train-loss =  44.11704545101877 , Val-loss =  45.608700802451686 , Time for epoch =  0.012792587280273438 s\n",
      "Epoch  813 / 1000  : Train-loss =  44.11885506150413 , Val-loss =  45.57144185116417 , Time for epoch =  0.013320207595825195 s\n",
      "Epoch  814 / 1000  : Train-loss =  44.10275466832737 , Val-loss =  45.620603461014596 , Time for epoch =  0.013343572616577148 s\n",
      "Epoch  815 / 1000  : Train-loss =  44.08111529161701 , Val-loss =  45.54033058568051 , Time for epoch =  0.017186403274536133 s\n",
      "Epoch  816 / 1000  : Train-loss =  44.06045678779904 , Val-loss =  45.591272253739206 , Time for epoch =  0.013870954513549805 s\n",
      "Epoch  817 / 1000  : Train-loss =  44.04898765262237 , Val-loss =  45.50549336483604 , Time for epoch =  0.014249324798583984 s\n",
      "Epoch  818 / 1000  : Train-loss =  44.05166580717442 , Val-loss =  45.467328322561166 , Time for epoch =  0.01381993293762207 s\n",
      "Epoch  819 / 1000  : Train-loss =  44.03419602388716 , Val-loss =  45.51692520944696 , Time for epoch =  0.013640403747558594 s\n",
      "Epoch  820 / 1000  : Train-loss =  44.0156373492742 , Val-loss =  45.435266193590664 , Time for epoch =  0.01357269287109375 s\n",
      "Epoch  821 / 1000  : Train-loss =  43.99378997457903 , Val-loss =  45.48665839747379 , Time for epoch =  0.013570785522460938 s\n",
      "Epoch  822 / 1000  : Train-loss =  43.984737719519664 , Val-loss =  45.3999282435367 , Time for epoch =  0.015916824340820312 s\n",
      "Epoch  823 / 1000  : Train-loss =  43.987873896367134 , Val-loss =  45.361446581388776 , Time for epoch =  0.013650894165039062 s\n",
      "Epoch  824 / 1000  : Train-loss =  43.96942461951304 , Val-loss =  45.411616676732116 , Time for epoch =  0.01345062255859375 s\n",
      "Epoch  825 / 1000  : Train-loss =  43.95270034014168 , Val-loss =  45.32935493870785 , Time for epoch =  0.013656854629516602 s\n",
      "Epoch  826 / 1000  : Train-loss =  43.9300108871891 , Val-loss =  45.38123080604955 , Time for epoch =  0.013319015502929688 s\n",
      "Epoch  827 / 1000  : Train-loss =  43.922488282629324 , Val-loss =  45.29408665707237 , Time for epoch =  0.013306379318237305 s\n",
      "Epoch  828 / 1000  : Train-loss =  43.92592618694413 , Val-loss =  45.25558451602333 , Time for epoch =  0.013830184936523438 s\n",
      "Epoch  829 / 1000  : Train-loss =  43.90670640589827 , Val-loss =  45.306274012515416 , Time for epoch =  0.01659989356994629 s\n",
      "Epoch  830 / 1000  : Train-loss =  43.891275201140154 , Val-loss =  45.223791423596836 , Time for epoch =  0.014083623886108398 s\n",
      "Epoch  831 / 1000  : Train-loss =  43.89365811536541 , Val-loss =  45.18481846859581 , Time for epoch =  0.01362919807434082 s\n",
      "Epoch  832 / 1000  : Train-loss =  43.87944946720102 , Val-loss =  45.238540047093444 , Time for epoch =  0.013537406921386719 s\n",
      "Epoch  833 / 1000  : Train-loss =  43.85733984823281 , Val-loss =  45.1578224583676 , Time for epoch =  0.01426243782043457 s\n",
      "Epoch  834 / 1000  : Train-loss =  43.83711807337185 , Val-loss =  45.20972101311935 , Time for epoch =  0.01402425765991211 s\n",
      "Epoch  835 / 1000  : Train-loss =  43.826524206474005 , Val-loss =  45.12454083091334 , Time for epoch =  0.014136791229248047 s\n",
      "Epoch  836 / 1000  : Train-loss =  43.82977596649342 , Val-loss =  45.0872792695698 , Time for epoch =  0.015746593475341797 s\n",
      "Epoch  837 / 1000  : Train-loss =  43.81252995722711 , Val-loss =  45.13782922845138 , Time for epoch =  0.014103889465332031 s\n",
      "Epoch  838 / 1000  : Train-loss =  43.795095799332955 , Val-loss =  45.05667294953999 , Time for epoch =  0.01354074478149414 s\n",
      "Epoch  839 / 1000  : Train-loss =  43.77348969885185 , Val-loss =  45.10911339207699 , Time for epoch =  0.013702392578125 s\n",
      "Epoch  840 / 1000  : Train-loss =  43.76550012793245 , Val-loss =  45.02287131861637 , Time for epoch =  0.013308525085449219 s\n",
      "Epoch  841 / 1000  : Train-loss =  43.769200405832066 , Val-loss =  44.98527828015779 , Time for epoch =  0.013896703720092773 s\n",
      "Epoch  842 / 1000  : Train-loss =  43.750788672495695 , Val-loss =  45.036400042082136 , Time for epoch =  0.015758037567138672 s\n",
      "Epoch  843 / 1000  : Train-loss =  43.73536335142319 , Val-loss =  44.954594260767884 , Time for epoch =  0.02392721176147461 s\n",
      "Epoch  844 / 1000  : Train-loss =  43.73809592467917 , Val-loss =  44.91630935668945 , Time for epoch =  0.020119428634643555 s\n",
      "Epoch  845 / 1000  : Train-loss =  43.72442937301377 , Val-loss =  44.97065594321803 , Time for epoch =  0.015733957290649414 s\n",
      "Epoch  846 / 1000  : Train-loss =  43.7026451024632 , Val-loss =  44.89042784038343 , Time for epoch =  0.01376032829284668 s\n",
      "Epoch  847 / 1000  : Train-loss =  43.682960402494096 , Val-loss =  44.94290020591334 , Time for epoch =  0.013640165328979492 s\n",
      "Epoch  848 / 1000  : Train-loss =  43.6726813451045 , Val-loss =  44.858244243421055 , Time for epoch =  0.013607978820800781 s\n",
      "Epoch  849 / 1000  : Train-loss =  43.67627862617795 , Val-loss =  44.81890186510588 , Time for epoch =  0.013686180114746094 s\n",
      "Epoch  850 / 1000  : Train-loss =  43.660875740697826 , Val-loss =  44.87371886403937 , Time for epoch =  0.014712095260620117 s\n",
      "Epoch  851 / 1000  : Train-loss =  43.64258866390939 , Val-loss =  44.79199238827354 , Time for epoch =  0.01690840721130371 s\n",
      "Epoch  852 / 1000  : Train-loss =  43.62129743759242 , Val-loss =  44.84504659552323 , Time for epoch =  0.013923168182373047 s\n",
      "Epoch  853 / 1000  : Train-loss =  43.613859575347036 , Val-loss =  44.75923578362716 , Time for epoch =  0.013788461685180664 s\n",
      "Epoch  854 / 1000  : Train-loss =  43.617945180774406 , Val-loss =  44.72229606226871 , Time for epoch =  0.013790130615234375 s\n",
      "Epoch  855 / 1000  : Train-loss =  43.599697608732235 , Val-loss =  44.77399846127159 , Time for epoch =  0.014224529266357422 s\n",
      "Epoch  856 / 1000  : Train-loss =  43.58501973125221 , Val-loss =  44.69258519222862 , Time for epoch =  0.0167996883392334 s\n",
      "Epoch  857 / 1000  : Train-loss =  43.588135369079936 , Val-loss =  44.65485121074476 , Time for epoch =  0.014068603515625 s\n",
      "Epoch  858 / 1000  : Train-loss =  43.57452939997959 , Val-loss =  44.70987239636873 , Time for epoch =  0.013675928115844727 s\n",
      "Epoch  859 / 1000  : Train-loss =  43.55361569938013 , Val-loss =  44.629932604337995 , Time for epoch =  0.013491153717041016 s\n",
      "Epoch  860 / 1000  : Train-loss =  43.53398841383767 , Val-loss =  44.68305146066766 , Time for epoch =  0.013509750366210938 s\n",
      "Epoch  861 / 1000  : Train-loss =  43.52453246897897 , Val-loss =  44.59877897563734 , Time for epoch =  0.013288021087646484 s\n",
      "Epoch  862 / 1000  : Train-loss =  43.52849406441726 , Val-loss =  44.559968647203945 , Time for epoch =  0.013692617416381836 s\n",
      "Epoch  863 / 1000  : Train-loss =  43.50654291702529 , Val-loss =  44.69617602699682 , Time for epoch =  0.015221595764160156 s\n",
      "Epoch  864 / 1000  : Train-loss =  43.50820851730088 , Val-loss =  44.724464215730364 , Time for epoch =  0.014863252639770508 s\n",
      "Epoch  865 / 1000  : Train-loss =  43.52975998355844 , Val-loss =  44.79004849885639 , Time for epoch =  0.013216495513916016 s\n",
      "Epoch  866 / 1000  : Train-loss =  43.531010536150745 , Val-loss =  44.93315967760588 , Time for epoch =  0.01311492919921875 s\n",
      "Epoch  867 / 1000  : Train-loss =  43.52737120719953 , Val-loss =  44.934227190519636 , Time for epoch =  0.01306462287902832 s\n",
      "Epoch  868 / 1000  : Train-loss =  43.54094183108227 , Val-loss =  44.96227244326943 , Time for epoch =  0.013018131256103516 s\n",
      "Epoch  869 / 1000  : Train-loss =  43.53699163663185 , Val-loss =  45.07164262470446 , Time for epoch =  0.0133514404296875 s\n",
      "Epoch  870 / 1000  : Train-loss =  43.52670163084558 , Val-loss =  45.04124209755346 , Time for epoch =  0.016915559768676758 s\n",
      "Epoch  871 / 1000  : Train-loss =  43.5366904264116 , Val-loss =  45.04805655228464 , Time for epoch =  0.014019012451171875 s\n",
      "Epoch  872 / 1000  : Train-loss =  43.52762495999956 , Val-loss =  45.1325424595883 , Time for epoch =  0.013466835021972656 s\n",
      "Epoch  873 / 1000  : Train-loss =  43.51303471279683 , Val-loss =  45.083365189401725 , Time for epoch =  0.013808488845825195 s\n",
      "Epoch  874 / 1000  : Train-loss =  43.49611603472866 , Val-loss =  45.160356421219674 , Time for epoch =  0.013610124588012695 s\n",
      "Epoch  875 / 1000  : Train-loss =  43.491853660109356 , Val-loss =  45.096156672427526 , Time for epoch =  0.013895988464355469 s\n",
      "Epoch  876 / 1000  : Train-loss =  43.498813241215075 , Val-loss =  45.077671452572474 , Time for epoch =  0.014571905136108398 s\n",
      "Epoch  877 / 1000  : Train-loss =  43.480658019329866 , Val-loss =  45.14398534674393 , Time for epoch =  0.014087438583374023 s\n",
      "Epoch  878 / 1000  : Train-loss =  43.47078069051107 , Val-loss =  45.07432315224096 , Time for epoch =  0.015515565872192383 s\n",
      "Epoch  879 / 1000  : Train-loss =  43.47566330904341 , Val-loss =  45.04734380621659 , Time for epoch =  0.013155937194824219 s\n",
      "Epoch  880 / 1000  : Train-loss =  43.45896879293151 , Val-loss =  45.108979877672695 , Time for epoch =  0.013225555419921875 s\n",
      "Epoch  881 / 1000  : Train-loss =  43.44542426847469 , Val-loss =  45.03902756540399 , Time for epoch =  0.013364076614379883 s\n",
      "Epoch  882 / 1000  : Train-loss =  43.447613128834526 , Val-loss =  45.007261978952506 , Time for epoch =  0.013154983520507812 s\n",
      "Epoch  883 / 1000  : Train-loss =  43.431032881224894 , Val-loss =  45.06525240446392 , Time for epoch =  0.017093181610107422 s\n",
      "Epoch  884 / 1000  : Train-loss =  43.41545294637734 , Val-loss =  44.99030906275699 , Time for epoch =  0.013965606689453125 s\n",
      "Epoch  885 / 1000  : Train-loss =  43.41835457322288 , Val-loss =  44.95783113178454 , Time for epoch =  0.014211416244506836 s\n",
      "Epoch  886 / 1000  : Train-loss =  43.401947991322665 , Val-loss =  45.0163190741288 , Time for epoch =  0.013652324676513672 s\n",
      "Epoch  887 / 1000  : Train-loss =  43.38374184215136 , Val-loss =  44.93894577026367 , Time for epoch =  0.013617515563964844 s\n",
      "Epoch  888 / 1000  : Train-loss =  43.3862812236204 , Val-loss =  44.90520176134611 , Time for epoch =  0.013633966445922852 s\n",
      "Epoch  889 / 1000  : Train-loss =  43.37003563487597 , Val-loss =  44.95978184750206 , Time for epoch =  0.01353001594543457 s\n",
      "Epoch  890 / 1000  : Train-loss =  43.35233354299082 , Val-loss =  44.88588694522255 , Time for epoch =  0.01375579833984375 s\n",
      "Epoch  891 / 1000  : Train-loss =  43.35324357458427 , Val-loss =  44.85008601138466 , Time for epoch =  0.01456904411315918 s\n",
      "Epoch  892 / 1000  : Train-loss =  43.33722760044249 , Val-loss =  44.903940301192435 , Time for epoch =  0.020090103149414062 s\n",
      "Epoch  893 / 1000  : Train-loss =  43.319167358053605 , Val-loss =  44.82660313656456 , Time for epoch =  0.018208980560302734 s\n",
      "Epoch  894 / 1000  : Train-loss =  43.32142061567576 , Val-loss =  44.791847831324525 , Time for epoch =  0.018093585968017578 s\n",
      "Epoch  895 / 1000  : Train-loss =  43.30555007417323 , Val-loss =  44.848122245387025 , Time for epoch =  0.018991470336914062 s\n",
      "Epoch  896 / 1000  : Train-loss =  43.285917896335405 , Val-loss =  44.76932626021536 , Time for epoch =  0.016968965530395508 s\n",
      "Epoch  897 / 1000  : Train-loss =  43.2881944731804 , Val-loss =  44.734350304854544 , Time for epoch =  0.014656543731689453 s\n",
      "Epoch  898 / 1000  : Train-loss =  43.27246983846029 , Val-loss =  44.78775004336708 , Time for epoch =  0.01410055160522461 s\n",
      "Epoch  899 / 1000  : Train-loss =  43.25397601370084 , Val-loss =  44.710197047183385 , Time for epoch =  0.016638994216918945 s\n",
      "Epoch  900 / 1000  : Train-loss =  43.25627478906664 , Val-loss =  44.678151983963815 , Time for epoch =  0.014495849609375 s\n",
      "Epoch  901 / 1000  : Train-loss =  43.239023585777495 , Val-loss =  44.73034908896998 , Time for epoch =  0.014768362045288086 s\n",
      "Epoch  902 / 1000  : Train-loss =  43.22071420270844 , Val-loss =  44.65263567472759 , Time for epoch =  0.014973163604736328 s\n",
      "Epoch  903 / 1000  : Train-loss =  43.223070888196006 , Val-loss =  44.61768501683285 , Time for epoch =  0.014632701873779297 s\n",
      "Epoch  904 / 1000  : Train-loss =  43.207481276517534 , Val-loss =  44.67114679436935 , Time for epoch =  0.014747381210327148 s\n",
      "Epoch  905 / 1000  : Train-loss =  43.18907708636785 , Val-loss =  44.596643347489206 , Time for epoch =  0.018047332763671875 s\n",
      "Epoch  906 / 1000  : Train-loss =  43.22088196318028 , Val-loss =  44.59901207371762 , Time for epoch =  0.018792152404785156 s\n",
      "Epoch  907 / 1000  : Train-loss =  43.175222127451065 , Val-loss =  44.620406100624486 , Time for epoch =  0.019709110260009766 s\n",
      "Epoch  908 / 1000  : Train-loss =  43.187498965505824 , Val-loss =  44.575225026983965 , Time for epoch =  0.02039337158203125 s\n",
      "Epoch  909 / 1000  : Train-loss =  43.15897662491448 , Val-loss =  44.5061687670256 , Time for epoch =  0.016961336135864258 s\n",
      "Epoch  910 / 1000  : Train-loss =  43.17243907950019 , Val-loss =  44.59330689279657 , Time for epoch =  0.014130353927612305 s\n",
      "Epoch  911 / 1000  : Train-loss =  43.15532514065672 , Val-loss =  44.520784076891445 , Time for epoch =  0.01398015022277832 s\n",
      "Epoch  912 / 1000  : Train-loss =  43.15691496423409 , Val-loss =  44.484920702482526 , Time for epoch =  0.014211893081665039 s\n",
      "Epoch  913 / 1000  : Train-loss =  43.13973820142153 , Val-loss =  44.53667048404091 , Time for epoch =  0.014713287353515625 s\n",
      "Epoch  914 / 1000  : Train-loss =  43.12339666334249 , Val-loss =  44.45859065808748 , Time for epoch =  0.014651775360107422 s\n",
      "Epoch  915 / 1000  : Train-loss =  43.12506879386255 , Val-loss =  44.42479484959652 , Time for epoch =  0.014919757843017578 s\n",
      "Epoch  916 / 1000  : Train-loss =  43.106364794370144 , Val-loss =  44.47567427785773 , Time for epoch =  0.015913963317871094 s\n",
      "Epoch  917 / 1000  : Train-loss =  43.090777898238876 , Val-loss =  44.39787714104904 , Time for epoch =  0.015022516250610352 s\n",
      "Epoch  918 / 1000  : Train-loss =  43.092751411394886 , Val-loss =  44.36169453671104 , Time for epoch =  0.025470972061157227 s\n",
      "Epoch  919 / 1000  : Train-loss =  43.07571408977616 , Val-loss =  44.41470276682001 , Time for epoch =  0.01564621925354004 s\n",
      "Epoch  920 / 1000  : Train-loss =  43.06032988984706 , Val-loss =  44.33763664647152 , Time for epoch =  0.016345500946044922 s\n",
      "Epoch  921 / 1000  : Train-loss =  43.062447391660875 , Val-loss =  44.30512257626182 , Time for epoch =  0.018497467041015625 s\n",
      "Epoch  922 / 1000  : Train-loss =  43.0438051169875 , Val-loss =  44.35748371325041 , Time for epoch =  0.025580883026123047 s\n",
      "Epoch  923 / 1000  : Train-loss =  43.0288904481015 , Val-loss =  44.28061696102745 , Time for epoch =  0.02055072784423828 s\n",
      "Epoch  924 / 1000  : Train-loss =  43.03114831784351 , Val-loss =  44.24548841777601 , Time for epoch =  0.019073486328125 s\n",
      "Epoch  925 / 1000  : Train-loss =  43.01416004849019 , Val-loss =  44.29957480179636 , Time for epoch =  0.013643026351928711 s\n",
      "Epoch  926 / 1000  : Train-loss =  42.999286069708354 , Val-loss =  44.22323287160773 , Time for epoch =  0.014178991317749023 s\n",
      "Epoch  927 / 1000  : Train-loss =  43.00161809975145 , Val-loss =  44.19143034282484 , Time for epoch =  0.013685464859008789 s\n",
      "Epoch  928 / 1000  : Train-loss =  42.98295862661243 , Val-loss =  44.24451587074682 , Time for epoch =  0.013671398162841797 s\n",
      "Epoch  929 / 1000  : Train-loss =  42.968479759949076 , Val-loss =  44.167887235942636 , Time for epoch =  0.013910055160522461 s\n",
      "Epoch  930 / 1000  : Train-loss =  42.97088135972535 , Val-loss =  44.13297713430304 , Time for epoch =  0.013845682144165039 s\n",
      "Epoch  931 / 1000  : Train-loss =  42.95388423251567 , Val-loss =  44.18740864803917 , Time for epoch =  0.015984773635864258 s\n",
      "Epoch  932 / 1000  : Train-loss =  42.93937747761355 , Val-loss =  44.11110566791735 , Time for epoch =  0.020145893096923828 s\n",
      "Epoch  933 / 1000  : Train-loss =  42.94185677221266 , Val-loss =  44.07947178890831 , Time for epoch =  0.015155315399169922 s\n",
      "Epoch  934 / 1000  : Train-loss =  42.923155380507644 , Val-loss =  44.132871326647304 , Time for epoch =  0.02191615104675293 s\n",
      "Epoch  935 / 1000  : Train-loss =  42.90900386659439 , Val-loss =  44.0564657512464 , Time for epoch =  0.015414714813232422 s\n",
      "Epoch  936 / 1000  : Train-loss =  42.91151660983845 , Val-loss =  44.02195518895199 , Time for epoch =  0.013303518295288086 s\n",
      "Epoch  937 / 1000  : Train-loss =  42.894511120467534 , Val-loss =  44.07679708380448 , Time for epoch =  0.013708353042602539 s\n",
      "Epoch  938 / 1000  : Train-loss =  42.88032406736902 , Val-loss =  44.003844813296666 , Time for epoch =  0.013900279998779297 s\n",
      "Epoch  939 / 1000  : Train-loss =  42.88136354004596 , Val-loss =  43.967932650917454 , Time for epoch =  0.014156103134155273 s\n",
      "Epoch  940 / 1000  : Train-loss =  42.864420141877424 , Val-loss =  44.02290725708008 , Time for epoch =  0.014219522476196289 s\n",
      "Epoch  941 / 1000  : Train-loss =  42.850485246733754 , Val-loss =  43.94677794607062 , Time for epoch =  0.014430999755859375 s\n",
      "Epoch  942 / 1000  : Train-loss =  42.85308415472171 , Val-loss =  43.912594845420436 , Time for epoch =  0.015367746353149414 s\n",
      "Epoch  943 / 1000  : Train-loss =  42.83610271734033 , Val-loss =  43.96776701274671 , Time for epoch =  0.01388406753540039 s\n",
      "Epoch  944 / 1000  : Train-loss =  42.822146809033754 , Val-loss =  43.89502977070055 , Time for epoch =  0.013362646102905273 s\n",
      "Epoch  945 / 1000  : Train-loss =  42.823263588598216 , Val-loss =  43.859433224326686 , Time for epoch =  0.01329350471496582 s\n",
      "Epoch  946 / 1000  : Train-loss =  42.80634277688581 , Val-loss =  43.914712604723476 , Time for epoch =  0.014053821563720703 s\n",
      "Epoch  947 / 1000  : Train-loss =  42.792654393082955 , Val-loss =  43.838741302490234 , Time for epoch =  0.015202522277832031 s\n",
      "Epoch  948 / 1000  : Train-loss =  42.79533653474797 , Val-loss =  43.80483948557001 , Time for epoch =  0.013969659805297852 s\n",
      "Epoch  949 / 1000  : Train-loss =  42.778383545956366 , Val-loss =  43.86325956645765 , Time for epoch =  0.013733625411987305 s\n",
      "Epoch  950 / 1000  : Train-loss =  42.76344107503945 , Val-loss =  43.785917583264805 , Time for epoch =  0.013820886611938477 s\n",
      "Epoch  951 / 1000  : Train-loss =  42.76622246348925 , Val-loss =  43.75202781275699 , Time for epoch =  0.014107465744018555 s\n",
      "Epoch  952 / 1000  : Train-loss =  42.74934124273096 , Val-loss =  43.80756317941766 , Time for epoch =  0.01517176628112793 s\n",
      "Epoch  953 / 1000  : Train-loss =  42.73580775287865 , Val-loss =  43.73186151604904 , Time for epoch =  0.014760494232177734 s\n",
      "Epoch  954 / 1000  : Train-loss =  42.73858200762905 , Val-loss =  43.698258550543535 , Time for epoch =  0.014541864395141602 s\n",
      "Epoch  955 / 1000  : Train-loss =  42.72168794190143 , Val-loss =  43.75686374463533 , Time for epoch =  0.015166044235229492 s\n",
      "Epoch  956 / 1000  : Train-loss =  42.706899998551705 , Val-loss =  43.67982221904554 , Time for epoch =  0.016920804977416992 s\n",
      "Epoch  957 / 1000  : Train-loss =  42.70977300439177 , Val-loss =  43.646212126079355 , Time for epoch =  0.01865220069885254 s\n",
      "Epoch  958 / 1000  : Train-loss =  42.692910426080566 , Val-loss =  43.70203188845986 , Time for epoch =  0.013274431228637695 s\n",
      "Epoch  959 / 1000  : Train-loss =  42.679616874220685 , Val-loss =  43.62649797138415 , Time for epoch =  0.01333475112915039 s\n",
      "Epoch  960 / 1000  : Train-loss =  42.682502574166335 , Val-loss =  43.59626980831749 , Time for epoch =  0.012937784194946289 s\n",
      "Epoch  961 / 1000  : Train-loss =  42.66399558115814 , Val-loss =  43.650837546900696 , Time for epoch =  0.018096208572387695 s\n",
      "Epoch  962 / 1000  : Train-loss =  42.6510179164046 , Val-loss =  43.57520605388441 , Time for epoch =  0.01988959312438965 s\n",
      "Epoch  963 / 1000  : Train-loss =  42.654008401989266 , Val-loss =  43.54182173076429 , Time for epoch =  0.01427602767944336 s\n",
      "Epoch  964 / 1000  : Train-loss =  42.637192612987455 , Val-loss =  43.597919263337786 , Time for epoch =  0.013766050338745117 s\n",
      "Epoch  965 / 1000  : Train-loss =  42.62413749048265 , Val-loss =  43.52255309255499 , Time for epoch =  0.013761281967163086 s\n",
      "Epoch  966 / 1000  : Train-loss =  42.627119764769816 , Val-loss =  43.492596676475124 , Time for epoch =  0.013740301132202148 s\n",
      "Epoch  967 / 1000  : Train-loss =  42.608664668886 , Val-loss =  43.54738526595266 , Time for epoch =  0.014035224914550781 s\n",
      "Epoch  968 / 1000  : Train-loss =  42.59591215747898 , Val-loss =  43.47189622176321 , Time for epoch =  0.014290094375610352 s\n",
      "Epoch  969 / 1000  : Train-loss =  42.59900891578803 , Val-loss =  43.43875895048443 , Time for epoch =  0.014481544494628906 s\n",
      "Epoch  970 / 1000  : Train-loss =  42.58224614461263 , Val-loss =  43.495052337646484 , Time for epoch =  0.016043424606323242 s\n",
      "Epoch  971 / 1000  : Train-loss =  42.56942425744008 , Val-loss =  43.419871280067845 , Time for epoch =  0.01338648796081543 s\n",
      "Epoch  972 / 1000  : Train-loss =  42.572506726798366 , Val-loss =  43.39017195450632 , Time for epoch =  0.01322317123413086 s\n",
      "Epoch  973 / 1000  : Train-loss =  42.55410773067151 , Val-loss =  43.44516432912726 , Time for epoch =  0.01387786865234375 s\n",
      "Epoch  974 / 1000  : Train-loss =  42.54160194612492 , Val-loss =  43.369852567973886 , Time for epoch =  0.013699531555175781 s\n",
      "Epoch  975 / 1000  : Train-loss =  42.544796744308904 , Val-loss =  43.336931228637695 , Time for epoch =  0.0158231258392334 s\n",
      "Epoch  976 / 1000  : Train-loss =  42.52808418920485 , Val-loss =  43.393474980404505 , Time for epoch =  0.014700651168823242 s\n",
      "Epoch  977 / 1000  : Train-loss =  42.515503209863006 , Val-loss =  43.318450927734375 , Time for epoch =  0.013576984405517578 s\n",
      "Epoch  978 / 1000  : Train-loss =  42.51867686557231 , Val-loss =  43.28899664627878 , Time for epoch =  0.01381683349609375 s\n",
      "Epoch  979 / 1000  : Train-loss =  42.500336124398615 , Val-loss =  43.34417895266884 , Time for epoch =  0.014359712600708008 s\n",
      "Epoch  980 / 1000  : Train-loss =  42.488060342389986 , Val-loss =  43.2689988989579 , Time for epoch =  0.015023469924926758 s\n",
      "Epoch  981 / 1000  : Train-loss =  42.49136193054544 , Val-loss =  43.23633003234863 , Time for epoch =  0.014394521713256836 s\n",
      "Epoch  982 / 1000  : Train-loss =  42.474728923732954 , Val-loss =  43.29311441120348 , Time for epoch =  0.014587640762329102 s\n",
      "Epoch  983 / 1000  : Train-loss =  42.4623648433362 , Val-loss =  43.218215340062194 , Time for epoch =  0.01460123062133789 s\n",
      "Epoch  984 / 1000  : Train-loss =  42.46563005177988 , Val-loss =  43.185773247166686 , Time for epoch =  0.017485618591308594 s\n",
      "Epoch  985 / 1000  : Train-loss =  42.449001161392125 , Val-loss =  43.245661183407435 , Time for epoch =  0.013485908508300781 s\n",
      "Epoch  986 / 1000  : Train-loss =  42.43537825244968 , Val-loss =  43.16938510694002 , Time for epoch =  0.013471126556396484 s\n",
      "Epoch  987 / 1000  : Train-loss =  42.438760013903604 , Val-loss =  43.136924944425886 , Time for epoch =  0.01338338851928711 s\n",
      "Epoch  988 / 1000  : Train-loss =  42.422155240161274 , Val-loss =  43.19392886914705 , Time for epoch =  0.013330936431884766 s\n",
      "Epoch  989 / 1000  : Train-loss =  42.41004008492507 , Val-loss =  43.119188710262904 , Time for epoch =  0.014151334762573242 s\n",
      "Epoch  990 / 1000  : Train-loss =  42.413427212817524 , Val-loss =  43.09016900313528 , Time for epoch =  0.01653265953063965 s\n",
      "Epoch  991 / 1000  : Train-loss =  42.3951771191958 , Val-loss =  43.14579180667275 , Time for epoch =  0.013713836669921875 s\n",
      "Epoch  992 / 1000  : Train-loss =  42.38336690266927 , Val-loss =  43.07093650416324 , Time for epoch =  0.013946294784545898 s\n",
      "Epoch  993 / 1000  : Train-loss =  42.38686875165519 , Val-loss =  43.03867570977462 , Time for epoch =  0.014496803283691406 s\n",
      "Epoch  994 / 1000  : Train-loss =  42.37034395724367 , Val-loss =  43.09588291770533 , Time for epoch =  0.014713287353515625 s\n",
      "Epoch  995 / 1000  : Train-loss =  42.35844617509572 , Val-loss =  43.02133811147589 , Time for epoch =  0.014718294143676758 s\n",
      "Epoch  996 / 1000  : Train-loss =  42.3619157607946 , Val-loss =  42.98932436892861 , Time for epoch =  0.01475667953491211 s\n",
      "Epoch  997 / 1000  : Train-loss =  42.34540135442874 , Val-loss =  43.04966504950272 , Time for epoch =  0.014827251434326172 s\n",
      "Epoch  998 / 1000  : Train-loss =  42.33222043312202 , Val-loss =  42.97180205897281 , Time for epoch =  0.01633477210998535 s\n",
      "Epoch  999 / 1000  : Train-loss =  42.335790407859676 , Val-loss =  42.93783017208702 , Time for epoch =  0.014911174774169922 s\n",
      "Epoch  1000 / 1000  : Train-loss =  42.31930311386195 , Val-loss =  42.993341847469935 , Time for epoch =  0.013655900955200195 s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAAEWCAYAAADIJfYaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nq5RSSvlIG69SSinlI228SimllI/+P2w/6W7r4XpdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f10798e3a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 s, sys: 296 ms, total: 15.8 s\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train([X_train, y_train, X_test, y_test], batch_size, [w1, w2], n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Perform training : GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, batch_size, model, n_epochs):\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = data\n",
    "    w1, w2 = model\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for t in range(n_epochs):\n",
    "\n",
    "        epoch_start = time.time()\n",
    "        train_loss = 0.\n",
    "        val_loss = 0.    \n",
    "        for state in ['train', 'val']:        \n",
    "\n",
    "            batch_start_idx = 0\n",
    "            n_samples = len(X_train) if state=='train' else len(X_test)        \n",
    "            while batch_start_idx < n_samples:\n",
    "\n",
    "                # Get next batch of data \n",
    "                batch_end_idx = batch_start_idx + batch_size\n",
    "                if batch_end_idx > n_samples:  batch_end_idx = n_samples\n",
    "                if state == 'train':  x, y = torch.Tensor(X_train.iloc[batch_start_idx:batch_end_idx, :].values).cuda(), torch.Tensor(y_train.iloc[batch_start_idx:batch_end_idx, :].values).cuda()\n",
    "                else:  x, y = torch.Tensor(X_test.iloc[batch_start_idx:batch_end_idx, :].values).cuda(), torch.Tensor(y_test.iloc[batch_start_idx:batch_end_idx, :].values).cuda()\n",
    "\n",
    "                # Forward pass: Compute output and loss\n",
    "                h = x.mm(w1)\n",
    "                h_relu = h.clamp(min=0)\n",
    "                y_pred = h_relu.mm(w2)\n",
    "                loss = (y_pred - y).pow(2).sum().item()\n",
    "                if state == 'train':  train_loss += loss\n",
    "                else:  val_loss += loss\n",
    "\n",
    "                # Backward pass: Compute gradients\n",
    "                if state == 'train':\n",
    "                    grad_y_pred = 2.0 * (y_pred - y)\n",
    "                    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "                    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "                    grad_h = grad_h_relu.clone()\n",
    "                    grad_h[h < 0] = 0\n",
    "                    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "                # Update weights using gradient descent\n",
    "                    w1 -= learning_rate * grad_w1\n",
    "                    w2 -= learning_rate * grad_w2\n",
    "\n",
    "                batch_start_idx = batch_end_idx\n",
    "\n",
    "        # Print statistics\n",
    "        train_loss /= len(X_train)\n",
    "        train_losses.append(train_loss)\n",
    "        val_loss /= len(X_test)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        epoch_end = time.time()\n",
    "        epoch_time = epoch_end - epoch_start\n",
    "        print(\"Epoch \", (t+1), \"/\", n_epochs, \" : Train-loss = \", train_loss, \", Val-loss = \", val_loss, \", Time for epoch = \", epoch_time, \"s\")\n",
    "\n",
    "    # Plot loss-curves\n",
    "    plt.figure()\n",
    "    plt.plot(range(2, n_epochs+1), train_losses[1:], label='Train-loss')\n",
    "    plt.plot(range(2, n_epochs+1), val_losses[1:], label='Val-loss')\n",
    "    plt.title('Loss curves')\n",
    "    plt.xlabel('No. of epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.grid(linestyle='dotted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 / 1000  : Train-loss =  34196299450294.72 , Val-loss =  565.7811439915707 , Time for epoch =  0.0370326042175293 s\n",
      "Epoch  2 / 1000  : Train-loss =  589.9449797377074 , Val-loss =  565.5632259971217 , Time for epoch =  0.020711421966552734 s\n",
      "Epoch  3 / 1000  : Train-loss =  586.5188771048508 , Val-loss =  564.0089400442023 , Time for epoch =  0.024940013885498047 s\n",
      "Epoch  4 / 1000  : Train-loss =  583.4597947287695 , Val-loss =  562.6939633018092 , Time for epoch =  0.018918752670288086 s\n",
      "Epoch  5 / 1000  : Train-loss =  580.4889250502074 , Val-loss =  559.9104164525082 , Time for epoch =  0.018567323684692383 s\n",
      "Epoch  6 / 1000  : Train-loss =  575.0640327755341 , Val-loss =  548.8745984529194 , Time for epoch =  0.018334627151489258 s\n",
      "Epoch  7 / 1000  : Train-loss =  537.8514166363215 , Val-loss =  461.06643034282484 , Time for epoch =  0.018436908721923828 s\n",
      "Epoch  8 / 1000  : Train-loss =  362.8117788066972 , Val-loss =  189.19135324578536 , Time for epoch =  0.018083572387695312 s\n",
      "Epoch  9 / 1000  : Train-loss =  182.5547174141232 , Val-loss =  141.44615093030427 , Time for epoch =  0.018565654754638672 s\n",
      "Epoch  10 / 1000  : Train-loss =  149.36922198365636 , Val-loss =  105.48995248894943 , Time for epoch =  0.019214391708374023 s\n",
      "Epoch  11 / 1000  : Train-loss =  104.61051522809908 , Val-loss =  75.95002947355572 , Time for epoch =  0.018967866897583008 s\n",
      "Epoch  12 / 1000  : Train-loss =  89.34192028153414 , Val-loss =  68.85147817511307 , Time for epoch =  0.026911497116088867 s\n",
      "Epoch  13 / 1000  : Train-loss =  87.96946324062887 , Val-loss =  66.99726586592824 , Time for epoch =  0.018930912017822266 s\n",
      "Epoch  14 / 1000  : Train-loss =  88.79228732006698 , Val-loss =  66.65963062487151 , Time for epoch =  0.01917862892150879 s\n",
      "Epoch  15 / 1000  : Train-loss =  88.17100520591951 , Val-loss =  66.39956544574939 , Time for epoch =  0.01827216148376465 s\n",
      "Epoch  16 / 1000  : Train-loss =  86.76250893113303 , Val-loss =  66.04332632767527 , Time for epoch =  0.018240690231323242 s\n",
      "Epoch  17 / 1000  : Train-loss =  85.31879703069137 , Val-loss =  65.73280535246197 , Time for epoch =  0.018345355987548828 s\n",
      "Epoch  18 / 1000  : Train-loss =  83.98190027441682 , Val-loss =  65.45911809017784 , Time for epoch =  0.019912004470825195 s\n",
      "Epoch  19 / 1000  : Train-loss =  82.85585414218363 , Val-loss =  65.12948046232525 , Time for epoch =  0.020778894424438477 s\n",
      "Epoch  20 / 1000  : Train-loss =  81.82338796497065 , Val-loss =  64.80321201525237 , Time for epoch =  0.019079208374023438 s\n",
      "Epoch  21 / 1000  : Train-loss =  80.90341509802867 , Val-loss =  64.4957345661364 , Time for epoch =  0.019982099533081055 s\n",
      "Epoch  22 / 1000  : Train-loss =  80.07033228470107 , Val-loss =  64.26090340865285 , Time for epoch =  0.024575471878051758 s\n",
      "Epoch  23 / 1000  : Train-loss =  79.32972493144752 , Val-loss =  64.01926462273849 , Time for epoch =  0.019348859786987305 s\n",
      "Epoch  24 / 1000  : Train-loss =  78.67555715269961 , Val-loss =  63.75480953015779 , Time for epoch =  0.01900172233581543 s\n",
      "Epoch  25 / 1000  : Train-loss =  78.0954594369662 , Val-loss =  63.501925016704355 , Time for epoch =  0.018825769424438477 s\n",
      "Epoch  26 / 1000  : Train-loss =  77.56264849301786 , Val-loss =  63.316510250693874 , Time for epoch =  0.018328428268432617 s\n",
      "Epoch  27 / 1000  : Train-loss =  77.05602762254618 , Val-loss =  63.0645099439119 , Time for epoch =  0.018404722213745117 s\n",
      "Epoch  28 / 1000  : Train-loss =  76.6052938342768 , Val-loss =  62.70539675260845 , Time for epoch =  0.0184171199798584 s\n",
      "Epoch  29 / 1000  : Train-loss =  76.17221674946069 , Val-loss =  62.358709837260996 , Time for epoch =  0.018480539321899414 s\n",
      "Epoch  30 / 1000  : Train-loss =  75.75669214280985 , Val-loss =  62.02392337196752 , Time for epoch =  0.018593788146972656 s\n",
      "Epoch  31 / 1000  : Train-loss =  75.36961084570588 , Val-loss =  61.73554370277807 , Time for epoch =  0.01838088035583496 s\n",
      "Epoch  32 / 1000  : Train-loss =  75.02280288092834 , Val-loss =  61.45001481708727 , Time for epoch =  0.02376842498779297 s\n",
      "Epoch  33 / 1000  : Train-loss =  74.71014346106578 , Val-loss =  61.10994620072214 , Time for epoch =  0.019314289093017578 s\n",
      "Epoch  34 / 1000  : Train-loss =  74.40756126446912 , Val-loss =  60.7474375273052 , Time for epoch =  0.018634557723999023 s\n",
      "Epoch  35 / 1000  : Train-loss =  74.11073835556117 , Val-loss =  60.41043030588251 , Time for epoch =  0.018488645553588867 s\n",
      "Epoch  36 / 1000  : Train-loss =  73.86488829359496 , Val-loss =  60.2507902446546 , Time for epoch =  0.018615245819091797 s\n",
      "Epoch  37 / 1000  : Train-loss =  73.57034273740263 , Val-loss =  60.18336185656096 , Time for epoch =  0.018274307250976562 s\n",
      "Epoch  38 / 1000  : Train-loss =  73.28355679269565 , Val-loss =  59.8463393763492 , Time for epoch =  0.01854109764099121 s\n",
      "Epoch  39 / 1000  : Train-loss =  73.03243359064652 , Val-loss =  59.48915842959755 , Time for epoch =  0.018217086791992188 s\n",
      "Epoch  40 / 1000  : Train-loss =  72.74992357674292 , Val-loss =  59.176542583264805 , Time for epoch =  0.01805400848388672 s\n",
      "Epoch  41 / 1000  : Train-loss =  72.46387942901438 , Val-loss =  58.76344459935238 , Time for epoch =  0.01860213279724121 s\n",
      "Epoch  42 / 1000  : Train-loss =  72.12558041588734 , Val-loss =  58.44255306846217 , Time for epoch =  0.01841115951538086 s\n",
      "Epoch  43 / 1000  : Train-loss =  71.82919686527576 , Val-loss =  58.240473897833574 , Time for epoch =  0.020139217376708984 s\n",
      "Epoch  44 / 1000  : Train-loss =  71.55505248247567 , Val-loss =  58.056600068744864 , Time for epoch =  0.026528596878051758 s\n",
      "Epoch  45 / 1000  : Train-loss =  71.29686051708157 , Val-loss =  57.88217865793329 , Time for epoch =  0.018985748291015625 s\n",
      "Epoch  46 / 1000  : Train-loss =  71.05480638062213 , Val-loss =  57.718141656172904 , Time for epoch =  0.01838088035583496 s\n",
      "Epoch  47 / 1000  : Train-loss =  70.82943466962394 , Val-loss =  57.55250960902164 , Time for epoch =  0.018198490142822266 s\n",
      "Epoch  48 / 1000  : Train-loss =  70.6139269467801 , Val-loss =  57.388166327225534 , Time for epoch =  0.018214702606201172 s\n",
      "Epoch  49 / 1000  : Train-loss =  70.40833709199549 , Val-loss =  57.22470414011102 , Time for epoch =  0.02012038230895996 s\n",
      "Epoch  50 / 1000  : Train-loss =  70.21153830404336 , Val-loss =  57.06340870104338 , Time for epoch =  0.01873040199279785 s\n",
      "Epoch  51 / 1000  : Train-loss =  70.02521648514742 , Val-loss =  56.900556463944284 , Time for epoch =  0.018335580825805664 s\n",
      "Epoch  52 / 1000  : Train-loss =  69.78129467721713 , Val-loss =  56.717483721281354 , Time for epoch =  0.018465042114257812 s\n",
      "Epoch  53 / 1000  : Train-loss =  69.55021201958091 , Val-loss =  56.533823916786595 , Time for epoch =  0.018131732940673828 s\n",
      "Epoch  54 / 1000  : Train-loss =  69.33160531857592 , Val-loss =  56.35425627859015 , Time for epoch =  0.02331089973449707 s\n",
      "Epoch  55 / 1000  : Train-loss =  69.12404861019156 , Val-loss =  56.180427049335684 , Time for epoch =  0.01955556869506836 s\n",
      "Epoch  56 / 1000  : Train-loss =  68.92628843232063 , Val-loss =  56.01283053347939 , Time for epoch =  0.01836395263671875 s\n",
      "Epoch  57 / 1000  : Train-loss =  68.7352726607673 , Val-loss =  55.847416626779655 , Time for epoch =  0.018959522247314453 s\n",
      "Epoch  58 / 1000  : Train-loss =  68.55977328887766 , Val-loss =  55.69710068953665 , Time for epoch =  0.0190885066986084 s\n",
      "Epoch  59 / 1000  : Train-loss =  68.3921061585852 , Val-loss =  55.54902438113564 , Time for epoch =  0.019221782684326172 s\n",
      "Epoch  60 / 1000  : Train-loss =  68.23056275965804 , Val-loss =  55.40518539830258 , Time for epoch =  0.01908707618713379 s\n",
      "Epoch  61 / 1000  : Train-loss =  68.07448336498885 , Val-loss =  55.266285243787266 , Time for epoch =  0.01868271827697754 s\n",
      "Epoch  62 / 1000  : Train-loss =  67.92336704232598 , Val-loss =  55.13239900689376 , Time for epoch =  0.018461942672729492 s\n",
      "Epoch  63 / 1000  : Train-loss =  67.77676686863441 , Val-loss =  55.003326416015625 , Time for epoch =  0.019804000854492188 s\n",
      "Epoch  64 / 1000  : Train-loss =  67.63432602963205 , Val-loss =  54.878784581234584 , Time for epoch =  0.01879739761352539 s\n",
      "Epoch  65 / 1000  : Train-loss =  67.49571695704918 , Val-loss =  54.758424959684675 , Time for epoch =  0.020044326782226562 s\n",
      "Epoch  66 / 1000  : Train-loss =  67.36065934606864 , Val-loss =  54.64197530244526 , Time for epoch =  0.023741960525512695 s\n",
      "Epoch  67 / 1000  : Train-loss =  67.22890750432418 , Val-loss =  54.529122603567025 , Time for epoch =  0.018820762634277344 s\n",
      "Epoch  68 / 1000  : Train-loss =  67.10022517920888 , Val-loss =  54.419627842150234 , Time for epoch =  0.018462181091308594 s\n",
      "Epoch  69 / 1000  : Train-loss =  66.97441715305135 , Val-loss =  54.313251294587786 , Time for epoch =  0.019402027130126953 s\n",
      "Epoch  70 / 1000  : Train-loss =  66.8512839193398 , Val-loss =  54.209780743247585 , Time for epoch =  0.020738601684570312 s\n",
      "Epoch  71 / 1000  : Train-loss =  66.7306631055929 , Val-loss =  54.0998851374576 , Time for epoch =  0.01843571662902832 s\n",
      "Epoch  72 / 1000  : Train-loss =  66.61238076592569 , Val-loss =  53.98206851356908 , Time for epoch =  0.018184900283813477 s\n",
      "Epoch  73 / 1000  : Train-loss =  66.4962947867011 , Val-loss =  53.86751777247379 , Time for epoch =  0.018094539642333984 s\n",
      "Epoch  74 / 1000  : Train-loss =  66.38226818364892 , Val-loss =  53.75606175472862 , Time for epoch =  0.01899123191833496 s\n",
      "Epoch  75 / 1000  : Train-loss =  66.27016203282243 , Val-loss =  53.647442064787214 , Time for epoch =  0.018813133239746094 s\n",
      "Epoch  76 / 1000  : Train-loss =  66.15985368200614 , Val-loss =  53.541493566412676 , Time for epoch =  0.021953344345092773 s\n",
      "Epoch  77 / 1000  : Train-loss =  66.05122349625927 , Val-loss =  53.438038173474766 , Time for epoch =  0.020722627639770508 s\n",
      "Epoch  78 / 1000  : Train-loss =  65.94192354019079 , Val-loss =  53.33110267237613 , Time for epoch =  0.01854872703552246 s\n",
      "Epoch  79 / 1000  : Train-loss =  65.83007922415005 , Val-loss =  53.225889105545846 , Time for epoch =  0.018423080444335938 s\n",
      "Epoch  80 / 1000  : Train-loss =  65.72005729890813 , Val-loss =  53.12284037941381 , Time for epoch =  0.018207311630249023 s\n",
      "Epoch  81 / 1000  : Train-loss =  65.61174127611064 , Val-loss =  53.018388748168945 , Time for epoch =  0.018240690231323242 s\n",
      "Epoch  82 / 1000  : Train-loss =  65.50499505511785 , Val-loss =  52.90877954583419 , Time for epoch =  0.01871204376220703 s\n",
      "Epoch  83 / 1000  : Train-loss =  65.3997024493029 , Val-loss =  52.801761627197266 , Time for epoch =  0.019079208374023438 s\n",
      "Epoch  84 / 1000  : Train-loss =  65.29574871602031 , Val-loss =  52.697172365690534 , Time for epoch =  0.018558263778686523 s\n",
      "Epoch  85 / 1000  : Train-loss =  65.19304514739473 , Val-loss =  52.59483929684288 , Time for epoch =  0.018635272979736328 s\n",
      "Epoch  86 / 1000  : Train-loss =  65.1137707166079 , Val-loss =  52.44098482633892 , Time for epoch =  0.018431663513183594 s\n",
      "Epoch  87 / 1000  : Train-loss =  65.00444198867022 , Val-loss =  52.3190803527832 , Time for epoch =  0.01972031593322754 s\n",
      "Epoch  88 / 1000  : Train-loss =  64.89988283922443 , Val-loss =  52.21244149459036 , Time for epoch =  0.022980213165283203 s\n",
      "Epoch  89 / 1000  : Train-loss =  64.79776343652757 , Val-loss =  52.113716527035365 , Time for epoch =  0.01907491683959961 s\n",
      "Epoch  90 / 1000  : Train-loss =  64.69724221956932 , Val-loss =  52.019486678274056 , Time for epoch =  0.0184628963470459 s\n",
      "Epoch  91 / 1000  : Train-loss =  64.59787952832583 , Val-loss =  51.92810650875694 , Time for epoch =  0.01845574378967285 s\n",
      "Epoch  92 / 1000  : Train-loss =  64.50140290341135 , Val-loss =  51.840558102256374 , Time for epoch =  0.018334150314331055 s\n",
      "Epoch  93 / 1000  : Train-loss =  64.40661672818459 , Val-loss =  51.7541120428788 , Time for epoch =  0.01842021942138672 s\n",
      "Epoch  94 / 1000  : Train-loss =  64.28100141967084 , Val-loss =  51.566667657149466 , Time for epoch =  0.018245935440063477 s\n",
      "Epoch  95 / 1000  : Train-loss =  64.15065034769349 , Val-loss =  51.405064030697474 , Time for epoch =  0.01874709129333496 s\n",
      "Epoch  96 / 1000  : Train-loss =  64.03022414816301 , Val-loss =  51.285953421341745 , Time for epoch =  0.0195310115814209 s\n",
      "Epoch  97 / 1000  : Train-loss =  63.9242005644545 , Val-loss =  51.18064498901367 , Time for epoch =  0.018453359603881836 s\n",
      "Epoch  98 / 1000  : Train-loss =  63.824644099521095 , Val-loss =  51.083416286267735 , Time for epoch =  0.0199582576751709 s\n",
      "Epoch  99 / 1000  : Train-loss =  63.72823779865847 , Val-loss =  50.991313432392325 , Time for epoch =  0.022807598114013672 s\n",
      "Epoch  100 / 1000  : Train-loss =  63.633500697249076 , Val-loss =  50.90262101825915 , Time for epoch =  0.019860267639160156 s\n",
      "Epoch  101 / 1000  : Train-loss =  63.539736947097346 , Val-loss =  50.81629070482756 , Time for epoch =  0.018730640411376953 s\n",
      "Epoch  102 / 1000  : Train-loss =  63.44658376402774 , Val-loss =  50.73165502046284 , Time for epoch =  0.018711566925048828 s\n",
      "Epoch  103 / 1000  : Train-loss =  63.35386144778149 , Val-loss =  50.648296556974714 , Time for epoch =  0.018499374389648438 s\n",
      "Epoch  104 / 1000  : Train-loss =  63.261431871834446 , Val-loss =  50.56593945151881 , Time for epoch =  0.018491268157958984 s\n",
      "Epoch  105 / 1000  : Train-loss =  63.16921979828743 , Val-loss =  50.484362050106654 , Time for epoch =  0.018434762954711914 s\n",
      "Epoch  106 / 1000  : Train-loss =  63.07716615321272 , Val-loss =  50.403434452257656 , Time for epoch =  0.018516063690185547 s\n",
      "Epoch  107 / 1000  : Train-loss =  62.985216431698554 , Val-loss =  50.323054564626595 , Time for epoch =  0.01817488670349121 s\n",
      "Epoch  108 / 1000  : Train-loss =  62.89333233590853 , Val-loss =  50.24312651784796 , Time for epoch =  0.01860833168029785 s\n",
      "Epoch  109 / 1000  : Train-loss =  62.80147692577987 , Val-loss =  50.16360282897949 , Time for epoch =  0.023049592971801758 s\n",
      "Epoch  110 / 1000  : Train-loss =  62.70961944666286 , Val-loss =  50.084416038111634 , Time for epoch =  0.0228269100189209 s\n",
      "Epoch  111 / 1000  : Train-loss =  62.6177298766745 , Val-loss =  50.00552699440404 , Time for epoch =  0.018590211868286133 s\n",
      "Epoch  112 / 1000  : Train-loss =  62.52578386209779 , Val-loss =  49.92689524198833 , Time for epoch =  0.018839359283447266 s\n",
      "Epoch  113 / 1000  : Train-loss =  62.4337576849986 , Val-loss =  49.84848142925062 , Time for epoch =  0.019172191619873047 s\n",
      "Epoch  114 / 1000  : Train-loss =  62.34162539681472 , Val-loss =  49.7702502200478 , Time for epoch =  0.019255876541137695 s\n",
      "Epoch  115 / 1000  : Train-loss =  62.249368624498615 , Val-loss =  49.692190872995475 , Time for epoch =  0.019276142120361328 s\n",
      "Epoch  116 / 1000  : Train-loss =  62.15696602083195 , Val-loss =  49.615713822214225 , Time for epoch =  0.019168853759765625 s\n",
      "Epoch  117 / 1000  : Train-loss =  62.06415928555074 , Val-loss =  49.52902934425756 , Time for epoch =  0.018976211547851562 s\n",
      "Epoch  118 / 1000  : Train-loss =  61.966255069452494 , Val-loss =  49.442248695775085 , Time for epoch =  0.019119739532470703 s\n",
      "Epoch  119 / 1000  : Train-loss =  61.86849283767959 , Val-loss =  49.3517625708329 , Time for epoch =  0.019182205200195312 s\n",
      "Epoch  120 / 1000  : Train-loss =  61.763817210655425 , Val-loss =  49.25944127534565 , Time for epoch =  0.028653383255004883 s\n",
      "Epoch  121 / 1000  : Train-loss =  61.658992551814364 , Val-loss =  49.11988168013723 , Time for epoch =  0.026309728622436523 s\n",
      "Epoch  122 / 1000  : Train-loss =  61.52312790606655 , Val-loss =  49.02070346631502 , Time for epoch =  0.01894521713256836 s\n",
      "Epoch  123 / 1000  : Train-loss =  61.40212828426038 , Val-loss =  48.93439282869038 , Time for epoch =  0.01856255531311035 s\n",
      "Epoch  124 / 1000  : Train-loss =  61.284243007164214 , Val-loss =  48.851212551719264 , Time for epoch =  0.018570661544799805 s\n",
      "Epoch  125 / 1000  : Train-loss =  61.17302572390454 , Val-loss =  48.77227170843827 , Time for epoch =  0.019012451171875 s\n",
      "Epoch  126 / 1000  : Train-loss =  61.06169802994378 , Val-loss =  48.69132403323525 , Time for epoch =  0.018948078155517578 s\n",
      "Epoch  127 / 1000  : Train-loss =  60.94483179426463 , Val-loss =  48.60107180946752 , Time for epoch =  0.018286466598510742 s\n",
      "Epoch  128 / 1000  : Train-loss =  60.82444894650562 , Val-loss =  48.50847475152267 , Time for epoch =  0.018730640411376953 s\n",
      "Epoch  129 / 1000  : Train-loss =  60.703214807025454 , Val-loss =  48.4216944042005 , Time for epoch =  0.018335580825805664 s\n",
      "Epoch  130 / 1000  : Train-loss =  60.58556303466107 , Val-loss =  48.33547933478104 , Time for epoch =  0.018285274505615234 s\n",
      "Epoch  131 / 1000  : Train-loss =  60.463887295480504 , Val-loss =  48.243274086400085 , Time for epoch =  0.026411771774291992 s\n",
      "Epoch  132 / 1000  : Train-loss =  60.34014822534249 , Val-loss =  48.14226020009894 , Time for epoch =  0.026767730712890625 s\n",
      "Epoch  133 / 1000  : Train-loss =  60.21805114530574 , Val-loss =  48.04275331999126 , Time for epoch =  0.019108295440673828 s\n",
      "Epoch  134 / 1000  : Train-loss =  60.09735280915169 , Val-loss =  47.94468829506322 , Time for epoch =  0.01857757568359375 s\n",
      "Epoch  135 / 1000  : Train-loss =  59.97577653227553 , Val-loss =  47.84900313929508 , Time for epoch =  0.018851757049560547 s\n",
      "Epoch  136 / 1000  : Train-loss =  59.85667887111168 , Val-loss =  47.751548967863386 , Time for epoch =  0.018658161163330078 s\n",
      "Epoch  137 / 1000  : Train-loss =  59.73867737506069 , Val-loss =  47.654396659449525 , Time for epoch =  0.01828289031982422 s\n",
      "Epoch  138 / 1000  : Train-loss =  59.62152551122978 , Val-loss =  47.558206257067226 , Time for epoch =  0.01818704605102539 s\n",
      "Epoch  139 / 1000  : Train-loss =  59.5024027743582 , Val-loss =  47.45939726578562 , Time for epoch =  0.018357038497924805 s\n",
      "Epoch  140 / 1000  : Train-loss =  59.38102169360145 , Val-loss =  47.36806929738898 , Time for epoch =  0.018217802047729492 s\n",
      "Epoch  141 / 1000  : Train-loss =  59.2654899554064 , Val-loss =  47.27988965887772 , Time for epoch =  0.018651723861694336 s\n",
      "Epoch  142 / 1000  : Train-loss =  59.1502685008076 , Val-loss =  47.19246994821649 , Time for epoch =  0.02655482292175293 s\n",
      "Epoch  143 / 1000  : Train-loss =  59.03540577861549 , Val-loss =  47.10577804163883 , Time for epoch =  0.027909517288208008 s\n",
      "Epoch  144 / 1000  : Train-loss =  58.920826874210334 , Val-loss =  47.0197407571893 , Time for epoch =  0.019509077072143555 s\n",
      "Epoch  145 / 1000  : Train-loss =  58.8064609462932 , Val-loss =  46.936063164158874 , Time for epoch =  0.019688844680786133 s\n",
      "Epoch  146 / 1000  : Train-loss =  58.69412712054064 , Val-loss =  46.85684535377904 , Time for epoch =  0.01918649673461914 s\n",
      "Epoch  147 / 1000  : Train-loss =  58.58572901709605 , Val-loss =  46.78040976273386 , Time for epoch =  0.019065380096435547 s\n",
      "Epoch  148 / 1000  : Train-loss =  58.47804417583229 , Val-loss =  46.70444880033794 , Time for epoch =  0.019064664840698242 s\n",
      "Epoch  149 / 1000  : Train-loss =  58.370085107404634 , Val-loss =  46.62732365256861 , Time for epoch =  0.01973891258239746 s\n",
      "Epoch  150 / 1000  : Train-loss =  58.26203476641811 , Val-loss =  46.54558462845652 , Time for epoch =  0.019249916076660156 s\n",
      "Epoch  151 / 1000  : Train-loss =  58.15389360546392 , Val-loss =  46.46438829522384 , Time for epoch =  0.018390655517578125 s\n",
      "Epoch  152 / 1000  : Train-loss =  58.0454048867953 , Val-loss =  46.38374920895225 , Time for epoch =  0.020430564880371094 s\n",
      "Epoch  153 / 1000  : Train-loss =  57.93655774822343 , Val-loss =  46.30368835047672 , Time for epoch =  0.027538537979125977 s\n",
      "Epoch  154 / 1000  : Train-loss =  57.82733515292238 , Val-loss =  46.22422951146176 , Time for epoch =  0.023372650146484375 s\n",
      "Epoch  155 / 1000  : Train-loss =  57.717733210763015 , Val-loss =  46.145437240600586 , Time for epoch =  0.018725156784057617 s\n",
      "Epoch  156 / 1000  : Train-loss =  57.60774869972703 , Val-loss =  46.06713033977308 , Time for epoch =  0.018291234970092773 s\n",
      "Epoch  157 / 1000  : Train-loss =  57.49126995754781 , Val-loss =  46.01745876513029 , Time for epoch =  0.018390178680419922 s\n",
      "Epoch  158 / 1000  : Train-loss =  57.36914437504138 , Val-loss =  45.94913783826326 , Time for epoch =  0.01834869384765625 s\n",
      "Epoch  159 / 1000  : Train-loss =  57.24112086107502 , Val-loss =  45.857051146657845 , Time for epoch =  0.01834869384765625 s\n",
      "Epoch  160 / 1000  : Train-loss =  57.09798774072679 , Val-loss =  45.75882429825632 , Time for epoch =  0.018398523330688477 s\n",
      "Epoch  161 / 1000  : Train-loss =  56.954880062469655 , Val-loss =  45.66106003209164 , Time for epoch =  0.018127918243408203 s\n",
      "Epoch  162 / 1000  : Train-loss =  56.814127927446094 , Val-loss =  45.56721627084833 , Time for epoch =  0.018805503845214844 s\n",
      "Epoch  163 / 1000  : Train-loss =  56.67837297040864 , Val-loss =  45.47538124887567 , Time for epoch =  0.02308344841003418 s\n",
      "Epoch  164 / 1000  : Train-loss =  56.5431005617993 , Val-loss =  45.38538591485275 , Time for epoch =  0.022777795791625977 s\n",
      "Epoch  165 / 1000  : Train-loss =  56.40845711487161 , Val-loss =  45.29744579917506 , Time for epoch =  0.018625497817993164 s\n",
      "Epoch  166 / 1000  : Train-loss =  56.273606866093004 , Val-loss =  45.2083807493511 , Time for epoch =  0.018500566482543945 s\n",
      "Epoch  167 / 1000  : Train-loss =  56.13457600006276 , Val-loss =  45.12070746170847 , Time for epoch =  0.018494129180908203 s\n",
      "Epoch  168 / 1000  : Train-loss =  55.99649796782241 , Val-loss =  45.03617638035824 , Time for epoch =  0.02002739906311035 s\n",
      "Epoch  169 / 1000  : Train-loss =  55.85942073326326 , Val-loss =  44.95458321822317 , Time for epoch =  0.019405841827392578 s\n",
      "Epoch  170 / 1000  : Train-loss =  55.72361393298133 , Val-loss =  44.87539793315687 , Time for epoch =  0.02001476287841797 s\n",
      "Epoch  171 / 1000  : Train-loss =  55.58846696756654 , Val-loss =  44.79931138691149 , Time for epoch =  0.018551349639892578 s\n",
      "Epoch  172 / 1000  : Train-loss =  55.45583023459224 , Val-loss =  44.724641599153216 , Time for epoch =  0.0195310115814209 s\n",
      "Epoch  173 / 1000  : Train-loss =  55.32309730443577 , Val-loss =  44.632874840184265 , Time for epoch =  0.02247476577758789 s\n",
      "Epoch  174 / 1000  : Train-loss =  55.16023827676719 , Val-loss =  44.541589636551706 , Time for epoch =  0.022260427474975586 s\n",
      "Epoch  175 / 1000  : Train-loss =  54.96684441862807 , Val-loss =  44.42726586994372 , Time for epoch =  0.020272493362426758 s\n",
      "Epoch  176 / 1000  : Train-loss =  54.734421002662785 , Val-loss =  44.30435301128187 , Time for epoch =  0.01874065399169922 s\n",
      "Epoch  177 / 1000  : Train-loss =  54.52505062124823 , Val-loss =  44.18590786582545 , Time for epoch =  0.018686771392822266 s\n",
      "Epoch  178 / 1000  : Train-loss =  54.32419624975172 , Val-loss =  44.086835158498666 , Time for epoch =  0.018624067306518555 s\n",
      "Epoch  179 / 1000  : Train-loss =  54.15392337949936 , Val-loss =  44.016380611218906 , Time for epoch =  0.018421649932861328 s\n",
      "Epoch  180 / 1000  : Train-loss =  54.00597299694341 , Val-loss =  43.94489910728053 , Time for epoch =  0.01812744140625 s\n",
      "Epoch  181 / 1000  : Train-loss =  53.864706653659624 , Val-loss =  43.870824914229544 , Time for epoch =  0.018469810485839844 s\n",
      "Epoch  182 / 1000  : Train-loss =  53.72443685154457 , Val-loss =  43.805992427625156 , Time for epoch =  0.018503427505493164 s\n",
      "Epoch  183 / 1000  : Train-loss =  53.58617431295794 , Val-loss =  43.747936048005755 , Time for epoch =  0.020229816436767578 s\n",
      "Epoch  184 / 1000  : Train-loss =  53.447244116141974 , Val-loss =  43.695720973767735 , Time for epoch =  0.023262500762939453 s\n",
      "Epoch  185 / 1000  : Train-loss =  53.314017990888175 , Val-loss =  43.64921328895971 , Time for epoch =  0.018552064895629883 s\n",
      "Epoch  186 / 1000  : Train-loss =  53.18237046063957 , Val-loss =  43.60781980815687 , Time for epoch =  0.0182645320892334 s\n",
      "Epoch  187 / 1000  : Train-loss =  53.048630493508895 , Val-loss =  43.575395483719674 , Time for epoch =  0.01883673667907715 s\n",
      "Epoch  188 / 1000  : Train-loss =  52.921165433980654 , Val-loss =  43.55220754523026 , Time for epoch =  0.018352508544921875 s\n",
      "Epoch  189 / 1000  : Train-loss =  52.79477326344635 , Val-loss =  43.53329768933748 , Time for epoch =  0.018522024154663086 s\n",
      "Epoch  190 / 1000  : Train-loss =  52.66914873069289 , Val-loss =  43.52281439931769 , Time for epoch =  0.01831507682800293 s\n",
      "Epoch  191 / 1000  : Train-loss =  52.54340981090136 , Val-loss =  43.51475123355263 , Time for epoch =  0.018540143966674805 s\n",
      "Epoch  192 / 1000  : Train-loss =  52.41947829251909 , Val-loss =  43.514702345195566 , Time for epoch =  0.018290042877197266 s\n",
      "Epoch  193 / 1000  : Train-loss =  52.29565699087024 , Val-loss =  43.51892170153166 , Time for epoch =  0.0184328556060791 s\n",
      "Epoch  194 / 1000  : Train-loss =  52.17285147629215 , Val-loss =  43.52774419282612 , Time for epoch =  0.019611835479736328 s\n",
      "Epoch  195 / 1000  : Train-loss =  52.05129793673586 , Val-loss =  43.54392945139032 , Time for epoch =  0.020343780517578125 s\n",
      "Epoch  196 / 1000  : Train-loss =  51.93031571813896 , Val-loss =  43.564216914929844 , Time for epoch =  0.022387266159057617 s\n",
      "Epoch  197 / 1000  : Train-loss =  51.812355160039694 , Val-loss =  43.59165482772024 , Time for epoch =  0.018513917922973633 s\n",
      "Epoch  198 / 1000  : Train-loss =  51.693727945877335 , Val-loss =  43.621131696199114 , Time for epoch =  0.018503427505493164 s\n",
      "Epoch  199 / 1000  : Train-loss =  51.57684128971423 , Val-loss =  43.65834707962839 , Time for epoch =  0.018940448760986328 s\n",
      "Epoch  200 / 1000  : Train-loss =  51.46247439195881 , Val-loss =  43.699661556043125 , Time for epoch =  0.019683122634887695 s\n",
      "Epoch  201 / 1000  : Train-loss =  51.34816429439911 , Val-loss =  43.74600852163214 , Time for epoch =  0.018683910369873047 s\n",
      "Epoch  202 / 1000  : Train-loss =  51.2365513602219 , Val-loss =  43.79688132436652 , Time for epoch =  0.018683671951293945 s\n",
      "Epoch  203 / 1000  : Train-loss =  51.11419027942722 , Val-loss =  43.86170959472656 , Time for epoch =  0.019522428512573242 s\n",
      "Epoch  204 / 1000  : Train-loss =  51.059126794674974 , Val-loss =  43.954003183465254 , Time for epoch =  0.019198179244995117 s\n",
      "Epoch  205 / 1000  : Train-loss =  50.947014027396165 , Val-loss =  44.029460304661804 , Time for epoch =  0.020493268966674805 s\n",
      "Epoch  206 / 1000  : Train-loss =  50.836695698021494 , Val-loss =  44.102238504510176 , Time for epoch =  0.01983499526977539 s\n",
      "Epoch  207 / 1000  : Train-loss =  50.72894696596652 , Val-loss =  44.177037590428405 , Time for epoch =  0.022852659225463867 s\n",
      "Epoch  208 / 1000  : Train-loss =  50.62322544378076 , Val-loss =  44.255461743003444 , Time for epoch =  0.019183635711669922 s\n",
      "Epoch  209 / 1000  : Train-loss =  50.51955519422973 , Val-loss =  44.33382285268683 , Time for epoch =  0.01937079429626465 s\n",
      "Epoch  210 / 1000  : Train-loss =  50.417982737223305 , Val-loss =  44.41372580277292 , Time for epoch =  0.019343852996826172 s\n",
      "Epoch  211 / 1000  : Train-loss =  50.31854944175246 , Val-loss =  44.49693398726614 , Time for epoch =  0.019158601760864258 s\n",
      "Epoch  212 / 1000  : Train-loss =  50.22129560998604 , Val-loss =  44.583181983546204 , Time for epoch =  0.019127607345581055 s\n",
      "Epoch  213 / 1000  : Train-loss =  50.1272745294086 , Val-loss =  44.67532449019583 , Time for epoch =  0.019025564193725586 s\n",
      "Epoch  214 / 1000  : Train-loss =  50.0337426137116 , Val-loss =  44.76845590691818 , Time for epoch =  0.019538402557373047 s\n",
      "Epoch  215 / 1000  : Train-loss =  49.94329566740047 , Val-loss =  44.862489198383535 , Time for epoch =  0.018814563751220703 s\n",
      "Epoch  216 / 1000  : Train-loss =  49.856271797654315 , Val-loss =  44.96122691505834 , Time for epoch =  0.020231962203979492 s\n",
      "Epoch  217 / 1000  : Train-loss =  49.76950646524375 , Val-loss =  45.059754722996765 , Time for epoch =  0.023099660873413086 s\n",
      "Epoch  218 / 1000  : Train-loss =  49.68710758187677 , Val-loss =  45.16148496928968 , Time for epoch =  0.01964116096496582 s\n",
      "Epoch  219 / 1000  : Train-loss =  49.60500221467961 , Val-loss =  45.261960682116054 , Time for epoch =  0.020562410354614258 s\n",
      "Epoch  220 / 1000  : Train-loss =  49.52727476216979 , Val-loss =  45.36489767777292 , Time for epoch =  0.02503061294555664 s\n",
      "Epoch  221 / 1000  : Train-loss =  49.44966218161718 , Val-loss =  45.46582713880037 , Time for epoch =  0.020711898803710938 s\n",
      "Epoch  222 / 1000  : Train-loss =  49.376636095639675 , Val-loss =  45.568550511410365 , Time for epoch =  0.022342443466186523 s\n",
      "Epoch  223 / 1000  : Train-loss =  49.30328563108282 , Val-loss =  45.668546174701895 , Time for epoch =  0.0193789005279541 s\n",
      "Epoch  224 / 1000  : Train-loss =  49.23494073900126 , Val-loss =  45.76974627846166 , Time for epoch =  0.020566463470458984 s\n",
      "Epoch  225 / 1000  : Train-loss =  49.16708675750905 , Val-loss =  45.87148003829153 , Time for epoch =  0.02475142478942871 s\n",
      "Epoch  226 / 1000  : Train-loss =  49.100187808106845 , Val-loss =  45.9682761744449 , Time for epoch =  0.020505666732788086 s\n",
      "Epoch  227 / 1000  : Train-loss =  49.03835986293642 , Val-loss =  46.065282219334655 , Time for epoch =  0.023317575454711914 s\n",
      "Epoch  228 / 1000  : Train-loss =  48.976719915530104 , Val-loss =  46.16202274121736 , Time for epoch =  0.019318580627441406 s\n",
      "Epoch  229 / 1000  : Train-loss =  48.91713964602368 , Val-loss =  46.257115615041634 , Time for epoch =  0.019567012786865234 s\n",
      "Epoch  230 / 1000  : Train-loss =  48.85800851940435 , Val-loss =  46.34581917210629 , Time for epoch =  0.019244670867919922 s\n",
      "Epoch  231 / 1000  : Train-loss =  48.8041464810991 , Val-loss =  46.43388718052914 , Time for epoch =  0.019889116287231445 s\n",
      "Epoch  232 / 1000  : Train-loss =  48.74997118502687 , Val-loss =  46.521058333547494 , Time for epoch =  0.019522905349731445 s\n",
      "Epoch  233 / 1000  : Train-loss =  48.69760123215153 , Val-loss =  46.60595140959087 , Time for epoch =  0.019458293914794922 s\n",
      "Epoch  234 / 1000  : Train-loss =  48.646902655477575 , Val-loss =  46.68813313935932 , Time for epoch =  0.019324541091918945 s\n",
      "Epoch  235 / 1000  : Train-loss =  48.597801122288246 , Val-loss =  46.767375343724304 , Time for epoch =  0.020448684692382812 s\n",
      "Epoch  236 / 1000  : Train-loss =  48.550209131618004 , Val-loss =  46.84358195254677 , Time for epoch =  0.020918846130371094 s\n",
      "Epoch  237 / 1000  : Train-loss =  48.50406571296649 , Val-loss =  46.916701768573965 , Time for epoch =  0.023995637893676758 s\n",
      "Epoch  238 / 1000  : Train-loss =  48.4592923525363 , Val-loss =  46.98667927792198 , Time for epoch =  0.019325971603393555 s\n",
      "Epoch  239 / 1000  : Train-loss =  48.41583154969296 , Val-loss =  47.053467198422084 , Time for epoch =  0.019227981567382812 s\n",
      "Epoch  240 / 1000  : Train-loss =  48.37360416563217 , Val-loss =  47.11703451056229 , Time for epoch =  0.019245386123657227 s\n",
      "Epoch  241 / 1000  : Train-loss =  48.33255759201481 , Val-loss =  47.17740149247019 , Time for epoch =  0.019344568252563477 s\n",
      "Epoch  242 / 1000  : Train-loss =  48.29261917717713 , Val-loss =  47.23461151123047 , Time for epoch =  0.0193023681640625 s\n",
      "Epoch  243 / 1000  : Train-loss =  48.25373271360235 , Val-loss =  47.28861437345806 , Time for epoch =  0.01914048194885254 s\n",
      "Epoch  244 / 1000  : Train-loss =  48.21584283430024 , Val-loss =  47.339530643663906 , Time for epoch =  0.02059459686279297 s\n",
      "Epoch  245 / 1000  : Train-loss =  48.1788925989873 , Val-loss =  47.3853376288163 , Time for epoch =  0.020258426666259766 s\n",
      "Epoch  246 / 1000  : Train-loss =  48.14282989501953 , Val-loss =  47.426701194361634 , Time for epoch =  0.02208995819091797 s\n",
      "Epoch  247 / 1000  : Train-loss =  48.107599032127254 , Val-loss =  47.46519811529862 , Time for epoch =  0.024047136306762695 s\n",
      "Epoch  248 / 1000  : Train-loss =  48.07315190633138 , Val-loss =  47.500890832198294 , Time for epoch =  0.021137714385986328 s\n",
      "Epoch  249 / 1000  : Train-loss =  48.03945310775843 , Val-loss =  47.53383405585038 , Time for epoch =  0.02027440071105957 s\n",
      "Epoch  250 / 1000  : Train-loss =  48.006450588420286 , Val-loss =  47.56411943937603 , Time for epoch =  0.019732236862182617 s\n",
      "Epoch  251 / 1000  : Train-loss =  47.974099692651784 , Val-loss =  47.59184947766756 , Time for epoch =  0.019431591033935547 s\n",
      "Epoch  252 / 1000  : Train-loss =  47.94237860986742 , Val-loss =  47.61707566913805 , Time for epoch =  0.019661664962768555 s\n",
      "Epoch  253 / 1000  : Train-loss =  47.911237468827245 , Val-loss =  47.63982371280068 , Time for epoch =  0.019111156463623047 s\n",
      "Epoch  254 / 1000  : Train-loss =  47.880651010631844 , Val-loss =  47.66015655116031 , Time for epoch =  0.01885843276977539 s\n",
      "Epoch  255 / 1000  : Train-loss =  47.85057813568977 , Val-loss =  47.67826863339073 , Time for epoch =  0.019708633422851562 s\n",
      "Epoch  256 / 1000  : Train-loss =  47.820997442902815 , Val-loss =  47.69422972829718 , Time for epoch =  0.01967334747314453 s\n",
      "Epoch  257 / 1000  : Train-loss =  47.791890031200346 , Val-loss =  47.70494993109452 , Time for epoch =  0.022909879684448242 s\n",
      "Epoch  258 / 1000  : Train-loss =  47.76321415443205 , Val-loss =  47.71354835911801 , Time for epoch =  0.01848006248474121 s\n",
      "Epoch  259 / 1000  : Train-loss =  47.734954402945135 , Val-loss =  47.72031844289679 , Time for epoch =  0.018218517303466797 s\n",
      "Epoch  260 / 1000  : Train-loss =  47.70708681095791 , Val-loss =  47.72533476980109 , Time for epoch =  0.01824474334716797 s\n",
      "Epoch  261 / 1000  : Train-loss =  47.8567821265614 , Val-loss =  47.850154073614824 , Time for epoch =  0.018149852752685547 s\n",
      "Epoch  262 / 1000  : Train-loss =  47.83067882128355 , Val-loss =  47.882566351639596 , Time for epoch =  0.018352985382080078 s\n",
      "Epoch  263 / 1000  : Train-loss =  47.79730935824119 , Val-loss =  47.890301152279505 , Time for epoch =  0.01891493797302246 s\n",
      "Epoch  264 / 1000  : Train-loss =  47.76766655269989 , Val-loss =  47.895612616288034 , Time for epoch =  0.02310919761657715 s\n",
      "Epoch  265 / 1000  : Train-loss =  47.73859614571609 , Val-loss =  47.89934720491108 , Time for epoch =  0.01896977424621582 s\n",
      "Epoch  266 / 1000  : Train-loss =  47.710058201504296 , Val-loss =  47.9016066099468 , Time for epoch =  0.019930601119995117 s\n",
      "Epoch  267 / 1000  : Train-loss =  47.68200610317079 , Val-loss =  47.90259050068102 , Time for epoch =  0.020628690719604492 s\n",
      "Epoch  268 / 1000  : Train-loss =  47.65441482888777 , Val-loss =  47.90233059933311 , Time for epoch =  0.02708148956298828 s\n",
      "Epoch  269 / 1000  : Train-loss =  47.62725047741906 , Val-loss =  47.90087629619398 , Time for epoch =  0.019426584243774414 s\n",
      "Epoch  270 / 1000  : Train-loss =  47.60047123795849 , Val-loss =  47.89830027128521 , Time for epoch =  0.01900458335876465 s\n",
      "Epoch  271 / 1000  : Train-loss =  47.77048585105077 , Val-loss =  47.98634117528012 , Time for epoch =  0.01913619041442871 s\n",
      "Epoch  272 / 1000  : Train-loss =  47.738543127889685 , Val-loss =  47.98727115831877 , Time for epoch =  0.01914811134338379 s\n",
      "Epoch  273 / 1000  : Train-loss =  47.7068384892523 , Val-loss =  47.97335775274979 , Time for epoch =  0.021054506301879883 s\n",
      "Epoch  274 / 1000  : Train-loss =  47.67597539007327 , Val-loss =  47.957421352988796 , Time for epoch =  0.019885778427124023 s\n",
      "Epoch  275 / 1000  : Train-loss =  47.64601904658948 , Val-loss =  47.94175298590409 , Time for epoch =  0.019501924514770508 s\n",
      "Epoch  276 / 1000  : Train-loss =  47.61686975942493 , Val-loss =  47.92599447149979 , Time for epoch =  0.02064681053161621 s\n",
      "Epoch  277 / 1000  : Train-loss =  47.58845670883265 , Val-loss =  47.910972795988386 , Time for epoch =  0.01990795135498047 s\n",
      "Epoch  278 / 1000  : Train-loss =  47.56208038330078 , Val-loss =  47.897401307758535 , Time for epoch =  0.02372884750366211 s\n",
      "Epoch  279 / 1000  : Train-loss =  47.53579880019366 , Val-loss =  47.88234831157484 , Time for epoch =  0.01978445053100586 s\n",
      "Epoch  280 / 1000  : Train-loss =  47.50989502297956 , Val-loss =  47.86695249457108 , Time for epoch =  0.01892685890197754 s\n",
      "Epoch  281 / 1000  : Train-loss =  47.483007700429795 , Val-loss =  47.85049639250103 , Time for epoch =  0.018815040588378906 s\n",
      "Epoch  282 / 1000  : Train-loss =  47.45829882864225 , Val-loss =  47.83645509418688 , Time for epoch =  0.019975662231445312 s\n",
      "Epoch  283 / 1000  : Train-loss =  47.43360448287705 , Val-loss =  47.820906388132194 , Time for epoch =  0.0197446346282959 s\n",
      "Epoch  284 / 1000  : Train-loss =  47.40777402543752 , Val-loss =  47.80134662828947 , Time for epoch =  0.019505739212036133 s\n",
      "Epoch  285 / 1000  : Train-loss =  47.38680189746921 , Val-loss =  47.78248726694208 , Time for epoch =  0.019469261169433594 s\n",
      "Epoch  286 / 1000  : Train-loss =  47.362761244262 , Val-loss =  47.764860454358555 , Time for epoch =  0.020228147506713867 s\n",
      "Epoch  287 / 1000  : Train-loss =  47.33902253404175 , Val-loss =  47.74722330193771 , Time for epoch =  0.02330303192138672 s\n",
      "Epoch  288 / 1000  : Train-loss =  47.315552037988006 , Val-loss =  47.72928237915039 , Time for epoch =  0.01952362060546875 s\n",
      "Epoch  289 / 1000  : Train-loss =  47.29232130751098 , Val-loss =  47.71101018002159 , Time for epoch =  0.022152185440063477 s\n",
      "Epoch  290 / 1000  : Train-loss =  47.26777028229277 , Val-loss =  47.68898391723633 , Time for epoch =  0.01939225196838379 s\n",
      "Epoch  291 / 1000  : Train-loss =  47.248312826210494 , Val-loss =  47.6677121614155 , Time for epoch =  0.01909017562866211 s\n",
      "Epoch  292 / 1000  : Train-loss =  47.22560979552188 , Val-loss =  47.647751456812806 , Time for epoch =  0.025182485580444336 s\n",
      "Epoch  293 / 1000  : Train-loss =  47.20316508664923 , Val-loss =  47.627832914653574 , Time for epoch =  0.020955801010131836 s\n",
      "Epoch  294 / 1000  : Train-loss =  47.180937535345215 , Val-loss =  47.60772604691355 , Time for epoch =  0.019438505172729492 s\n",
      "Epoch  295 / 1000  : Train-loss =  47.15891774495443 , Val-loss =  47.587304968582956 , Time for epoch =  0.019377708435058594 s\n",
      "Epoch  296 / 1000  : Train-loss =  47.13708838769945 , Val-loss =  47.56669154920076 , Time for epoch =  0.021108388900756836 s\n",
      "Epoch  297 / 1000  : Train-loss =  47.115453148965784 , Val-loss =  47.545780181884766 , Time for epoch =  0.021157026290893555 s\n",
      "Epoch  298 / 1000  : Train-loss =  47.094005455405025 , Val-loss =  47.524592750950866 , Time for epoch =  0.02385687828063965 s\n",
      "Epoch  299 / 1000  : Train-loss =  47.072724897309214 , Val-loss =  47.503156561600534 , Time for epoch =  0.019832611083984375 s\n",
      "Epoch  300 / 1000  : Train-loss =  47.05162087133375 , Val-loss =  47.48148687262284 , Time for epoch =  0.020028352737426758 s\n",
      "Epoch  301 / 1000  : Train-loss =  47.030686373091015 , Val-loss =  47.45958167628238 , Time for epoch =  0.01958179473876953 s\n",
      "Epoch  302 / 1000  : Train-loss =  47.00990579896054 , Val-loss =  47.43743294163754 , Time for epoch =  0.01901102066040039 s\n",
      "Epoch  303 / 1000  : Train-loss =  46.9892792782541 , Val-loss =  47.4150948775442 , Time for epoch =  0.01964402198791504 s\n",
      "Epoch  304 / 1000  : Train-loss =  46.968799504856605 , Val-loss =  47.392525923879525 , Time for epoch =  0.02048349380493164 s\n",
      "Epoch  305 / 1000  : Train-loss =  46.94846889258778 , Val-loss =  47.36975418893915 , Time for epoch =  0.019861936569213867 s\n",
      "Epoch  306 / 1000  : Train-loss =  46.92828535090732 , Val-loss =  47.34678991217362 , Time for epoch =  0.02284860610961914 s\n",
      "Epoch  307 / 1000  : Train-loss =  46.908231508933895 , Val-loss =  47.3236363059596 , Time for epoch =  0.027957677841186523 s\n",
      "Epoch  308 / 1000  : Train-loss =  46.88830753908319 , Val-loss =  47.30034075285259 , Time for epoch =  0.025159597396850586 s\n",
      "Epoch  309 / 1000  : Train-loss =  46.86852600614903 , Val-loss =  47.276865105879935 , Time for epoch =  0.022904396057128906 s\n",
      "Epoch  310 / 1000  : Train-loss =  46.84886497023415 , Val-loss =  47.2532276354338 , Time for epoch =  0.018488407135009766 s\n",
      "Epoch  311 / 1000  : Train-loss =  46.82933219004486 , Val-loss =  47.22944460417095 , Time for epoch =  0.018265485763549805 s\n",
      "Epoch  312 / 1000  : Train-loss =  46.80992484227412 , Val-loss =  47.205569217079564 , Time for epoch =  0.018233299255371094 s\n",
      "Epoch  313 / 1000  : Train-loss =  46.79063409061755 , Val-loss =  47.181546662983145 , Time for epoch =  0.018138408660888672 s\n",
      "Epoch  314 / 1000  : Train-loss =  46.771463835980256 , Val-loss =  47.15739681846217 , Time for epoch =  0.018150806427001953 s\n",
      "Epoch  315 / 1000  : Train-loss =  46.75240297910184 , Val-loss =  47.13313514307926 , Time for epoch =  0.0198974609375 s\n",
      "Epoch  316 / 1000  : Train-loss =  46.73345184326172 , Val-loss =  47.10879396137438 , Time for epoch =  0.025876998901367188 s\n",
      "Epoch  317 / 1000  : Train-loss =  46.714613057799255 , Val-loss =  47.08431203741776 , Time for epoch =  0.026949167251586914 s\n",
      "Epoch  318 / 1000  : Train-loss =  46.69587625622076 , Val-loss =  47.05975683111893 , Time for epoch =  0.02613544464111328 s\n",
      "Epoch  319 / 1000  : Train-loss =  46.67724986534334 , Val-loss =  47.035150829114414 , Time for epoch =  0.022338390350341797 s\n",
      "Epoch  320 / 1000  : Train-loss =  46.65872830320886 , Val-loss =  47.01044383801912 , Time for epoch =  0.019371747970581055 s\n",
      "Epoch  321 / 1000  : Train-loss =  46.64030204385014 , Val-loss =  46.985679024144225 , Time for epoch =  0.020832538604736328 s\n",
      "Epoch  322 / 1000  : Train-loss =  46.62198490207478 , Val-loss =  46.96086903622276 , Time for epoch =  0.018517732620239258 s\n",
      "Epoch  323 / 1000  : Train-loss =  46.60376416222524 , Val-loss =  46.93596849943462 , Time for epoch =  0.018085956573486328 s\n",
      "Epoch  324 / 1000  : Train-loss =  46.58562473792814 , Val-loss =  46.91105149921618 , Time for epoch =  0.018296241760253906 s\n",
      "Epoch  325 / 1000  : Train-loss =  46.567588827704306 , Val-loss =  46.8860555949964 , Time for epoch =  0.018382549285888672 s\n",
      "Epoch  326 / 1000  : Train-loss =  46.549647164210086 , Val-loss =  46.86107173718904 , Time for epoch =  0.022280454635620117 s\n",
      "Epoch  327 / 1000  : Train-loss =  46.53179360513633 , Val-loss =  46.836002952174134 , Time for epoch =  0.019342422485351562 s\n",
      "Epoch  328 / 1000  : Train-loss =  46.51402832289874 , Val-loss =  46.81091228284334 , Time for epoch =  0.022372722625732422 s\n",
      "Epoch  329 / 1000  : Train-loss =  46.496352050264 , Val-loss =  46.78583365992496 , Time for epoch =  0.018924713134765625 s\n",
      "Epoch  330 / 1000  : Train-loss =  46.47876349411442 , Val-loss =  46.76068617168226 , Time for epoch =  0.018661975860595703 s\n",
      "Epoch  331 / 1000  : Train-loss =  46.46125640438101 , Val-loss =  46.735555146869864 , Time for epoch =  0.018162012100219727 s\n",
      "Epoch  332 / 1000  : Train-loss =  46.44383261298056 , Val-loss =  46.710366901598476 , Time for epoch =  0.018089771270751953 s\n",
      "Epoch  333 / 1000  : Train-loss =  46.42649382251804 , Val-loss =  46.68521820871454 , Time for epoch =  0.01797628402709961 s\n",
      "Epoch  334 / 1000  : Train-loss =  46.409235765705 , Val-loss =  46.66002554642527 , Time for epoch =  0.018061399459838867 s\n",
      "Epoch  335 / 1000  : Train-loss =  46.39205596406581 , Val-loss =  46.63485597309313 , Time for epoch =  0.017989397048950195 s\n",
      "Epoch  336 / 1000  : Train-loss =  46.374958965064444 , Val-loss =  46.6096719440661 , Time for epoch =  0.018189191818237305 s\n",
      "Epoch  337 / 1000  : Train-loss =  46.3579450488764 , Val-loss =  46.58451522024054 , Time for epoch =  0.019535541534423828 s\n",
      "Epoch  338 / 1000  : Train-loss =  46.34099152128575 , Val-loss =  46.55931713706568 , Time for epoch =  0.019170761108398438 s\n",
      "Epoch  339 / 1000  : Train-loss =  46.324124955861585 , Val-loss =  46.534177679764596 , Time for epoch =  0.022159099578857422 s\n",
      "Epoch  340 / 1000  : Train-loss =  46.307326645500915 , Val-loss =  46.50902557373047 , Time for epoch =  0.01985311508178711 s\n",
      "Epoch  341 / 1000  : Train-loss =  46.290600448004945 , Val-loss =  46.48388029399671 , Time for epoch =  0.019598722457885742 s\n",
      "Epoch  342 / 1000  : Train-loss =  46.273950587558204 , Val-loss =  46.45876352410568 , Time for epoch =  0.01869034767150879 s\n",
      "Epoch  343 / 1000  : Train-loss =  46.25737687019305 , Val-loss =  46.43360559563888 , Time for epoch =  0.018658161163330078 s\n",
      "Epoch  344 / 1000  : Train-loss =  46.24086765785002 , Val-loss =  46.40845409192537 , Time for epoch =  0.01852893829345703 s\n",
      "Epoch  345 / 1000  : Train-loss =  46.22442939456573 , Val-loss =  46.38332728335732 , Time for epoch =  0.01919865608215332 s\n",
      "Epoch  346 / 1000  : Train-loss =  46.20806335190595 , Val-loss =  46.35822446722733 , Time for epoch =  0.020057201385498047 s\n",
      "Epoch  347 / 1000  : Train-loss =  46.19176196513203 , Val-loss =  46.33316732707777 , Time for epoch =  0.019034385681152344 s\n",
      "Epoch  348 / 1000  : Train-loss =  46.17552807910294 , Val-loss =  46.30813126814993 , Time for epoch =  0.020219087600708008 s\n",
      "Epoch  349 / 1000  : Train-loss =  46.15936824561513 , Val-loss =  46.283127433375306 , Time for epoch =  0.019513368606567383 s\n",
      "Epoch  350 / 1000  : Train-loss =  46.14326520154705 , Val-loss =  46.25814016241776 , Time for epoch =  0.02347850799560547 s\n",
      "Epoch  351 / 1000  : Train-loss =  46.127233666888735 , Val-loss =  46.23319595738461 , Time for epoch =  0.019784927368164062 s\n",
      "Epoch  352 / 1000  : Train-loss =  46.11126053804732 , Val-loss =  46.20829150551244 , Time for epoch =  0.019093751907348633 s\n",
      "Epoch  353 / 1000  : Train-loss =  46.09535236681922 , Val-loss =  46.18343413503546 , Time for epoch =  0.01952338218688965 s\n",
      "Epoch  354 / 1000  : Train-loss =  46.079506976456294 , Val-loss =  46.15858620091488 , Time for epoch =  0.019212007522583008 s\n",
      "Epoch  355 / 1000  : Train-loss =  46.06372270745746 , Val-loss =  46.13377330177709 , Time for epoch =  0.018774747848510742 s\n",
      "Epoch  356 / 1000  : Train-loss =  46.04800708145745 , Val-loss =  46.10901943006014 , Time for epoch =  0.018297195434570312 s\n",
      "Epoch  357 / 1000  : Train-loss =  46.032341951704296 , Val-loss =  46.08430862426758 , Time for epoch =  0.01798844337463379 s\n",
      "Epoch  358 / 1000  : Train-loss =  46.01674585288527 , Val-loss =  46.05959591112639 , Time for epoch =  0.019591331481933594 s\n",
      "Epoch  359 / 1000  : Train-loss =  46.00120675900562 , Val-loss =  46.03499141492342 , Time for epoch =  0.02311849594116211 s\n",
      "Epoch  360 / 1000  : Train-loss =  45.98572697612526 , Val-loss =  46.01036654020611 , Time for epoch =  0.020241975784301758 s\n",
      "Epoch  361 / 1000  : Train-loss =  45.970300792974264 , Val-loss =  45.98583813717491 , Time for epoch =  0.023096799850463867 s\n",
      "Epoch  362 / 1000  : Train-loss =  45.95493900708559 , Val-loss =  45.96131896972656 , Time for epoch =  0.01981663703918457 s\n",
      "Epoch  363 / 1000  : Train-loss =  45.93963004505567 , Val-loss =  45.93687659815738 , Time for epoch =  0.019120216369628906 s\n",
      "Epoch  364 / 1000  : Train-loss =  45.92437366981291 , Val-loss =  45.91243603355006 , Time for epoch =  0.020359277725219727 s\n",
      "Epoch  365 / 1000  : Train-loss =  45.909178868525444 , Val-loss =  45.888080396150286 , Time for epoch =  0.019868135452270508 s\n",
      "Epoch  366 / 1000  : Train-loss =  45.89404083510577 , Val-loss =  45.86375356975355 , Time for epoch =  0.020329952239990234 s\n",
      "Epoch  367 / 1000  : Train-loss =  45.87895541002521 , Val-loss =  45.83950163188734 , Time for epoch =  0.018116474151611328 s\n",
      "Epoch  368 / 1000  : Train-loss =  45.86393259339413 , Val-loss =  45.815277802316764 , Time for epoch =  0.018880844116210938 s\n",
      "Epoch  369 / 1000  : Train-loss =  45.84895839798922 , Val-loss =  45.79111039011102 , Time for epoch =  0.02013111114501953 s\n",
      "Epoch  370 / 1000  : Train-loss =  45.83403950491868 , Val-loss =  45.766964159513776 , Time for epoch =  0.022172212600708008 s\n",
      "Epoch  371 / 1000  : Train-loss =  45.81917290768381 , Val-loss =  45.742882778770046 , Time for epoch =  0.02324056625366211 s\n",
      "Epoch  372 / 1000  : Train-loss =  45.80435605237713 , Val-loss =  45.71883854113127 , Time for epoch =  0.021661043167114258 s\n",
      "Epoch  373 / 1000  : Train-loss =  45.78959493044406 , Val-loss =  45.694853933233965 , Time for epoch =  0.022289752960205078 s\n",
      "Epoch  374 / 1000  : Train-loss =  45.774881287483176 , Val-loss =  45.67095033746017 , Time for epoch =  0.019834280014038086 s\n",
      "Epoch  375 / 1000  : Train-loss =  45.76022582404357 , Val-loss =  45.64708147550884 , Time for epoch =  0.018861055374145508 s\n",
      "Epoch  376 / 1000  : Train-loss =  45.7442790101477 , Val-loss =  45.620579970510384 , Time for epoch =  0.01887989044189453 s\n",
      "Epoch  377 / 1000  : Train-loss =  45.73273409827281 , Val-loss =  45.59482203031841 , Time for epoch =  0.018733501434326172 s\n",
      "Epoch  378 / 1000  : Train-loss =  45.71809107031526 , Val-loss =  45.5705220071893 , Time for epoch =  0.01902627944946289 s\n",
      "Epoch  379 / 1000  : Train-loss =  45.70353741834393 , Val-loss =  45.546593515496504 , Time for epoch =  0.020377159118652344 s\n",
      "Epoch  380 / 1000  : Train-loss =  45.68904905804133 , Val-loss =  45.52284652308414 , Time for epoch =  0.022117137908935547 s\n",
      "Epoch  381 / 1000  : Train-loss =  45.67461700223934 , Val-loss =  45.499205137553965 , Time for epoch =  0.019011497497558594 s\n",
      "Epoch  382 / 1000  : Train-loss =  45.66024200525661 , Val-loss =  45.47568552117599 , Time for epoch =  0.022380828857421875 s\n",
      "Epoch  383 / 1000  : Train-loss =  45.64458445101808 , Val-loss =  45.44691316705001 , Time for epoch =  0.018288373947143555 s\n",
      "Epoch  384 / 1000  : Train-loss =  45.63334706408829 , Val-loss =  45.41806803251568 , Time for epoch =  0.01849222183227539 s\n",
      "Epoch  385 / 1000  : Train-loss =  45.61898948109083 , Val-loss =  45.39065842879446 , Time for epoch =  0.018851757049560547 s\n",
      "Epoch  386 / 1000  : Train-loss =  45.60473438844843 , Val-loss =  45.36362718280993 , Time for epoch =  0.019070148468017578 s\n",
      "Epoch  387 / 1000  : Train-loss =  45.59053242139223 , Val-loss =  45.336801629317435 , Time for epoch =  0.019181489944458008 s\n",
      "Epoch  388 / 1000  : Train-loss =  45.57639926975056 , Val-loss =  45.31012434708445 , Time for epoch =  0.018947362899780273 s\n",
      "Epoch  389 / 1000  : Train-loss =  45.56068299719169 , Val-loss =  45.27095493517424 , Time for epoch =  0.01926422119140625 s\n",
      "Epoch  390 / 1000  : Train-loss =  45.55096085327493 , Val-loss =  45.2532316509046 , Time for epoch =  0.021265745162963867 s\n",
      "Epoch  391 / 1000  : Train-loss =  45.537311209123686 , Val-loss =  45.224939848247324 , Time for epoch =  0.019776105880737305 s\n",
      "Epoch  392 / 1000  : Train-loss =  45.52307557790293 , Val-loss =  45.197737442819694 , Time for epoch =  0.021329879760742188 s\n",
      "Epoch  393 / 1000  : Train-loss =  45.50896001266221 , Val-loss =  45.170942406905326 , Time for epoch =  0.021718502044677734 s\n",
      "Epoch  394 / 1000  : Train-loss =  45.49375280822064 , Val-loss =  45.14151874341463 , Time for epoch =  0.020177125930786133 s\n",
      "Epoch  395 / 1000  : Train-loss =  45.482306291828046 , Val-loss =  45.10356089943334 , Time for epoch =  0.019722461700439453 s\n",
      "Epoch  396 / 1000  : Train-loss =  45.46965883545956 , Val-loss =  45.087519796271074 , Time for epoch =  0.018645048141479492 s\n",
      "Epoch  397 / 1000  : Train-loss =  45.45622135959776 , Val-loss =  45.05985219855057 , Time for epoch =  0.019061803817749023 s\n",
      "Epoch  398 / 1000  : Train-loss =  45.44095956403657 , Val-loss =  45.030318912706875 , Time for epoch =  0.019090652465820312 s\n",
      "Epoch  399 / 1000  : Train-loss =  45.429967007394566 , Val-loss =  45.00218110335501 , Time for epoch =  0.019112586975097656 s\n",
      "Epoch  400 / 1000  : Train-loss =  45.41561554515429 , Val-loss =  44.965912768715306 , Time for epoch =  0.020380735397338867 s\n",
      "Epoch  401 / 1000  : Train-loss =  45.40315800467454 , Val-loss =  44.95042519820364 , Time for epoch =  0.01988077163696289 s\n",
      "Epoch  402 / 1000  : Train-loss =  45.388715991866114 , Val-loss =  44.92047450416967 , Time for epoch =  0.019978761672973633 s\n",
      "Epoch  403 / 1000  : Train-loss =  45.37770993291995 , Val-loss =  44.89242493478876 , Time for epoch =  0.023702383041381836 s\n",
      "Epoch  404 / 1000  : Train-loss =  45.36343246934104 , Val-loss =  44.856805299457754 , Time for epoch =  0.01971721649169922 s\n",
      "Epoch  405 / 1000  : Train-loss =  45.35109655735857 , Val-loss =  44.84110430667275 , Time for epoch =  0.018798351287841797 s\n",
      "Epoch  406 / 1000  : Train-loss =  45.33685909422104 , Val-loss =  44.81146742168226 , Time for epoch =  0.018670082092285156 s\n",
      "Epoch  407 / 1000  : Train-loss =  45.32582011465299 , Val-loss =  44.78376669632761 , Time for epoch =  0.019224882125854492 s\n",
      "Epoch  408 / 1000  : Train-loss =  45.31164733972927 , Val-loss =  44.7486071335642 , Time for epoch =  0.01940178871154785 s\n",
      "Epoch  409 / 1000  : Train-loss =  45.29836091079281 , Val-loss =  44.73038201583059 , Time for epoch =  0.019686460494995117 s\n",
      "Epoch  410 / 1000  : Train-loss =  45.2880537065409 , Val-loss =  44.70212424428839 , Time for epoch =  0.019867897033691406 s\n",
      "Epoch  411 / 1000  : Train-loss =  45.27427237990212 , Val-loss =  44.676048579968906 , Time for epoch =  0.01990365982055664 s\n",
      "Epoch  412 / 1000  : Train-loss =  45.259176782295526 , Val-loss =  44.63882476405094 , Time for epoch =  0.019638776779174805 s\n",
      "Epoch  413 / 1000  : Train-loss =  45.24993297339833 , Val-loss =  44.622129339920846 , Time for epoch =  0.024021387100219727 s\n",
      "Epoch  414 / 1000  : Train-loss =  45.23683128787973 , Val-loss =  44.59562893917686 , Time for epoch =  0.022840499877929688 s\n",
      "Epoch  415 / 1000  : Train-loss =  45.22219354015286 , Val-loss =  44.567610690468236 , Time for epoch =  0.020478010177612305 s\n",
      "Epoch  416 / 1000  : Train-loss =  45.21111159674865 , Val-loss =  44.531612597013776 , Time for epoch =  0.018421411514282227 s\n",
      "Epoch  417 / 1000  : Train-loss =  45.199053489555745 , Val-loss =  44.51696666918303 , Time for epoch =  0.018498897552490234 s\n",
      "Epoch  418 / 1000  : Train-loss =  45.18521079370531 , Val-loss =  44.4885119387978 , Time for epoch =  0.018222808837890625 s\n",
      "Epoch  419 / 1000  : Train-loss =  45.174042232966016 , Val-loss =  44.45307932401958 , Time for epoch =  0.019324064254760742 s\n",
      "Epoch  420 / 1000  : Train-loss =  45.160906807850985 , Val-loss =  44.435454619558236 , Time for epoch =  0.01997518539428711 s\n",
      "Epoch  421 / 1000  : Train-loss =  45.150918023060946 , Val-loss =  44.408152530067845 , Time for epoch =  0.021082639694213867 s\n",
      "Epoch  422 / 1000  : Train-loss =  45.13740821881483 , Val-loss =  44.38312450208162 , Time for epoch =  0.019184350967407227 s\n",
      "Epoch  423 / 1000  : Train-loss =  45.122728250794495 , Val-loss =  44.346637525056536 , Time for epoch =  0.022524595260620117 s\n",
      "Epoch  424 / 1000  : Train-loss =  45.11364247165831 , Val-loss =  44.331507331446595 , Time for epoch =  0.01861858367919922 s\n",
      "Epoch  425 / 1000  : Train-loss =  45.09976518490894 , Val-loss =  44.303538372642116 , Time for epoch =  0.018114805221557617 s\n",
      "Epoch  426 / 1000  : Train-loss =  45.08891300697111 , Val-loss =  44.26828033045719 , Time for epoch =  0.018036842346191406 s\n",
      "Epoch  427 / 1000  : Train-loss =  45.07706929869571 , Val-loss =  44.25438198290373 , Time for epoch =  0.0185244083404541 s\n",
      "Epoch  428 / 1000  : Train-loss =  45.06357600325245 , Val-loss =  44.226934031436315 , Time for epoch =  0.01976609230041504 s\n",
      "Epoch  429 / 1000  : Train-loss =  45.05252324120473 , Val-loss =  44.19216939022667 , Time for epoch =  0.020916223526000977 s\n",
      "Epoch  430 / 1000  : Train-loss =  45.03987539690093 , Val-loss =  44.175871196546055 , Time for epoch =  0.032712459564208984 s\n",
      "Epoch  431 / 1000  : Train-loss =  45.029915761139435 , Val-loss =  44.149618449964024 , Time for epoch =  0.023470163345336914 s\n",
      "Epoch  432 / 1000  : Train-loss =  45.01530455465371 , Val-loss =  44.113786697387695 , Time for epoch =  0.019601821899414062 s\n",
      "Epoch  433 / 1000  : Train-loss =  45.00640779699983 , Val-loss =  44.09896489193565 , Time for epoch =  0.02509617805480957 s\n",
      "Epoch  434 / 1000  : Train-loss =  44.99277665520792 , Val-loss =  44.071768509714225 , Time for epoch =  0.03671717643737793 s\n",
      "Epoch  435 / 1000  : Train-loss =  44.982013573080806 , Val-loss =  44.037296897486634 , Time for epoch =  0.03120732307434082 s\n",
      "Epoch  436 / 1000  : Train-loss =  44.96937878926595 , Val-loss =  44.02171948081568 , Time for epoch =  0.0258638858795166 s\n",
      "Epoch  437 / 1000  : Train-loss =  44.95924326794296 , Val-loss =  43.98753708287289 , Time for epoch =  0.030658721923828125 s\n",
      "Epoch  438 / 1000  : Train-loss =  44.94663496071336 , Val-loss =  43.97096091822574 , Time for epoch =  0.027201414108276367 s\n",
      "Epoch  439 / 1000  : Train-loss =  44.9368064363124 , Val-loss =  43.94529934933311 , Time for epoch =  0.019311189651489258 s\n",
      "Epoch  440 / 1000  : Train-loss =  44.92234653537556 , Val-loss =  43.910525472540606 , Time for epoch =  0.02041912078857422 s\n",
      "Epoch  441 / 1000  : Train-loss =  44.913587074495304 , Val-loss =  43.896011653699375 , Time for epoch =  0.03160810470581055 s\n",
      "Epoch  442 / 1000  : Train-loss =  44.90021064456573 , Val-loss =  43.86965219598068 , Time for epoch =  0.020021915435791016 s\n",
      "Epoch  443 / 1000  : Train-loss =  44.73343065768312 , Val-loss =  43.7428314811305 , Time for epoch =  0.018979549407958984 s\n",
      "Epoch  444 / 1000  : Train-loss =  44.71771602307336 , Val-loss =  43.70435483832108 , Time for epoch =  0.019037961959838867 s\n",
      "Epoch  445 / 1000  : Train-loss =  44.7047244357524 , Val-loss =  43.66873821459318 , Time for epoch =  0.019269943237304688 s\n",
      "Epoch  446 / 1000  : Train-loss =  44.69178493952347 , Val-loss =  43.637521844161185 , Time for epoch =  0.021795988082885742 s\n",
      "Epoch  447 / 1000  : Train-loss =  44.67867161594542 , Val-loss =  43.599676634135996 , Time for epoch =  0.019896984100341797 s\n",
      "Epoch  448 / 1000  : Train-loss =  44.66740089890647 , Val-loss =  43.58036332381399 , Time for epoch =  0.020461559295654297 s\n",
      "Epoch  449 / 1000  : Train-loss =  44.655290441997984 , Val-loss =  43.5513377942537 , Time for epoch =  0.019658803939819336 s\n",
      "Epoch  450 / 1000  : Train-loss =  44.6427533855546 , Val-loss =  43.5235605741802 , Time for epoch =  0.01998734474182129 s\n",
      "Epoch  451 / 1000  : Train-loss =  44.63037150323728 , Val-loss =  43.496462069059675 , Time for epoch =  0.024691343307495117 s\n",
      "Epoch  452 / 1000  : Train-loss =  44.617679488187456 , Val-loss =  43.46118244371916 , Time for epoch =  0.019698619842529297 s\n",
      "Epoch  453 / 1000  : Train-loss =  44.60681111395022 , Val-loss =  43.44467494362279 , Time for epoch =  0.01964879035949707 s\n",
      "Epoch  454 / 1000  : Train-loss =  44.595095295017046 , Val-loss =  43.41770854749178 , Time for epoch =  0.019820213317871094 s\n",
      "Epoch  455 / 1000  : Train-loss =  44.58292227276301 , Val-loss =  43.39171871386076 , Time for epoch =  0.018651962280273438 s\n",
      "Epoch  456 / 1000  : Train-loss =  44.570466812047584 , Val-loss =  43.35748883297569 , Time for epoch =  0.01845097541809082 s\n",
      "Epoch  457 / 1000  : Train-loss =  44.559816349697655 , Val-loss =  43.341868450767116 , Time for epoch =  0.01895594596862793 s\n",
      "Epoch  458 / 1000  : Train-loss =  44.54831422924322 , Val-loss =  43.315777226498255 , Time for epoch =  0.021487951278686523 s\n",
      "Epoch  459 / 1000  : Train-loss =  44.53592643091234 , Val-loss =  43.282496000591074 , Time for epoch =  0.022635936737060547 s\n",
      "Epoch  460 / 1000  : Train-loss =  44.52542187534483 , Val-loss =  43.266644728811166 , Time for epoch =  0.020853042602539062 s\n",
      "Epoch  461 / 1000  : Train-loss =  44.51398605950135 , Val-loss =  43.240920518573965 , Time for epoch =  0.019387006759643555 s\n",
      "Epoch  462 / 1000  : Train-loss =  44.50212590707898 , Val-loss =  43.216087642468906 , Time for epoch =  0.024918079376220703 s\n",
      "Epoch  463 / 1000  : Train-loss =  44.489973445396636 , Val-loss =  43.18325906050833 , Time for epoch =  0.019270896911621094 s\n",
      "Epoch  464 / 1000  : Train-loss =  44.47964605773236 , Val-loss =  43.16843805815044 , Time for epoch =  0.020653963088989258 s\n",
      "Epoch  465 / 1000  : Train-loss =  44.467071856482555 , Val-loss =  43.14092274716026 , Time for epoch =  0.02001214027404785 s\n",
      "Epoch  466 / 1000  : Train-loss =  44.457557462703036 , Val-loss =  43.10694282933285 , Time for epoch =  0.01887989044189453 s\n",
      "Epoch  467 / 1000  : Train-loss =  44.447179815863485 , Val-loss =  43.091493104633535 , Time for epoch =  0.01928567886352539 s\n",
      "Epoch  468 / 1000  : Train-loss =  44.435921189475195 , Val-loss =  43.06648585670873 , Time for epoch =  0.02077484130859375 s\n",
      "Epoch  469 / 1000  : Train-loss =  44.42425758016985 , Val-loss =  43.042413209614004 , Time for epoch =  0.02002573013305664 s\n",
      "Epoch  470 / 1000  : Train-loss =  44.41229456023308 , Val-loss =  43.01020792910927 , Time for epoch =  0.019588947296142578 s\n",
      "Epoch  471 / 1000  : Train-loss =  44.402171204992605 , Val-loss =  42.99633226896587 , Time for epoch =  0.020081281661987305 s\n",
      "Epoch  472 / 1000  : Train-loss =  44.391145253585556 , Val-loss =  42.972081535740905 , Time for epoch =  0.023296117782592773 s\n",
      "Epoch  473 / 1000  : Train-loss =  44.37924728824594 , Val-loss =  42.94032126978824 , Time for epoch =  0.019256591796875 s\n",
      "Epoch  474 / 1000  : Train-loss =  44.36791093470686 , Val-loss =  42.92415528548391 , Time for epoch =  0.01984548568725586 s\n",
      "Epoch  475 / 1000  : Train-loss =  44.359544657044495 , Val-loss =  42.89856017263312 , Time for epoch =  0.01925206184387207 s\n",
      "Epoch  476 / 1000  : Train-loss =  44.347585408701065 , Val-loss =  42.8666800448769 , Time for epoch =  0.019562959671020508 s\n",
      "Epoch  477 / 1000  : Train-loss =  44.337568875760006 , Val-loss =  42.852801172356855 , Time for epoch =  0.01933884620666504 s\n",
      "Epoch  478 / 1000  : Train-loss =  44.326629606343936 , Val-loss =  42.82899183976023 , Time for epoch =  0.02034592628479004 s\n",
      "Epoch  479 / 1000  : Train-loss =  44.31484682546497 , Val-loss =  42.79788669786955 , Time for epoch =  0.019888877868652344 s\n",
      "Epoch  480 / 1000  : Train-loss =  44.3049672121382 , Val-loss =  42.784399936073704 , Time for epoch =  0.019778966903686523 s\n",
      "Epoch  481 / 1000  : Train-loss =  44.29296205811581 , Val-loss =  42.758711764686986 , Time for epoch =  0.019654035568237305 s\n",
      "Epoch  482 / 1000  : Train-loss =  44.28373953178104 , Val-loss =  42.726279409308184 , Time for epoch =  0.02365279197692871 s\n",
      "Epoch  483 / 1000  : Train-loss =  44.27381433605474 , Val-loss =  42.71266555786133 , Time for epoch =  0.019089937210083008 s\n",
      "Epoch  484 / 1000  : Train-loss =  44.2630017059671 , Val-loss =  42.68936799701891 , Time for epoch =  0.019995689392089844 s\n",
      "Epoch  485 / 1000  : Train-loss =  44.2513590882727 , Val-loss =  42.65866199292635 , Time for epoch =  0.019655942916870117 s\n",
      "Epoch  486 / 1000  : Train-loss =  44.24045972231418 , Val-loss =  42.643633792274876 , Time for epoch =  0.01921367645263672 s\n",
      "Epoch  487 / 1000  : Train-loss =  44.23222941597976 , Val-loss =  42.61919352882787 , Time for epoch =  0.019018173217773438 s\n",
      "Epoch  488 / 1000  : Train-loss =  44.2205590178064 , Val-loss =  42.58827018737793 , Time for epoch =  0.02118206024169922 s\n",
      "Epoch  489 / 1000  : Train-loss =  44.21084326404636 , Val-loss =  42.575749949405065 , Time for epoch =  0.020560503005981445 s\n",
      "Epoch  490 / 1000  : Train-loss =  44.19856645831954 , Val-loss =  42.54321991769891 , Time for epoch =  0.019540786743164062 s\n",
      "Epoch  491 / 1000  : Train-loss =  44.19140274780618 , Val-loss =  42.52837723179867 , Time for epoch =  0.0194089412689209 s\n",
      "Epoch  492 / 1000  : Train-loss =  44.1806110446736 , Val-loss =  42.505358143856654 , Time for epoch =  0.02335643768310547 s\n",
      "Epoch  493 / 1000  : Train-loss =  44.16907443030406 , Val-loss =  42.47545864707545 , Time for epoch =  0.01828169822692871 s\n",
      "Epoch  494 / 1000  : Train-loss =  44.15831723186256 , Val-loss =  42.46080358404862 , Time for epoch =  0.018434524536132812 s\n",
      "Epoch  495 / 1000  : Train-loss =  44.14980152367198 , Val-loss =  42.429627769871765 , Time for epoch =  0.021787643432617188 s\n",
      "Epoch  496 / 1000  : Train-loss =  44.14011862587794 , Val-loss =  42.41603148610968 , Time for epoch =  0.01942157745361328 s\n",
      "Epoch  497 / 1000  : Train-loss =  44.1294746829965 , Val-loss =  42.3937342794318 , Time for epoch =  0.019113540649414062 s\n",
      "Epoch  498 / 1000  : Train-loss =  44.117013306267516 , Val-loss =  42.362371946635996 , Time for epoch =  0.02389359474182129 s\n",
      "Epoch  499 / 1000  : Train-loss =  44.10992430563027 , Val-loss =  42.348664835879674 , Time for epoch =  0.019514083862304688 s\n",
      "Epoch  500 / 1000  : Train-loss =  44.099343671637065 , Val-loss =  42.3265054602372 , Time for epoch =  0.02030491828918457 s\n",
      "Epoch  501 / 1000  : Train-loss =  44.08688067851094 , Val-loss =  42.29499656275699 , Time for epoch =  0.019643306732177734 s\n",
      "Epoch  502 / 1000  : Train-loss =  44.079915580102956 , Val-loss =  42.282044862446035 , Time for epoch =  0.029792308807373047 s\n",
      "Epoch  503 / 1000  : Train-loss =  44.06899666651494 , Val-loss =  42.252429460224356 , Time for epoch =  0.03772449493408203 s\n",
      "Epoch  504 / 1000  : Train-loss =  44.05842584944041 , Val-loss =  42.23817614505165 , Time for epoch =  0.040201425552368164 s\n",
      "Epoch  505 / 1000  : Train-loss =  44.05002100454212 , Val-loss =  42.2079049160606 , Time for epoch =  0.03662538528442383 s\n",
      "Epoch  506 / 1000  : Train-loss =  44.04053214983752 , Val-loss =  42.195060328433385 , Time for epoch =  0.02099299430847168 s\n",
      "Epoch  507 / 1000  : Train-loss =  44.0289695222499 , Val-loss =  42.171552055760436 , Time for epoch =  0.019977331161499023 s\n",
      "Epoch  508 / 1000  : Train-loss =  44.020163703099485 , Val-loss =  42.1415400254099 , Time for epoch =  0.019785642623901367 s\n",
      "Epoch  509 / 1000  : Train-loss =  44.01078012972902 , Val-loss =  42.12990961576763 , Time for epoch =  0.02838754653930664 s\n",
      "Epoch  510 / 1000  : Train-loss =  43.9990150537868 , Val-loss =  42.09928843849584 , Time for epoch =  0.029491901397705078 s\n",
      "Epoch  511 / 1000  : Train-loss =  43.99207986950201 , Val-loss =  42.08607181749846 , Time for epoch =  0.02311229705810547 s\n",
      "Epoch  512 / 1000  : Train-loss =  43.98122574111163 , Val-loss =  42.057642083419 , Time for epoch =  0.02972555160522461 s\n",
      "Epoch  513 / 1000  : Train-loss =  43.97107572609422 , Val-loss =  42.04353734066612 , Time for epoch =  0.024197101593017578 s\n",
      "Epoch  514 / 1000  : Train-loss =  43.96297463454769 , Val-loss =  42.0213084973787 , Time for epoch =  0.0233306884765625 s\n",
      "Epoch  515 / 1000  : Train-loss =  43.950710684566175 , Val-loss =  41.99097593207108 , Time for epoch =  0.02035665512084961 s\n",
      "Epoch  516 / 1000  : Train-loss =  43.94395162291446 , Val-loss =  41.97877371938605 , Time for epoch =  0.019518136978149414 s\n",
      "Epoch  517 / 1000  : Train-loss =  43.93323572880804 , Val-loss =  41.95034498917429 , Time for epoch =  0.023560047149658203 s\n",
      "Epoch  518 / 1000  : Train-loss =  43.92320563968292 , Val-loss =  41.93726850810804 , Time for epoch =  0.02389359474182129 s\n",
      "Epoch  519 / 1000  : Train-loss =  43.91478092387571 , Val-loss =  41.90808507015831 , Time for epoch =  0.026863574981689453 s\n",
      "Epoch  520 / 1000  : Train-loss =  43.90458494929944 , Val-loss =  41.89457040084036 , Time for epoch =  0.026119232177734375 s\n",
      "Epoch  521 / 1000  : Train-loss =  43.89626020226775 , Val-loss =  41.865625983790345 , Time for epoch =  0.01978135108947754 s\n",
      "Epoch  522 / 1000  : Train-loss =  43.885976252582786 , Val-loss =  41.85195230182848 , Time for epoch =  0.021797657012939453 s\n",
      "Epoch  523 / 1000  : Train-loss =  43.87775656058963 , Val-loss =  41.82327963176527 , Time for epoch =  0.02730393409729004 s\n",
      "Epoch  524 / 1000  : Train-loss =  43.8674221254338 , Val-loss =  41.809592497976205 , Time for epoch =  0.019308090209960938 s\n",
      "Epoch  525 / 1000  : Train-loss =  43.85928329640189 , Val-loss =  41.78118966755114 , Time for epoch =  0.01957106590270996 s\n",
      "Epoch  526 / 1000  : Train-loss =  43.85013239801267 , Val-loss =  41.76945937307257 , Time for epoch =  0.02377033233642578 s\n",
      "Epoch  527 / 1000  : Train-loss =  43.839156307069594 , Val-loss =  41.74768899616442 , Time for epoch =  0.026233673095703125 s\n",
      "Epoch  528 / 1000  : Train-loss =  43.83041961583714 , Val-loss =  41.719381733944545 , Time for epoch =  0.01824188232421875 s\n",
      "Epoch  529 / 1000  : Train-loss =  43.8205729554602 , Val-loss =  41.70748469704076 , Time for epoch =  0.02197718620300293 s\n",
      "Epoch  530 / 1000  : Train-loss =  43.81234666856669 , Val-loss =  41.67887245981317 , Time for epoch =  0.026831865310668945 s\n",
      "Epoch  531 / 1000  : Train-loss =  43.80248131186275 , Val-loss =  41.66677675749126 , Time for epoch =  0.020920276641845703 s\n",
      "Epoch  532 / 1000  : Train-loss =  43.79425105940824 , Val-loss =  41.638357965569746 , Time for epoch =  0.020040035247802734 s\n",
      "Epoch  533 / 1000  : Train-loss =  43.78440969003796 , Val-loss =  41.62625011644865 , Time for epoch =  0.019808053970336914 s\n",
      "Epoch  534 / 1000  : Train-loss =  43.776178273777504 , Val-loss =  41.59797216716566 , Time for epoch =  0.020038127899169922 s\n",
      "Epoch  535 / 1000  : Train-loss =  43.76638556873731 , Val-loss =  41.585916117617955 , Time for epoch =  0.024374723434448242 s\n",
      "Epoch  536 / 1000  : Train-loss =  43.75814528384451 , Val-loss =  41.55783040899979 , Time for epoch =  0.01984119415283203 s\n",
      "Epoch  537 / 1000  : Train-loss =  43.74843086630611 , Val-loss =  41.545847139860456 , Time for epoch =  0.019756555557250977 s\n",
      "Epoch  538 / 1000  : Train-loss =  43.740164805266815 , Val-loss =  41.51792837444105 , Time for epoch =  0.019603967666625977 s\n",
      "Epoch  539 / 1000  : Train-loss =  43.73055313670702 , Val-loss =  41.50610863535028 , Time for epoch =  0.019774913787841797 s\n",
      "Epoch  540 / 1000  : Train-loss =  43.72117929404738 , Val-loss =  41.47643621344315 , Time for epoch =  0.02208399772644043 s\n",
      "Epoch  541 / 1000  : Train-loss =  43.714711711905096 , Val-loss =  41.46516719617342 , Time for epoch =  0.020235776901245117 s\n",
      "Epoch  542 / 1000  : Train-loss =  43.703316640045685 , Val-loss =  41.43668325323807 , Time for epoch =  0.02298903465270996 s\n",
      "Epoch  543 / 1000  : Train-loss =  43.696820027410645 , Val-loss =  41.42583395305433 , Time for epoch =  0.01990032196044922 s\n",
      "Epoch  544 / 1000  : Train-loss =  43.685600237657795 , Val-loss =  41.397540042274876 , Time for epoch =  0.020032405853271484 s\n",
      "Epoch  545 / 1000  : Train-loss =  43.67901341928601 , Val-loss =  41.386952450400905 , Time for epoch =  0.02468419075012207 s\n",
      "Epoch  546 / 1000  : Train-loss =  43.667981810488946 , Val-loss =  41.35878301921644 , Time for epoch =  0.019503116607666016 s\n",
      "Epoch  547 / 1000  : Train-loss =  43.520009649675444 , Val-loss =  41.294266048230625 , Time for epoch =  0.020010948181152344 s\n",
      "Epoch  548 / 1000  : Train-loss =  43.510108247315145 , Val-loss =  41.257333052785775 , Time for epoch =  0.01967024803161621 s\n",
      "Epoch  549 / 1000  : Train-loss =  43.50219781520003 , Val-loss =  41.24675700539037 , Time for epoch =  0.019364118576049805 s\n",
      "Epoch  550 / 1000  : Train-loss =  43.49333876270359 , Val-loss =  41.22222308108681 , Time for epoch =  0.022715330123901367 s\n",
      "Epoch  551 / 1000  : Train-loss =  43.48593492023016 , Val-loss =  41.212826678627415 , Time for epoch =  0.024532079696655273 s\n",
      "Epoch  552 / 1000  : Train-loss =  43.477408748562056 , Val-loss =  41.19507388064736 , Time for epoch =  0.022249460220336914 s\n",
      "Epoch  553 / 1000  : Train-loss =  43.46806540192857 , Val-loss =  41.170868723016035 , Time for epoch =  0.01975274085998535 s\n",
      "Epoch  554 / 1000  : Train-loss =  43.46056234499829 , Val-loss =  41.161686746697676 , Time for epoch =  0.021139144897460938 s\n",
      "Epoch  555 / 1000  : Train-loss =  43.45196395270568 , Val-loss =  41.14369502820467 , Time for epoch =  0.024012088775634766 s\n",
      "Epoch  556 / 1000  : Train-loss =  43.44125508453887 , Val-loss =  41.11694918180767 , Time for epoch =  0.019331932067871094 s\n",
      "Epoch  557 / 1000  : Train-loss =  43.43593847414868 , Val-loss =  41.10653405440481 , Time for epoch =  0.018973827362060547 s\n",
      "Epoch  558 / 1000  : Train-loss =  43.42672520438157 , Val-loss =  41.08092739707545 , Time for epoch =  0.01845526695251465 s\n",
      "Epoch  559 / 1000  : Train-loss =  43.41901713441321 , Val-loss =  41.07096059698807 , Time for epoch =  0.0184173583984375 s\n",
      "Epoch  560 / 1000  : Train-loss =  43.409825405832066 , Val-loss =  41.04588267677709 , Time for epoch =  0.019348621368408203 s\n",
      "Epoch  561 / 1000  : Train-loss =  43.40215007329391 , Val-loss =  41.03546544125206 , Time for epoch =  0.020821094512939453 s\n",
      "Epoch  562 / 1000  : Train-loss =  43.39339895302293 , Val-loss =  41.01693685431229 , Time for epoch =  0.019629716873168945 s\n",
      "Epoch  563 / 1000  : Train-loss =  43.38392154241012 , Val-loss =  40.991918664229544 , Time for epoch =  0.019576311111450195 s\n",
      "Epoch  564 / 1000  : Train-loss =  43.37509032427254 , Val-loss =  40.980709979408665 , Time for epoch =  0.019677400588989258 s\n",
      "Epoch  565 / 1000  : Train-loss =  43.368221735550186 , Val-loss =  40.954129570408874 , Time for epoch =  0.019989728927612305 s\n",
      "Epoch  566 / 1000  : Train-loss =  43.360475701800844 , Val-loss =  40.94376895302221 , Time for epoch =  0.023862838745117188 s\n",
      "Epoch  567 / 1000  : Train-loss =  43.351297443195925 , Val-loss =  40.91873038442511 , Time for epoch =  0.019058942794799805 s\n",
      "Epoch  568 / 1000  : Train-loss =  43.343676410825914 , Val-loss =  40.90837448521664 , Time for epoch =  0.019107580184936523 s\n",
      "Epoch  569 / 1000  : Train-loss =  43.334990970158984 , Val-loss =  40.89003311960321 , Time for epoch =  0.019147157669067383 s\n",
      "Epoch  570 / 1000  : Train-loss =  43.32436887019098 , Val-loss =  40.863413860923366 , Time for epoch =  0.0191652774810791 s\n",
      "Epoch  571 / 1000  : Train-loss =  43.31905633312161 , Val-loss =  40.852928262007865 , Time for epoch =  0.019756078720092773 s\n",
      "Epoch  572 / 1000  : Train-loss =  43.309920704297426 , Val-loss =  40.82753803855494 , Time for epoch =  0.020186901092529297 s\n",
      "Epoch  573 / 1000  : Train-loss =  43.30235304536119 , Val-loss =  40.81789448386744 , Time for epoch =  0.019315481185913086 s\n",
      "Epoch  574 / 1000  : Train-loss =  43.293301264444985 , Val-loss =  40.793150550440735 , Time for epoch =  0.02045464515686035 s\n",
      "Epoch  575 / 1000  : Train-loss =  43.284634886488405 , Val-loss =  40.781702643946595 , Time for epoch =  0.023926973342895508 s\n",
      "Epoch  576 / 1000  : Train-loss =  43.27775927182645 , Val-loss =  40.75585626301012 , Time for epoch =  0.024481534957885742 s\n",
      "Epoch  577 / 1000  : Train-loss =  43.27016371387546 , Val-loss =  40.745641909147565 , Time for epoch =  0.03011465072631836 s\n",
      "Epoch  578 / 1000  : Train-loss =  43.261092148258186 , Val-loss =  40.72132040324964 , Time for epoch =  0.030188322067260742 s\n",
      "Epoch  579 / 1000  : Train-loss =  43.25241779607568 , Val-loss =  40.70966128299111 , Time for epoch =  0.03324103355407715 s\n",
      "Epoch  580 / 1000  : Train-loss =  43.246076476102495 , Val-loss =  40.69053198161878 , Time for epoch =  0.020564556121826172 s\n",
      "Epoch  581 / 1000  : Train-loss =  43.236683883235955 , Val-loss =  40.6659214622096 , Time for epoch =  0.019666671752929688 s\n",
      "Epoch  582 / 1000  : Train-loss =  43.229286657214836 , Val-loss =  40.65726731952868 , Time for epoch =  0.01950836181640625 s\n",
      "Epoch  583 / 1000  : Train-loss =  43.219234488104696 , Val-loss =  40.63117388675087 , Time for epoch =  0.02325272560119629 s\n",
      "Epoch  584 / 1000  : Train-loss =  43.21406206033998 , Val-loss =  40.62109134071752 , Time for epoch =  0.03081059455871582 s\n",
      "Epoch  585 / 1000  : Train-loss =  43.20507040939762 , Val-loss =  40.59652378684596 , Time for epoch =  0.021611690521240234 s\n",
      "Epoch  586 / 1000  : Train-loss =  43.197692968077575 , Val-loss =  40.5875745070608 , Time for epoch =  0.01879715919494629 s\n",
      "Epoch  587 / 1000  : Train-loss =  43.18774513201525 , Val-loss =  40.56195761028089 , Time for epoch =  0.018239259719848633 s\n",
      "Epoch  588 / 1000  : Train-loss =  43.18252472958322 , Val-loss =  40.55175299393503 , Time for epoch =  0.018524169921875 s\n",
      "Epoch  589 / 1000  : Train-loss =  43.17355659183136 , Val-loss =  40.5275956204063 , Time for epoch =  0.019832372665405273 s\n",
      "Epoch  590 / 1000  : Train-loss =  43.16507551764364 , Val-loss =  40.51702800549959 , Time for epoch =  0.019736766815185547 s\n",
      "Epoch  591 / 1000  : Train-loss =  43.15840864450918 , Val-loss =  40.49203220166658 , Time for epoch =  0.01945662498474121 s\n",
      "Epoch  592 / 1000  : Train-loss =  43.151027744099245 , Val-loss =  40.48283165379574 , Time for epoch =  0.019554615020751953 s\n",
      "Epoch  593 / 1000  : Train-loss =  43.14097373229636 , Val-loss =  40.45767904582777 , Time for epoch =  0.02524733543395996 s\n",
      "Epoch  594 / 1000  : Train-loss =  43.135947987184686 , Val-loss =  40.44755564237896 , Time for epoch =  0.02728271484375 s\n",
      "Epoch  595 / 1000  : Train-loss =  43.1270243865622 , Val-loss =  40.42389779341848 , Time for epoch =  0.03585481643676758 s\n",
      "Epoch  596 / 1000  : Train-loss =  43.11860666436664 , Val-loss =  40.413548720510384 , Time for epoch =  0.031264543533325195 s\n",
      "Epoch  597 / 1000  : Train-loss =  43.11202481372208 , Val-loss =  40.38902864958111 , Time for epoch =  0.03499197959899902 s\n",
      "Epoch  598 / 1000  : Train-loss =  43.10472424825033 , Val-loss =  40.38010436610172 , Time for epoch =  0.0204925537109375 s\n",
      "Epoch  599 / 1000  : Train-loss =  43.09481268413996 , Val-loss =  40.35543381540399 , Time for epoch =  0.01999831199645996 s\n",
      "Epoch  600 / 1000  : Train-loss =  43.08981707944708 , Val-loss =  40.345673310129264 , Time for epoch =  0.019820451736450195 s\n",
      "Epoch  601 / 1000  : Train-loss =  43.08098057030284 , Val-loss =  40.32243497748124 , Time for epoch =  0.030596017837524414 s\n",
      "Epoch  602 / 1000  : Train-loss =  43.072789704058806 , Val-loss =  40.31252178392912 , Time for epoch =  0.031236886978149414 s\n",
      "Epoch  603 / 1000  : Train-loss =  43.06616456629866 , Val-loss =  40.288386595876595 , Time for epoch =  0.027678489685058594 s\n",
      "Epoch  604 / 1000  : Train-loss =  43.05896281657246 , Val-loss =  40.27996414586117 , Time for epoch =  0.019469261169433594 s\n",
      "Epoch  605 / 1000  : Train-loss =  43.049354779518254 , Val-loss =  40.25562286376953 , Time for epoch =  0.019891977310180664 s\n",
      "Epoch  606 / 1000  : Train-loss =  43.04425026198565 , Val-loss =  40.24640454744038 , Time for epoch =  0.020433902740478516 s\n",
      "Epoch  607 / 1000  : Train-loss =  43.03441267498469 , Val-loss =  40.221894916735195 , Time for epoch =  0.020143508911132812 s\n",
      "Epoch  608 / 1000  : Train-loss =  43.02948139212226 , Val-loss =  40.2127638365093 , Time for epoch =  0.019828319549560547 s\n",
      "Epoch  609 / 1000  : Train-loss =  43.02075273977161 , Val-loss =  40.18978590714304 , Time for epoch =  0.020297527313232422 s\n",
      "Epoch  610 / 1000  : Train-loss =  43.012795356707386 , Val-loss =  40.18065793890702 , Time for epoch =  0.02012467384338379 s\n",
      "Epoch  611 / 1000  : Train-loss =  43.00617083317816 , Val-loss =  40.156775625128496 , Time for epoch =  0.025061845779418945 s\n",
      "Epoch  612 / 1000  : Train-loss =  42.9980322627698 , Val-loss =  40.14763551009329 , Time for epoch =  0.019512414932250977 s\n",
      "Epoch  613 / 1000  : Train-loss =  42.99154906623107 , Val-loss =  40.123706315693106 , Time for epoch =  0.019936561584472656 s\n",
      "Epoch  614 / 1000  : Train-loss =  42.982840586516815 , Val-loss =  40.108871058413854 , Time for epoch =  0.019635438919067383 s\n",
      "Epoch  615 / 1000  : Train-loss =  42.97838319896978 , Val-loss =  40.09864807128906 , Time for epoch =  0.019652128219604492 s\n",
      "Epoch  616 / 1000  : Train-loss =  42.96958261694612 , Val-loss =  40.07646470320852 , Time for epoch =  0.021840572357177734 s\n",
      "Epoch  617 / 1000  : Train-loss =  42.961737896763 , Val-loss =  40.066904971474095 , Time for epoch =  0.019891738891601562 s\n",
      "Epoch  618 / 1000  : Train-loss =  42.955062704571226 , Val-loss =  40.04386068645277 , Time for epoch =  0.02007579803466797 s\n",
      "Epoch  619 / 1000  : Train-loss =  42.94711480437026 , Val-loss =  40.03450905649286 , Time for epoch =  0.01986074447631836 s\n",
      "Epoch  620 / 1000  : Train-loss =  42.940553115586106 , Val-loss =  40.01138195238615 , Time for epoch =  0.021923303604125977 s\n",
      "Epoch  621 / 1000  : Train-loss =  42.93256679901295 , Val-loss =  40.0023529655055 , Time for epoch =  0.02598261833190918 s\n",
      "Epoch  622 / 1000  : Train-loss =  42.926098979799086 , Val-loss =  39.97918149044639 , Time for epoch =  0.01979684829711914 s\n",
      "Epoch  623 / 1000  : Train-loss =  42.9180954647603 , Val-loss =  39.97051369516473 , Time for epoch =  0.019087791442871094 s\n",
      "Epoch  624 / 1000  : Train-loss =  42.91170233387058 , Val-loss =  39.94728489925987 , Time for epoch =  0.019330501556396484 s\n",
      "Epoch  625 / 1000  : Train-loss =  42.90324919102556 , Val-loss =  39.93305527536493 , Time for epoch =  0.019076824188232422 s\n",
      "Epoch  626 / 1000  : Train-loss =  42.898816372715146 , Val-loss =  39.923503273411804 , Time for epoch =  0.019834041595458984 s\n",
      "Epoch  627 / 1000  : Train-loss =  42.88911600705594 , Val-loss =  39.90048518933748 , Time for epoch =  0.01974010467529297 s\n",
      "Epoch  628 / 1000  : Train-loss =  42.8843428832663 , Val-loss =  39.891847108539785 , Time for epoch =  0.01922750473022461 s\n",
      "Epoch  629 / 1000  : Train-loss =  42.87477042850128 , Val-loss =  39.868831734908255 , Time for epoch =  0.019594669342041016 s\n",
      "Epoch  630 / 1000  : Train-loss =  42.8700119384938 , Val-loss =  39.86065985027113 , Time for epoch =  0.019681930541992188 s\n",
      "Epoch  631 / 1000  : Train-loss =  42.86053369813046 , Val-loss =  39.83761034513775 , Time for epoch =  0.024034500122070312 s\n",
      "Epoch  632 / 1000  : Train-loss =  42.85529962097858 , Val-loss =  39.82411936709755 , Time for epoch =  0.018802881240844727 s\n",
      "Epoch  633 / 1000  : Train-loss =  42.84785660781429 , Val-loss =  39.81444328709652 , Time for epoch =  0.018464326858520508 s\n",
      "Epoch  634 / 1000  : Train-loss =  42.84131688047937 , Val-loss =  39.79231181897615 , Time for epoch =  0.018283605575561523 s\n",
      "Epoch  635 / 1000  : Train-loss =  42.833608627319336 , Val-loss =  39.78362304285953 , Time for epoch =  0.018990755081176758 s\n",
      "Epoch  636 / 1000  : Train-loss =  42.82711884665624 , Val-loss =  39.76146708036724 , Time for epoch =  0.01868152618408203 s\n",
      "Epoch  637 / 1000  : Train-loss =  42.8195273404741 , Val-loss =  39.75332029242264 , Time for epoch =  0.02001023292541504 s\n",
      "Epoch  638 / 1000  : Train-loss =  42.813026212703036 , Val-loss =  39.73106063039679 , Time for epoch =  0.019776582717895508 s\n",
      "Epoch  639 / 1000  : Train-loss =  42.80508899149922 , Val-loss =  39.717591536672494 , Time for epoch =  0.020641088485717773 s\n",
      "Epoch  640 / 1000  : Train-loss =  42.79944179556464 , Val-loss =  39.70745116785953 , Time for epoch =  0.020158052444458008 s\n",
      "Epoch  641 / 1000  : Train-loss =  42.793042824093234 , Val-loss =  39.68534288908306 , Time for epoch =  0.02757430076599121 s\n",
      "Epoch  642 / 1000  : Train-loss =  42.78530682278218 , Val-loss =  39.67706981458162 , Time for epoch =  0.026386499404907227 s\n",
      "Epoch  643 / 1000  : Train-loss =  42.77895021169199 , Val-loss =  39.65509625485069 , Time for epoch =  0.02739715576171875 s\n",
      "Epoch  644 / 1000  : Train-loss =  42.770942375484836 , Val-loss =  39.64180454454924 , Time for epoch =  0.02642536163330078 s\n",
      "Epoch  645 / 1000  : Train-loss =  42.7653519150901 , Val-loss =  39.631786948756165 , Time for epoch =  0.03085613250732422 s\n",
      "Epoch  646 / 1000  : Train-loss =  42.759053041705975 , Val-loss =  39.6099853515625 , Time for epoch =  0.021574974060058594 s\n",
      "Epoch  647 / 1000  : Train-loss =  42.75134040272169 , Val-loss =  39.601880625674596 , Time for epoch =  0.01968979835510254 s\n",
      "Epoch  648 / 1000  : Train-loss =  42.74503948190118 , Val-loss =  39.580230612503854 , Time for epoch =  0.019798994064331055 s\n",
      "Epoch  649 / 1000  : Train-loss =  42.73710247621698 , Val-loss =  39.56718966835424 , Time for epoch =  0.021110057830810547 s\n",
      "Epoch  650 / 1000  : Train-loss =  42.731584225670765 , Val-loss =  39.55743679247404 , Time for epoch =  0.03393054008483887 s\n",
      "Epoch  651 / 1000  : Train-loss =  42.725304889140155 , Val-loss =  39.53591567591617 , Time for epoch =  0.025642871856689453 s\n",
      "Epoch  652 / 1000  : Train-loss =  42.717712122168244 , Val-loss =  39.52811702929045 , Time for epoch =  0.030269622802734375 s\n",
      "Epoch  653 / 1000  : Train-loss =  42.71140593189304 , Val-loss =  39.50672661630731 , Time for epoch =  0.02469801902770996 s\n",
      "Epoch  654 / 1000  : Train-loss =  42.70363407889329 , Val-loss =  39.49396605240671 , Time for epoch =  0.03675079345703125 s\n",
      "Epoch  655 / 1000  : Train-loss =  42.6981958507818 , Val-loss =  39.48459585089432 , Time for epoch =  0.027738571166992188 s\n",
      "Epoch  656 / 1000  : Train-loss =  42.691854379944886 , Val-loss =  39.46329779373972 , Time for epoch =  0.021865367889404297 s\n",
      "Epoch  657 / 1000  : Train-loss =  42.6840113408148 , Val-loss =  39.450468264128034 , Time for epoch =  0.020114898681640625 s\n",
      "Epoch  658 / 1000  : Train-loss =  42.67857564505884 , Val-loss =  39.44083926552221 , Time for epoch =  0.020095109939575195 s\n",
      "Epoch  659 / 1000  : Train-loss =  42.67226297841907 , Val-loss =  39.419857225920026 , Time for epoch =  0.03460836410522461 s\n",
      "Epoch  660 / 1000  : Train-loss =  42.664886797888805 , Val-loss =  39.412263569078945 , Time for epoch =  0.03604412078857422 s\n",
      "Epoch  661 / 1000  : Train-loss =  42.65750397935425 , Val-loss =  39.390149668643346 , Time for epoch =  0.02499532699584961 s\n",
      "Epoch  662 / 1000  : Train-loss =  42.652558558404785 , Val-loss =  39.37776033501876 , Time for epoch =  0.019792556762695312 s\n",
      "Epoch  663 / 1000  : Train-loss =  42.64555733890857 , Val-loss =  39.36955973976537 , Time for epoch =  0.020587682723999023 s\n",
      "Epoch  664 / 1000  : Train-loss =  42.638145791608736 , Val-loss =  39.347712667364824 , Time for epoch =  0.020465850830078125 s\n",
      "Epoch  665 / 1000  : Train-loss =  42.6331782583463 , Val-loss =  39.33533307125694 , Time for epoch =  0.02971196174621582 s\n",
      "Epoch  666 / 1000  : Train-loss =  42.626240110666735 , Val-loss =  39.327028475309675 , Time for epoch =  0.029888629913330078 s\n",
      "Epoch  667 / 1000  : Train-loss =  42.61883299229509 , Val-loss =  39.30548848603901 , Time for epoch =  0.028084993362426758 s\n",
      "Epoch  668 / 1000  : Train-loss =  42.61383873459983 , Val-loss =  39.29320104498612 , Time for epoch =  0.027120113372802734 s\n",
      "Epoch  669 / 1000  : Train-loss =  42.60699954275358 , Val-loss =  39.284897352519785 , Time for epoch =  0.031116724014282227 s\n",
      "Epoch  670 / 1000  : Train-loss =  42.599621767378125 , Val-loss =  39.26362429167095 , Time for epoch =  0.02750110626220703 s\n",
      "Epoch  671 / 1000  : Train-loss =  42.593513564201395 , Val-loss =  39.25027445742958 , Time for epoch =  0.02483820915222168 s\n",
      "Epoch  672 / 1000  : Train-loss =  42.58944053434383 , Val-loss =  39.241931312962585 , Time for epoch =  0.019608497619628906 s\n",
      "Epoch  673 / 1000  : Train-loss =  42.58039513280836 , Val-loss =  39.221732691714635 , Time for epoch =  0.019854307174682617 s\n",
      "Epoch  674 / 1000  : Train-loss =  42.574870114946094 , Val-loss =  39.21382612931101 , Time for epoch =  0.019656896591186523 s\n",
      "Epoch  675 / 1000  : Train-loss =  42.56872034881074 , Val-loss =  39.193459360223066 , Time for epoch =  0.023220539093017578 s\n",
      "Epoch  676 / 1000  : Train-loss =  42.56124011540817 , Val-loss =  39.1816473509136 , Time for epoch =  0.019088029861450195 s\n",
      "Epoch  677 / 1000  : Train-loss =  42.55608545723608 , Val-loss =  39.173337836014596 , Time for epoch =  0.01868605613708496 s\n",
      "Epoch  678 / 1000  : Train-loss =  42.54879247805493 , Val-loss =  39.15199239630448 , Time for epoch =  0.019461393356323242 s\n",
      "Epoch  679 / 1000  : Train-loss =  42.543929816639356 , Val-loss =  39.14019203186035 , Time for epoch =  0.020982742309570312 s\n",
      "Epoch  680 / 1000  : Train-loss =  42.53722546464306 , Val-loss =  39.132735804507604 , Time for epoch =  0.019930124282836914 s\n",
      "Epoch  681 / 1000  : Train-loss =  42.53001317600746 , Val-loss =  39.11178257590846 , Time for epoch =  0.01992940902709961 s\n",
      "Epoch  682 / 1000  : Train-loss =  42.52405946806999 , Val-loss =  39.0990259270919 , Time for epoch =  0.020431041717529297 s\n",
      "Epoch  683 / 1000  : Train-loss =  42.51996914276295 , Val-loss =  39.09160644129703 , Time for epoch =  0.024489402770996094 s\n",
      "Epoch  684 / 1000  : Train-loss =  42.511252387095304 , Val-loss =  39.071646539788496 , Time for epoch =  0.020355701446533203 s\n",
      "Epoch  685 / 1000  : Train-loss =  42.50539521039543 , Val-loss =  39.05924315201609 , Time for epoch =  0.019426345825195312 s\n",
      "Epoch  686 / 1000  : Train-loss =  42.50026421627756 , Val-loss =  39.050941366898385 , Time for epoch =  0.023880720138549805 s\n",
      "Epoch  687 / 1000  : Train-loss =  42.49302673339844 , Val-loss =  39.02998362089458 , Time for epoch =  0.0204775333404541 s\n",
      "Epoch  688 / 1000  : Train-loss =  42.48828631471106 , Val-loss =  39.018420169228 , Time for epoch =  0.02359795570373535 s\n",
      "Epoch  689 / 1000  : Train-loss =  42.481624355423925 , Val-loss =  39.01128668534128 , Time for epoch =  0.02472376823425293 s\n",
      "Epoch  690 / 1000  : Train-loss =  42.474504934192375 , Val-loss =  38.99074343631142 , Time for epoch =  0.02895069122314453 s\n",
      "Epoch  691 / 1000  : Train-loss =  42.46865193857312 , Val-loss =  38.97837699087042 , Time for epoch =  0.021413087844848633 s\n",
      "Epoch  692 / 1000  : Train-loss =  42.463086790957696 , Val-loss =  38.965389452482526 , Time for epoch =  0.01912212371826172 s\n",
      "Epoch  693 / 1000  : Train-loss =  42.45907926828848 , Val-loss =  38.95758528458445 , Time for epoch =  0.019575119018554688 s\n",
      "Epoch  694 / 1000  : Train-loss =  42.45032138070144 , Val-loss =  38.9384072956286 , Time for epoch =  0.02229928970336914 s\n",
      "Epoch  695 / 1000  : Train-loss =  42.44456514261537 , Val-loss =  38.926292620207136 , Time for epoch =  0.020734310150146484 s\n",
      "Epoch  696 / 1000  : Train-loss =  42.439518621412375 , Val-loss =  38.918000873766445 , Time for epoch =  0.01865363121032715 s\n",
      "Epoch  697 / 1000  : Train-loss =  42.432361085536115 , Val-loss =  38.897784885607265 , Time for epoch =  0.01830291748046875 s\n",
      "Epoch  698 / 1000  : Train-loss =  42.42761146416098 , Val-loss =  38.88660922803377 , Time for epoch =  0.018481731414794922 s\n",
      "Epoch  699 / 1000  : Train-loss =  42.42118139320848 , Val-loss =  38.87965925116288 , Time for epoch =  0.01976299285888672 s\n",
      "Epoch  700 / 1000  : Train-loss =  42.414158072175276 , Val-loss =  38.85984992980957 , Time for epoch =  0.019199132919311523 s\n",
      "Epoch  701 / 1000  : Train-loss =  42.40844047675699 , Val-loss =  38.84790761847245 , Time for epoch =  0.019458770751953125 s\n",
      "Epoch  702 / 1000  : Train-loss =  42.40298964074776 , Val-loss =  38.8353587702701 , Time for epoch =  0.020052433013916016 s\n",
      "Epoch  703 / 1000  : Train-loss =  42.39794380920755 , Val-loss =  38.82689275239643 , Time for epoch =  0.020601511001586914 s\n",
      "Epoch  704 / 1000  : Train-loss =  42.39079905364473 , Val-loss =  38.80710822657535 , Time for epoch =  0.025615692138671875 s\n",
      "Epoch  705 / 1000  : Train-loss =  42.3861479355117 , Val-loss =  38.796086160760176 , Time for epoch =  0.019025087356567383 s\n",
      "Epoch  706 / 1000  : Train-loss =  42.379727013367045 , Val-loss =  38.78924460160105 , Time for epoch =  0.019585847854614258 s\n",
      "Epoch  707 / 1000  : Train-loss =  42.372757410599014 , Val-loss =  38.76980048731754 , Time for epoch =  0.019680023193359375 s\n",
      "Epoch  708 / 1000  : Train-loss =  42.367110624151714 , Val-loss =  38.75815130534925 , Time for epoch =  0.02038407325744629 s\n",
      "Epoch  709 / 1000  : Train-loss =  42.36173732132561 , Val-loss =  38.74592560216 , Time for epoch =  0.021066904067993164 s\n",
      "Epoch  710 / 1000  : Train-loss =  42.356770725573526 , Val-loss =  38.73769438894171 , Time for epoch =  0.02067112922668457 s\n",
      "Epoch  711 / 1000  : Train-loss =  42.349701251013805 , Val-loss =  38.7182741667095 , Time for epoch =  0.020176410675048828 s\n",
      "Epoch  712 / 1000  : Train-loss =  42.34404559593416 , Val-loss =  38.70653905366596 , Time for epoch =  0.019709348678588867 s\n",
      "Epoch  713 / 1000  : Train-loss =  42.34017187862073 , Val-loss =  38.69983331780685 , Time for epoch =  0.01970195770263672 s\n",
      "Epoch  714 / 1000  : Train-loss =  42.33178152741685 , Val-loss =  38.68150239241751 , Time for epoch =  0.02479696273803711 s\n",
      "Epoch  715 / 1000  : Train-loss =  42.326273029133425 , Val-loss =  38.67036488181666 , Time for epoch =  0.018714189529418945 s\n",
      "Epoch  716 / 1000  : Train-loss =  42.320996225216966 , Val-loss =  38.65850237796181 , Time for epoch =  0.01891493797302246 s\n",
      "Epoch  717 / 1000  : Train-loss =  42.31611762612553 , Val-loss =  38.650734750848066 , Time for epoch =  0.018724918365478516 s\n",
      "Epoch  718 / 1000  : Train-loss =  42.3091464931682 , Val-loss =  38.63163285506399 , Time for epoch =  0.01948690414428711 s\n",
      "Epoch  719 / 1000  : Train-loss =  42.30357117302674 , Val-loss =  38.62022861681486 , Time for epoch =  0.02042531967163086 s\n",
      "Epoch  720 / 1000  : Train-loss =  42.29828565134167 , Val-loss =  38.60832826714767 , Time for epoch =  0.020019054412841797 s\n",
      "Epoch  721 / 1000  : Train-loss =  42.29340588844428 , Val-loss =  38.60047751978824 , Time for epoch =  0.019644975662231445 s\n",
      "Epoch  722 / 1000  : Train-loss =  42.28643958312644 , Val-loss =  38.581551903172546 , Time for epoch =  0.020315885543823242 s\n",
      "Epoch  723 / 1000  : Train-loss =  42.13922636387712 , Val-loss =  38.56054426494398 , Time for epoch =  0.020798444747924805 s\n",
      "Epoch  724 / 1000  : Train-loss =  42.14090449661858 , Val-loss =  38.584447258397155 , Time for epoch =  0.02758312225341797 s\n",
      "Epoch  725 / 1000  : Train-loss =  42.141313585184385 , Val-loss =  38.600886696263366 , Time for epoch =  0.023119449615478516 s\n",
      "Epoch  726 / 1000  : Train-loss =  42.14293804276461 , Val-loss =  38.627098986977025 , Time for epoch =  0.019908905029296875 s\n",
      "Epoch  727 / 1000  : Train-loss =  42.142154909123136 , Val-loss =  38.63678651106985 , Time for epoch =  0.018976211547851562 s\n",
      "Epoch  728 / 1000  : Train-loss =  41.812545194464214 , Val-loss =  38.722583168431335 , Time for epoch =  0.020069360733032227 s\n",
      "Epoch  729 / 1000  : Train-loss =  41.8140014928613 , Val-loss =  38.82677660490337 , Time for epoch =  0.020112991333007812 s\n",
      "Epoch  730 / 1000  : Train-loss =  41.817957603325276 , Val-loss =  38.91163263822857 , Time for epoch =  0.019352436065673828 s\n",
      "Epoch  731 / 1000  : Train-loss =  41.82381919817736 , Val-loss =  38.99148941040039 , Time for epoch =  0.018938302993774414 s\n",
      "Epoch  732 / 1000  : Train-loss =  41.82971550246417 , Val-loss =  39.06360867148951 , Time for epoch =  0.02091813087463379 s\n",
      "Epoch  733 / 1000  : Train-loss =  41.83233640422929 , Val-loss =  39.11200222216154 , Time for epoch =  0.020073890686035156 s\n",
      "Epoch  734 / 1000  : Train-loss =  41.83566927505752 , Val-loss =  39.158981122468646 , Time for epoch =  0.026788949966430664 s\n",
      "Epoch  735 / 1000  : Train-loss =  41.839177611183985 , Val-loss =  39.20061984815096 , Time for epoch =  0.018473148345947266 s\n",
      "Epoch  736 / 1000  : Train-loss =  41.83910722247625 , Val-loss =  39.21923235843056 , Time for epoch =  0.018568992614746094 s\n",
      "Epoch  737 / 1000  : Train-loss =  41.839698015633275 , Val-loss =  39.2383686868768 , Time for epoch =  0.02014636993408203 s\n",
      "Epoch  738 / 1000  : Train-loss =  41.84023962721313 , Val-loss =  39.25394881399054 , Time for epoch =  0.019636869430541992 s\n",
      "Epoch  739 / 1000  : Train-loss =  41.83775519247109 , Val-loss =  39.25090388247841 , Time for epoch =  0.020009279251098633 s\n",
      "Epoch  740 / 1000  : Train-loss =  41.83629537032822 , Val-loss =  39.25296412016216 , Time for epoch =  0.021084070205688477 s\n",
      "Epoch  741 / 1000  : Train-loss =  41.83453570651469 , Val-loss =  39.2508430480957 , Time for epoch =  0.019231796264648438 s\n",
      "Epoch  742 / 1000  : Train-loss =  41.83272699043576 , Val-loss =  39.25105074832314 , Time for epoch =  0.018990755081176758 s\n",
      "Epoch  743 / 1000  : Train-loss =  41.82818851363187 , Val-loss =  39.23490313479775 , Time for epoch =  0.019115924835205078 s\n",
      "Epoch  744 / 1000  : Train-loss =  41.824925298744674 , Val-loss =  39.225966905292715 , Time for epoch =  0.024087190628051758 s\n",
      "Epoch  745 / 1000  : Train-loss =  41.82159068220753 , Val-loss =  39.21463956330952 , Time for epoch =  0.018877267837524414 s\n",
      "Epoch  746 / 1000  : Train-loss =  41.8183920585503 , Val-loss =  39.207195683529505 , Time for epoch =  0.01840806007385254 s\n",
      "Epoch  747 / 1000  : Train-loss =  41.81264847146589 , Val-loss =  39.18454762508995 , Time for epoch =  0.01928091049194336 s\n",
      "Epoch  748 / 1000  : Train-loss =  41.808335083352645 , Val-loss =  39.170334464625306 , Time for epoch =  0.019140243530273438 s\n",
      "Epoch  749 / 1000  : Train-loss =  41.857156462588556 , Val-loss =  39.19240349217465 , Time for epoch =  0.01918482780456543 s\n",
      "Epoch  750 / 1000  : Train-loss =  41.85881927188507 , Val-loss =  39.23516183150442 , Time for epoch =  0.022322893142700195 s\n",
      "Epoch  751 / 1000  : Train-loss =  41.860644744614426 , Val-loss =  39.28217917994449 , Time for epoch =  0.01900029182434082 s\n",
      "Epoch  752 / 1000  : Train-loss =  41.860138154972745 , Val-loss =  39.30916334453382 , Time for epoch =  0.019969940185546875 s\n",
      "Epoch  753 / 1000  : Train-loss =  41.86046464564436 , Val-loss =  39.3376522064209 , Time for epoch =  0.019185781478881836 s\n",
      "Epoch  754 / 1000  : Train-loss =  41.86019806942697 , Val-loss =  39.35928535461426 , Time for epoch =  0.019241809844970703 s\n",
      "Epoch  755 / 1000  : Train-loss =  41.85906327242232 , Val-loss =  39.375814839413295 , Time for epoch =  0.02292323112487793 s\n",
      "Epoch  756 / 1000  : Train-loss =  41.85718471721067 , Val-loss =  39.38795260379189 , Time for epoch =  0.02023935317993164 s\n",
      "Epoch  757 / 1000  : Train-loss =  41.85517405924824 , Val-loss =  39.40212601109555 , Time for epoch =  0.019313812255859375 s\n",
      "Epoch  758 / 1000  : Train-loss =  41.85035746515134 , Val-loss =  39.39851188659668 , Time for epoch =  0.01896190643310547 s\n",
      "Epoch  759 / 1000  : Train-loss =  41.846664870526155 , Val-loss =  39.40206106085526 , Time for epoch =  0.019367456436157227 s\n",
      "Epoch  760 / 1000  : Train-loss =  41.84282849198681 , Val-loss =  39.40257965890985 , Time for epoch =  0.02227187156677246 s\n",
      "Epoch  761 / 1000  : Train-loss =  41.83853177431613 , Val-loss =  39.400855817292864 , Time for epoch =  0.019275903701782227 s\n",
      "Epoch  762 / 1000  : Train-loss =  41.83388680926824 , Val-loss =  39.397305839940124 , Time for epoch =  0.019305944442749023 s\n",
      "Epoch  763 / 1000  : Train-loss =  41.82894649613375 , Val-loss =  39.39219956648977 , Time for epoch =  0.019495248794555664 s\n",
      "Epoch  764 / 1000  : Train-loss =  41.82374772109554 , Val-loss =  39.385772805464896 , Time for epoch =  0.019787073135375977 s\n",
      "Epoch  765 / 1000  : Train-loss =  41.81833729501498 , Val-loss =  39.378249620136465 , Time for epoch =  0.022006988525390625 s\n",
      "Epoch  766 / 1000  : Train-loss =  41.81274379579361 , Val-loss =  39.36974023517809 , Time for epoch =  0.018868446350097656 s\n",
      "Epoch  767 / 1000  : Train-loss =  41.80522419773253 , Val-loss =  39.35521677920693 , Time for epoch =  0.01876354217529297 s\n",
      "Epoch  768 / 1000  : Train-loss =  41.80364123845504 , Val-loss =  39.34227501718622 , Time for epoch =  0.019212961196899414 s\n",
      "Epoch  769 / 1000  : Train-loss =  41.79737268868139 , Val-loss =  39.33037155552914 , Time for epoch =  0.019393444061279297 s\n",
      "Epoch  770 / 1000  : Train-loss =  41.79120282534152 , Val-loss =  39.31839420920924 , Time for epoch =  0.021312236785888672 s\n",
      "Epoch  771 / 1000  : Train-loss =  41.78500063405872 , Val-loss =  39.30617944817794 , Time for epoch =  0.019287109375 s\n",
      "Epoch  772 / 1000  : Train-loss =  41.778748162048686 , Val-loss =  39.293701171875 , Time for epoch =  0.01920795440673828 s\n",
      "Epoch  773 / 1000  : Train-loss =  41.77243855578751 , Val-loss =  39.28101168180767 , Time for epoch =  0.019077062606811523 s\n",
      "Epoch  774 / 1000  : Train-loss =  41.76608547921908 , Val-loss =  39.26813497041401 , Time for epoch =  0.020033597946166992 s\n",
      "Epoch  775 / 1000  : Train-loss =  41.75961572032864 , Val-loss =  39.25542660763389 , Time for epoch =  0.0245211124420166 s\n",
      "Epoch  776 / 1000  : Train-loss =  41.75298232816707 , Val-loss =  39.24291751259252 , Time for epoch =  0.01970195770263672 s\n",
      "Epoch  777 / 1000  : Train-loss =  41.746375046207405 , Val-loss =  39.23040671097605 , Time for epoch =  0.0200197696685791 s\n",
      "Epoch  778 / 1000  : Train-loss =  41.73976052278853 , Val-loss =  39.21789159272846 , Time for epoch =  0.01938629150390625 s\n",
      "Epoch  779 / 1000  : Train-loss =  41.733145234275 , Val-loss =  39.20533601861251 , Time for epoch =  0.020228147506713867 s\n",
      "Epoch  780 / 1000  : Train-loss =  41.72485014274295 , Val-loss =  39.187584023726615 , Time for epoch =  0.01916646957397461 s\n",
      "Epoch  781 / 1000  : Train-loss =  41.72251032166562 , Val-loss =  39.171961433009095 , Time for epoch =  0.021271228790283203 s\n",
      "Epoch  782 / 1000  : Train-loss =  41.71563872644457 , Val-loss =  39.157956876252825 , Time for epoch =  0.02206897735595703 s\n",
      "Epoch  783 / 1000  : Train-loss =  41.70897029079286 , Val-loss =  39.144342824032435 , Time for epoch =  0.020279645919799805 s\n",
      "Epoch  784 / 1000  : Train-loss =  41.702264861198465 , Val-loss =  39.13122076737253 , Time for epoch =  0.024139881134033203 s\n",
      "Epoch  785 / 1000  : Train-loss =  41.695436531541034 , Val-loss =  39.118464620489824 , Time for epoch =  0.01915740966796875 s\n",
      "Epoch  786 / 1000  : Train-loss =  41.688675293141166 , Val-loss =  39.10590252123381 , Time for epoch =  0.019789457321166992 s\n",
      "Epoch  787 / 1000  : Train-loss =  41.681936210158185 , Val-loss =  39.093415009348014 , Time for epoch =  0.019744157791137695 s\n",
      "Epoch  788 / 1000  : Train-loss =  41.673620385638735 , Val-loss =  39.07588075336657 , Time for epoch =  0.019195556640625 s\n",
      "Epoch  789 / 1000  : Train-loss =  41.67118193200753 , Val-loss =  39.06051445007324 , Time for epoch =  0.02038264274597168 s\n",
      "Epoch  790 / 1000  : Train-loss =  41.66427232990157 , Val-loss =  39.046803625006426 , Time for epoch =  0.020299673080444336 s\n",
      "Epoch  791 / 1000  : Train-loss =  41.657489862819176 , Val-loss =  39.03385694403397 , Time for epoch =  0.019533872604370117 s\n",
      "Epoch  792 / 1000  : Train-loss =  41.65061810595841 , Val-loss =  39.02143147117213 , Time for epoch =  0.020170211791992188 s\n",
      "Epoch  793 / 1000  : Train-loss =  41.64383367764748 , Val-loss =  39.00922694959139 , Time for epoch =  0.02067399024963379 s\n",
      "Epoch  794 / 1000  : Train-loss =  41.63541219463456 , Val-loss =  38.99205047205875 , Time for epoch =  0.02289891242980957 s\n",
      "Epoch  795 / 1000  : Train-loss =  41.63306283681406 , Val-loss =  38.977007715325605 , Time for epoch =  0.020572185516357422 s\n",
      "Epoch  796 / 1000  : Train-loss =  41.6261525019414 , Val-loss =  38.963654467934056 , Time for epoch =  0.019006967544555664 s\n",
      "Epoch  797 / 1000  : Train-loss =  41.61937166203213 , Val-loss =  38.9510757044742 , Time for epoch =  0.01891469955444336 s\n",
      "Epoch  798 / 1000  : Train-loss =  41.612507168182546 , Val-loss =  38.93905368604158 , Time for epoch =  0.01884937286376953 s\n",
      "Epoch  799 / 1000  : Train-loss =  41.60573819262833 , Val-loss =  38.927256533974095 , Time for epoch =  0.01992177963256836 s\n",
      "Epoch  800 / 1000  : Train-loss =  41.59743001905538 , Val-loss =  38.91054093210321 , Time for epoch =  0.021396398544311523 s\n",
      "Epoch  801 / 1000  : Train-loss =  41.5950271800413 , Val-loss =  38.895922108700404 , Time for epoch =  0.020658493041992188 s\n",
      "Epoch  802 / 1000  : Train-loss =  41.5880579005527 , Val-loss =  38.8833122253418 , Time for epoch =  0.019638538360595703 s\n",
      "Epoch  803 / 1000  : Train-loss =  41.58115121873759 , Val-loss =  38.871528926648594 , Time for epoch =  0.019464731216430664 s\n",
      "Epoch  804 / 1000  : Train-loss =  41.57437142409847 , Val-loss =  38.86002691168534 , Time for epoch =  0.019567489624023438 s\n",
      "Epoch  805 / 1000  : Train-loss =  41.566128811593785 , Val-loss =  38.843651119031406 , Time for epoch =  0.02457904815673828 s\n",
      "Epoch  806 / 1000  : Train-loss =  41.563709981023926 , Val-loss =  38.82935975727282 , Time for epoch =  0.020334243774414062 s\n",
      "Epoch  807 / 1000  : Train-loss =  41.5567724367993 , Val-loss =  38.81707663285105 , Time for epoch =  0.019452810287475586 s\n",
      "Epoch  808 / 1000  : Train-loss =  41.54989022723699 , Val-loss =  38.80562551398026 , Time for epoch =  0.01999688148498535 s\n",
      "Epoch  809 / 1000  : Train-loss =  41.54313489407469 , Val-loss =  38.79445979469701 , Time for epoch =  0.02010798454284668 s\n",
      "Epoch  810 / 1000  : Train-loss =  41.535071087422345 , Val-loss =  38.77846637525057 , Time for epoch =  0.019634723663330078 s\n",
      "Epoch  811 / 1000  : Train-loss =  41.53244507784224 , Val-loss =  38.76487741972271 , Time for epoch =  0.020382165908813477 s\n",
      "Epoch  812 / 1000  : Train-loss =  41.525364956613316 , Val-loss =  38.753297203465515 , Time for epoch =  0.020262718200683594 s\n",
      "Epoch  813 / 1000  : Train-loss =  41.51857907354495 , Val-loss =  38.74228547748766 , Time for epoch =  0.020577669143676758 s\n",
      "Epoch  814 / 1000  : Train-loss =  41.51052266999153 , Val-loss =  38.72650327180561 , Time for epoch =  0.021190166473388672 s\n",
      "Epoch  815 / 1000  : Train-loss =  41.50790289970441 , Val-loss =  38.713124425787676 , Time for epoch =  0.02677607536315918 s\n",
      "Epoch  816 / 1000  : Train-loss =  41.50084036487644 , Val-loss =  38.70175542329487 , Time for epoch =  0.018860340118408203 s\n",
      "Epoch  817 / 1000  : Train-loss =  41.49406413708703 , Val-loss =  38.690987034847865 , Time for epoch =  0.019557476043701172 s\n",
      "Epoch  818 / 1000  : Train-loss =  41.48610917861852 , Val-loss =  38.67548079239695 , Time for epoch =  0.019489288330078125 s\n",
      "Epoch  819 / 1000  : Train-loss =  41.4834485673635 , Val-loss =  38.66235662761488 , Time for epoch =  0.020712614059448242 s\n",
      "Epoch  820 / 1000  : Train-loss =  41.47640544007727 , Val-loss =  38.65125585857191 , Time for epoch =  0.019843101501464844 s\n",
      "Epoch  821 / 1000  : Train-loss =  41.46810901232359 , Val-loss =  38.635774210879674 , Time for epoch =  0.020771503448486328 s\n",
      "Epoch  822 / 1000  : Train-loss =  41.465804137752556 , Val-loss =  38.62236976623535 , Time for epoch =  0.02205491065979004 s\n",
      "Epoch  823 / 1000  : Train-loss =  41.45892890024994 , Val-loss =  38.61100528114721 , Time for epoch =  0.021868467330932617 s\n",
      "Epoch  824 / 1000  : Train-loss =  41.452109967247914 , Val-loss =  38.600526307758535 , Time for epoch =  0.025805234909057617 s\n",
      "Epoch  825 / 1000  : Train-loss =  41.443975265416725 , Val-loss =  38.58544419941149 , Time for epoch =  0.020422935485839844 s\n",
      "Epoch  826 / 1000  : Train-loss =  41.441523535776945 , Val-loss =  38.572730214972246 , Time for epoch =  0.019481182098388672 s\n",
      "Epoch  827 / 1000  : Train-loss =  41.43449735910879 , Val-loss =  38.56205859937166 , Time for epoch =  0.019628524780273438 s\n",
      "Epoch  828 / 1000  : Train-loss =  41.42778122896529 , Val-loss =  38.551947141948496 , Time for epoch =  0.020168542861938477 s\n",
      "Epoch  829 / 1000  : Train-loss =  41.41987893271581 , Val-loss =  38.53758751718622 , Time for epoch =  0.02227020263671875 s\n",
      "Epoch  830 / 1000  : Train-loss =  41.416999719910706 , Val-loss =  38.525548332615905 , Time for epoch =  0.020864486694335938 s\n",
      "Epoch  831 / 1000  : Train-loss =  41.41009052729203 , Val-loss =  38.51525808635511 , Time for epoch =  0.020047426223754883 s\n",
      "Epoch  832 / 1000  : Train-loss =  41.40217886671508 , Val-loss =  38.50096662420975 , Time for epoch =  0.019804954528808594 s\n",
      "Epoch  833 / 1000  : Train-loss =  41.399276388567046 , Val-loss =  38.48905934785542 , Time for epoch =  0.020357847213745117 s\n",
      "Epoch  834 / 1000  : Train-loss =  41.39082329960193 , Val-loss =  38.47402662979929 , Time for epoch =  0.0265352725982666 s\n",
      "Epoch  835 / 1000  : Train-loss =  41.388453726041114 , Val-loss =  38.46165757430227 , Time for epoch =  0.020061969757080078 s\n",
      "Epoch  836 / 1000  : Train-loss =  41.38143983399127 , Val-loss =  38.45140346727873 , Time for epoch =  0.01979351043701172 s\n",
      "Epoch  837 / 1000  : Train-loss =  41.37474166740805 , Val-loss =  38.441763626901725 , Time for epoch =  0.02004218101501465 s\n",
      "Epoch  838 / 1000  : Train-loss =  41.36695299310199 , Val-loss =  38.42790904798006 , Time for epoch =  0.01978588104248047 s\n",
      "Epoch  839 / 1000  : Train-loss =  41.36404862915729 , Val-loss =  38.41639368157638 , Time for epoch =  0.02053976058959961 s\n",
      "Epoch  840 / 1000  : Train-loss =  41.35573905470681 , Val-loss =  38.40177786977667 , Time for epoch =  0.02012801170349121 s\n",
      "Epoch  841 / 1000  : Train-loss =  41.3533191788668 , Val-loss =  38.389734870509095 , Time for epoch =  0.0196380615234375 s\n",
      "Epoch  842 / 1000  : Train-loss =  41.346341968256205 , Val-loss =  38.37985179298803 , Time for epoch =  0.01929497718811035 s\n",
      "Epoch  843 / 1000  : Train-loss =  41.33828556470278 , Val-loss =  38.36572596901342 , Time for epoch =  0.019343852996826172 s\n",
      "Epoch  844 / 1000  : Train-loss =  41.335893523221635 , Val-loss =  38.3539894505551 , Time for epoch =  0.0203549861907959 s\n",
      "Epoch  845 / 1000  : Train-loss =  41.32894218574136 , Val-loss =  38.34428927772924 , Time for epoch =  0.022915363311767578 s\n",
      "Epoch  846 / 1000  : Train-loss =  41.32098672080175 , Val-loss =  38.3303875170256 , Time for epoch =  0.022167444229125977 s\n",
      "Epoch  847 / 1000  : Train-loss =  41.31854965727208 , Val-loss =  38.31884354039242 , Time for epoch =  0.019957780838012695 s\n",
      "Epoch  848 / 1000  : Train-loss =  41.3116295916886 , Val-loss =  38.309323862979284 , Time for epoch =  0.020626306533813477 s\n",
      "Epoch  849 / 1000  : Train-loss =  41.30380567992474 , Val-loss =  38.29563361720035 , Time for epoch =  0.02084946632385254 s\n",
      "Epoch  850 / 1000  : Train-loss =  41.30129524274061 , Val-loss =  38.28423801221346 , Time for epoch =  0.019887685775756836 s\n",
      "Epoch  851 / 1000  : Train-loss =  41.294391675184 , Val-loss =  38.27489371048777 , Time for epoch =  0.019997835159301758 s\n",
      "Epoch  852 / 1000  : Train-loss =  41.28659348568674 , Val-loss =  38.26176914415861 , Time for epoch =  0.020756244659423828 s\n",
      "Epoch  853 / 1000  : Train-loss =  41.28375752766927 , Val-loss =  38.25099684062757 , Time for epoch =  0.020616769790649414 s\n",
      "Epoch  854 / 1000  : Train-loss =  41.27564703946733 , Val-loss =  38.23720369840923 , Time for epoch =  0.020028352737426758 s\n",
      "Epoch  855 / 1000  : Train-loss =  41.2732085966121 , Val-loss =  38.22592735290527 , Time for epoch =  0.025056123733520508 s\n",
      "Epoch  856 / 1000  : Train-loss =  41.26630561095847 , Val-loss =  38.21677850422106 , Time for epoch =  0.019762039184570312 s\n",
      "Epoch  857 / 1000  : Train-loss =  41.258484684141344 , Val-loss =  38.203928897255345 , Time for epoch =  0.02031874656677246 s\n",
      "Epoch  858 / 1000  : Train-loss =  41.255696161992134 , Val-loss =  38.19337533649645 , Time for epoch =  0.020085811614990234 s\n",
      "Epoch  859 / 1000  : Train-loss =  41.24762537250411 , Val-loss =  38.17984199523926 , Time for epoch =  0.020884275436401367 s\n",
      "Epoch  860 / 1000  : Train-loss =  41.24519308273402 , Val-loss =  38.16881912632992 , Time for epoch =  0.020212888717651367 s\n",
      "Epoch  861 / 1000  : Train-loss =  41.238312036977646 , Val-loss =  38.15991863451506 , Time for epoch =  0.019848108291625977 s\n",
      "Epoch  862 / 1000  : Train-loss =  41.23059733978099 , Val-loss =  38.14733294436806 , Time for epoch =  0.02007603645324707 s\n",
      "Epoch  863 / 1000  : Train-loss =  41.227758051985404 , Val-loss =  38.137053539878444 , Time for epoch =  0.019960403442382812 s\n",
      "Epoch  864 / 1000  : Train-loss =  41.21969519361938 , Val-loss =  38.12420644258198 , Time for epoch =  0.020383834838867188 s\n",
      "Epoch  865 / 1000  : Train-loss =  41.2169551418326 , Val-loss =  38.11391097620914 , Time for epoch =  0.02388143539428711 s\n",
      "Epoch  866 / 1000  : Train-loss =  41.208897143433994 , Val-loss =  38.10071433217902 , Time for epoch =  0.019460201263427734 s\n",
      "Epoch  867 / 1000  : Train-loss =  41.20650908906581 , Val-loss =  38.09000647695441 , Time for epoch =  0.019440650939941406 s\n",
      "Epoch  868 / 1000  : Train-loss =  41.19965054355772 , Val-loss =  38.08142682125694 , Time for epoch =  0.019516944885253906 s\n",
      "Epoch  869 / 1000  : Train-loss =  41.19205529811018 , Val-loss =  38.069211759065325 , Time for epoch =  0.02147054672241211 s\n",
      "Epoch  870 / 1000  : Train-loss =  41.189170751194496 , Val-loss =  38.059293947721784 , Time for epoch =  0.021067380905151367 s\n",
      "Epoch  871 / 1000  : Train-loss =  41.181286752560716 , Val-loss =  38.046857131154916 , Time for epoch =  0.01988959312438965 s\n",
      "Epoch  872 / 1000  : Train-loss =  41.178453402330646 , Val-loss =  38.03689625388697 , Time for epoch =  0.021036386489868164 s\n",
      "Epoch  873 / 1000  : Train-loss =  41.170482366098526 , Val-loss =  38.0244977850663 , Time for epoch =  0.02027726173400879 s\n",
      "Epoch  874 / 1000  : Train-loss =  41.167717076964294 , Val-loss =  38.01460396616083 , Time for epoch =  0.01960444450378418 s\n",
      "Epoch  875 / 1000  : Train-loss =  41.15969210694739 , Val-loss =  38.0022924322831 , Time for epoch =  0.023701190948486328 s\n",
      "Epoch  876 / 1000  : Train-loss =  41.156984318447655 , Val-loss =  37.99248625102796 , Time for epoch =  0.020548582077026367 s\n",
      "Epoch  877 / 1000  : Train-loss =  41.14893093216891 , Val-loss =  37.980274501599766 , Time for epoch =  0.020001888275146484 s\n",
      "Epoch  878 / 1000  : Train-loss =  41.14625674317786 , Val-loss =  37.97054862976074 , Time for epoch =  0.018922805786132812 s\n",
      "Epoch  879 / 1000  : Train-loss =  41.1383626474499 , Val-loss =  37.95803712543688 , Time for epoch =  0.0200345516204834 s\n",
      "Epoch  880 / 1000  : Train-loss =  41.13594277160989 , Val-loss =  37.94792918155068 , Time for epoch =  0.019429922103881836 s\n",
      "Epoch  881 / 1000  : Train-loss =  41.127786377728995 , Val-loss =  37.93535202427914 , Time for epoch =  0.01949930191040039 s\n",
      "Epoch  882 / 1000  : Train-loss =  41.12553084637486 , Val-loss =  37.92530531632273 , Time for epoch =  0.020959854125976562 s\n",
      "Epoch  883 / 1000  : Train-loss =  41.11871958587129 , Val-loss =  37.91742776569567 , Time for epoch =  0.019762516021728516 s\n",
      "Epoch  884 / 1000  : Train-loss =  41.11128640040166 , Val-loss =  37.90597885533383 , Time for epoch =  0.019983530044555664 s\n",
      "Epoch  885 / 1000  : Train-loss =  41.10837850193519 , Val-loss =  37.896780014038086 , Time for epoch =  0.025197744369506836 s\n",
      "Epoch  886 / 1000  : Train-loss =  41.10078706040894 , Val-loss =  37.885096198634095 , Time for epoch =  0.019438982009887695 s\n",
      "Epoch  887 / 1000  : Train-loss =  41.097817146171955 , Val-loss =  37.87588541131271 , Time for epoch =  0.022423744201660156 s\n",
      "Epoch  888 / 1000  : Train-loss =  41.090273302153676 , Val-loss =  37.86429887068899 , Time for epoch =  0.020052671432495117 s\n",
      "Epoch  889 / 1000  : Train-loss =  41.085846432184766 , Val-loss =  37.85058352821752 , Time for epoch =  0.020632028579711914 s\n",
      "Epoch  890 / 1000  : Train-loss =  41.083488960050595 , Val-loss =  37.84049495897795 , Time for epoch =  0.02359151840209961 s\n",
      "Epoch  891 / 1000  : Train-loss =  41.07664125517937 , Val-loss =  37.83279007359555 , Time for epoch =  0.02439093589782715 s\n",
      "Epoch  892 / 1000  : Train-loss =  41.069260408649335 , Val-loss =  37.82168920416581 , Time for epoch =  0.019441843032836914 s\n",
      "Epoch  893 / 1000  : Train-loss =  41.06491330249161 , Val-loss =  37.808277431287266 , Time for epoch =  0.019244670867919922 s\n",
      "Epoch  894 / 1000  : Train-loss =  41.06259985023973 , Val-loss =  37.79837748878881 , Time for epoch =  0.019228696823120117 s\n",
      "Epoch  895 / 1000  : Train-loss =  41.05576626190358 , Val-loss =  37.79090007982756 , Time for epoch =  0.02499842643737793 s\n",
      "Epoch  896 / 1000  : Train-loss =  41.04844409058997 , Val-loss =  37.77999938161749 , Time for epoch =  0.02301788330078125 s\n",
      "Epoch  897 / 1000  : Train-loss =  41.04413923705365 , Val-loss =  37.766796613994394 , Time for epoch =  0.018834590911865234 s\n",
      "Epoch  898 / 1000  : Train-loss =  41.04179646335753 , Val-loss =  37.75710587752493 , Time for epoch =  0.018650531768798828 s\n",
      "Epoch  899 / 1000  : Train-loss =  41.03359703020861 , Val-loss =  37.745304709986634 , Time for epoch =  0.02002859115600586 s\n",
      "Epoch  900 / 1000  : Train-loss =  41.03146912957315 , Val-loss =  37.73601511905068 , Time for epoch =  0.02061772346496582 s\n",
      "Epoch  901 / 1000  : Train-loss =  41.02470594072072 , Val-loss =  37.72886677792198 , Time for epoch =  0.020272016525268555 s\n",
      "Epoch  902 / 1000  : Train-loss =  41.01750240218168 , Val-loss =  37.71831783495451 , Time for epoch =  0.020212650299072266 s\n",
      "Epoch  903 / 1000  : Train-loss =  41.0132637454965 , Val-loss =  37.70547133997867 , Time for epoch =  0.020412445068359375 s\n",
      "Epoch  904 / 1000  : Train-loss =  41.01086169312903 , Val-loss =  37.69605726944773 , Time for epoch =  0.020587921142578125 s\n",
      "Epoch  905 / 1000  : Train-loss =  41.002841313680015 , Val-loss =  37.68457141675447 , Time for epoch =  0.02489638328552246 s\n",
      "Epoch  906 / 1000  : Train-loss =  41.000613929188184 , Val-loss =  37.675541727166426 , Time for epoch =  0.019174575805664062 s\n",
      "Epoch  907 / 1000  : Train-loss =  40.99265473575915 , Val-loss =  37.664232655575404 , Time for epoch =  0.018864154815673828 s\n",
      "Epoch  908 / 1000  : Train-loss =  40.99043765310514 , Val-loss =  37.655315599943464 , Time for epoch =  0.019019603729248047 s\n",
      "Epoch  909 / 1000  : Train-loss =  40.98252153127207 , Val-loss =  37.64411976462916 , Time for epoch =  0.019777774810791016 s\n",
      "Epoch  910 / 1000  : Train-loss =  40.98028982561187 , Val-loss =  37.63530761317203 , Time for epoch =  0.022089242935180664 s\n",
      "Epoch  911 / 1000  : Train-loss =  40.9724249112404 , Val-loss =  37.6242157785516 , Time for epoch =  0.019711971282958984 s\n",
      "Epoch  912 / 1000  : Train-loss =  40.970170188084836 , Val-loss =  37.615497287951015 , Time for epoch =  0.01988077163696289 s\n",
      "Epoch  913 / 1000  : Train-loss =  40.962193225063174 , Val-loss =  37.6049478430497 , Time for epoch =  0.020805835723876953 s\n",
      "Epoch  914 / 1000  : Train-loss =  40.95963223775228 , Val-loss =  37.596849843075404 , Time for epoch =  0.02058100700378418 s\n",
      "Epoch  915 / 1000  : Train-loss =  40.95204592559297 , Val-loss =  37.58653369702791 , Time for epoch =  0.024901866912841797 s\n",
      "Epoch  916 / 1000  : Train-loss =  40.94924269422973 , Val-loss =  37.57857242383455 , Time for epoch =  0.019772768020629883 s\n",
      "Epoch  917 / 1000  : Train-loss =  40.94197188124145 , Val-loss =  37.56835425527472 , Time for epoch =  0.020137786865234375 s\n",
      "Epoch  918 / 1000  : Train-loss =  40.937644387369104 , Val-loss =  37.5565569024337 , Time for epoch =  0.020127058029174805 s\n",
      "Epoch  919 / 1000  : Train-loss =  40.93489391520872 , Val-loss =  37.54826525637978 , Time for epoch =  0.021065235137939453 s\n",
      "Epoch  920 / 1000  : Train-loss =  40.92731421950173 , Val-loss =  37.538029419748405 , Time for epoch =  0.0199429988861084 s\n",
      "Epoch  921 / 1000  : Train-loss =  40.923156587417516 , Val-loss =  37.525811647114004 , Time for epoch =  0.01960444450378418 s\n",
      "Epoch  922 / 1000  : Train-loss =  40.920878868318546 , Val-loss =  37.51703432986611 , Time for epoch =  0.01972222328186035 s\n",
      "Epoch  923 / 1000  : Train-loss =  40.912968145251945 , Val-loss =  37.506301377948965 , Time for epoch =  0.01998114585876465 s\n",
      "Epoch  924 / 1000  : Train-loss =  40.91075782991398 , Val-loss =  37.49795803270842 , Time for epoch =  0.020749330520629883 s\n",
      "Epoch  925 / 1000  : Train-loss =  40.90287209634727 , Val-loss =  37.48789566441586 , Time for epoch =  0.025457143783569336 s\n",
      "Epoch  926 / 1000  : Train-loss =  40.90027528967561 , Val-loss =  37.48021175986842 , Time for epoch =  0.01976752281188965 s\n",
      "Epoch  927 / 1000  : Train-loss =  40.89288337621311 , Val-loss =  37.470415014969674 , Time for epoch =  0.019315719604492188 s\n",
      "Epoch  928 / 1000  : Train-loss =  40.888804613533665 , Val-loss =  37.45859196311549 , Time for epoch =  0.01939845085144043 s\n",
      "Epoch  929 / 1000  : Train-loss =  40.886436462402344 , Val-loss =  37.45014592220909 , Time for epoch =  0.021966218948364258 s\n",
      "Epoch  930 / 1000  : Train-loss =  40.87855937117237 , Val-loss =  37.44019960102282 , Time for epoch =  0.019815921783447266 s\n",
      "Epoch  931 / 1000  : Train-loss =  40.87593797371213 , Val-loss =  37.432699504651524 , Time for epoch =  0.01964592933654785 s\n",
      "Epoch  932 / 1000  : Train-loss =  40.86892693729724 , Val-loss =  37.426008124100534 , Time for epoch =  0.019760847091674805 s\n",
      "Epoch  933 / 1000  : Train-loss =  40.86551197504593 , Val-loss =  37.412860669587786 , Time for epoch =  0.020104408264160156 s\n",
      "Epoch  934 / 1000  : Train-loss =  40.86249305164747 , Val-loss =  37.404490320306074 , Time for epoch =  0.01944446563720703 s\n",
      "Epoch  935 / 1000  : Train-loss =  40.85496113664013 , Val-loss =  37.39456236989874 , Time for epoch =  0.024774551391601562 s\n",
      "Epoch  936 / 1000  : Train-loss =  40.85085280466888 , Val-loss =  37.38276571976511 , Time for epoch =  0.019510507583618164 s\n",
      "Epoch  937 / 1000  : Train-loss =  40.84842124766549 , Val-loss =  37.3743550150018 , Time for epoch =  0.018798351287841797 s\n",
      "Epoch  938 / 1000  : Train-loss =  40.840603402778925 , Val-loss =  37.36456881071392 , Time for epoch =  0.021680593490600586 s\n",
      "Epoch  939 / 1000  : Train-loss =  40.83788082963329 , Val-loss =  37.357217487535976 , Time for epoch =  0.021935462951660156 s\n",
      "Epoch  940 / 1000  : Train-loss =  40.83070309956869 , Val-loss =  37.347783741198086 , Time for epoch =  0.019361495971679688 s\n",
      "Epoch  941 / 1000  : Train-loss =  40.82650399073369 , Val-loss =  37.33684640181692 , Time for epoch =  0.019535064697265625 s\n",
      "Epoch  942 / 1000  : Train-loss =  40.823647601456294 , Val-loss =  37.32935262981214 , Time for epoch =  0.019666433334350586 s\n",
      "Epoch  943 / 1000  : Train-loss =  40.816445021979554 , Val-loss =  37.319997586702044 , Time for epoch =  0.02038884162902832 s\n",
      "Epoch  944 / 1000  : Train-loss =  40.812569623613086 , Val-loss =  37.312057294343646 , Time for epoch =  0.02125239372253418 s\n",
      "Epoch  945 / 1000  : Train-loss =  40.81049565676242 , Val-loss =  37.3026835792943 , Time for epoch =  0.020850658416748047 s\n",
      "Epoch  946 / 1000  : Train-loss =  40.80305445396294 , Val-loss =  37.29284698084781 , Time for epoch =  0.03492259979248047 s\n",
      "Epoch  947 / 1000  : Train-loss =  40.79877575373246 , Val-loss =  37.28184860631039 , Time for epoch =  0.027374267578125 s\n",
      "Epoch  948 / 1000  : Train-loss =  40.7945340258927 , Val-loss =  37.270118713378906 , Time for epoch =  0.03507590293884277 s\n",
      "Epoch  949 / 1000  : Train-loss =  40.79223193152476 , Val-loss =  37.2619907981471 , Time for epoch =  0.02040719985961914 s\n",
      "Epoch  950 / 1000  : Train-loss =  40.78432269554354 , Val-loss =  37.25257672761616 , Time for epoch =  0.020170927047729492 s\n",
      "Epoch  951 / 1000  : Train-loss =  40.78167972456937 , Val-loss =  37.24558458830181 , Time for epoch =  0.020622730255126953 s\n",
      "Epoch  952 / 1000  : Train-loss =  40.77453170388432 , Val-loss =  37.236605192485605 , Time for epoch =  0.020692825317382812 s\n",
      "Epoch  953 / 1000  : Train-loss =  40.77040083933685 , Val-loss =  37.22615342391165 , Time for epoch =  0.020624399185180664 s\n",
      "Epoch  954 / 1000  : Train-loss =  40.7665644607975 , Val-loss =  37.2176762631065 , Time for epoch =  0.020497798919677734 s\n",
      "Epoch  955 / 1000  : Train-loss =  40.7651085072318 , Val-loss =  37.2079896424946 , Time for epoch =  0.028576135635375977 s\n",
      "Epoch  956 / 1000  : Train-loss =  40.75700601480775 , Val-loss =  37.19835150869269 , Time for epoch =  0.025768756866455078 s\n",
      "Epoch  957 / 1000  : Train-loss =  40.75424024075438 , Val-loss =  37.19138948540939 , Time for epoch =  0.02622699737548828 s\n",
      "Epoch  958 / 1000  : Train-loss =  40.747154774638894 , Val-loss =  37.18252111736097 , Time for epoch =  0.021903038024902344 s\n",
      "Epoch  959 / 1000  : Train-loss =  40.74303375933803 , Val-loss =  37.17224301789936 , Time for epoch =  0.019869327545166016 s\n",
      "Epoch  960 / 1000  : Train-loss =  40.73891700054966 , Val-loss =  37.16112668890702 , Time for epoch =  0.01980447769165039 s\n",
      "Epoch  961 / 1000  : Train-loss =  40.736540562688965 , Val-loss =  37.15352399725663 , Time for epoch =  0.028690338134765625 s\n",
      "Epoch  962 / 1000  : Train-loss =  40.728894874874484 , Val-loss =  37.144664664017526 , Time for epoch =  0.02141261100769043 s\n",
      "Epoch  963 / 1000  : Train-loss =  40.72529742138534 , Val-loss =  37.13682797080592 , Time for epoch =  0.019533634185791016 s\n",
      "Epoch  964 / 1000  : Train-loss =  40.72378398873712 , Val-loss =  37.127553739045794 , Time for epoch =  0.028390884399414062 s\n",
      "Epoch  965 / 1000  : Train-loss =  40.71588962360964 , Val-loss =  37.11829225640548 , Time for epoch =  0.021185874938964844 s\n",
      "Epoch  966 / 1000  : Train-loss =  40.71189804939227 , Val-loss =  37.10757094935367 , Time for epoch =  0.01960134506225586 s\n",
      "Epoch  967 / 1000  : Train-loss =  40.70952563097248 , Val-loss =  37.10014443648489 , Time for epoch =  0.02253413200378418 s\n",
      "Epoch  968 / 1000  : Train-loss =  40.70193916794944 , Val-loss =  37.09149641739695 , Time for epoch =  0.020444393157958984 s\n",
      "Epoch  969 / 1000  : Train-loss =  40.69784585769567 , Val-loss =  37.081541663721985 , Time for epoch =  0.020239830017089844 s\n",
      "Epoch  970 / 1000  : Train-loss =  40.69516274619237 , Val-loss =  37.074923063579355 , Time for epoch =  0.020261526107788086 s\n",
      "Epoch  971 / 1000  : Train-loss =  40.688350214123055 , Val-loss =  37.06937087209601 , Time for epoch =  0.02031087875366211 s\n",
      "Epoch  972 / 1000  : Train-loss =  40.68511820647676 , Val-loss =  37.05777881019994 , Time for epoch =  0.02040576934814453 s\n",
      "Epoch  973 / 1000  : Train-loss =  40.680804408876234 , Val-loss =  37.046687377126595 , Time for epoch =  0.025938034057617188 s\n",
      "Epoch  974 / 1000  : Train-loss =  40.67833485576393 , Val-loss =  37.039285358629726 , Time for epoch =  0.020760297775268555 s\n",
      "Epoch  975 / 1000  : Train-loss =  40.67078422287763 , Val-loss =  37.03078510886744 , Time for epoch =  0.019457340240478516 s\n",
      "Epoch  976 / 1000  : Train-loss =  40.66671063266905 , Val-loss =  37.02103695116545 , Time for epoch =  0.020612239837646484 s\n",
      "Epoch  977 / 1000  : Train-loss =  40.66395130265231 , Val-loss =  37.01460888511256 , Time for epoch =  0.019298315048217773 s\n",
      "Epoch  978 / 1000  : Train-loss =  40.6572627051402 , Val-loss =  37.00923718904194 , Time for epoch =  0.019471406936645508 s\n",
      "Epoch  979 / 1000  : Train-loss =  40.65407481436002 , Val-loss =  36.9978921789872 , Time for epoch =  0.019225120544433594 s\n",
      "Epoch  980 / 1000  : Train-loss =  40.64958226478706 , Val-loss =  36.98750776993601 , Time for epoch =  0.019171953201293945 s\n",
      "Epoch  981 / 1000  : Train-loss =  40.64666198471845 , Val-loss =  36.98091175681666 , Time for epoch =  0.019303321838378906 s\n",
      "Epoch  982 / 1000  : Train-loss =  40.63968562541035 , Val-loss =  36.97279769495914 , Time for epoch =  0.024799585342407227 s\n",
      "Epoch  983 / 1000  : Train-loss =  40.6356825963252 , Val-loss =  36.963333330656354 , Time for epoch =  0.019572734832763672 s\n",
      "Epoch  984 / 1000  : Train-loss =  40.63148377844169 , Val-loss =  36.953587883397155 , Time for epoch =  0.01840686798095703 s\n",
      "Epoch  985 / 1000  : Train-loss =  40.62777541855634 , Val-loss =  36.94599794086657 , Time for epoch =  0.018359899520874023 s\n",
      "Epoch  986 / 1000  : Train-loss =  40.62624349432477 , Val-loss =  36.93728778236791 , Time for epoch =  0.021489381790161133 s\n",
      "Epoch  987 / 1000  : Train-loss =  40.6184744215281 , Val-loss =  36.928741354691354 , Time for epoch =  0.021966934204101562 s\n",
      "Epoch  988 / 1000  : Train-loss =  40.614380809546866 , Val-loss =  36.91922388578716 , Time for epoch =  0.02075648307800293 s\n",
      "Epoch  989 / 1000  : Train-loss =  40.610370560554465 , Val-loss =  36.90905591061241 , Time for epoch =  0.019536495208740234 s\n",
      "Epoch  990 / 1000  : Train-loss =  40.60810883301126 , Val-loss =  36.90226986533717 , Time for epoch =  0.019719839096069336 s\n",
      "Epoch  991 / 1000  : Train-loss =  40.600881145498846 , Val-loss =  36.89706220124897 , Time for epoch =  0.01982593536376953 s\n",
      "Epoch  992 / 1000  : Train-loss =  40.5977093863622 , Val-loss =  36.88612737153706 , Time for epoch =  0.020840883255004883 s\n",
      "Epoch  993 / 1000  : Train-loss =  40.59348120393052 , Val-loss =  36.87567309329384 , Time for epoch =  0.024696826934814453 s\n",
      "Epoch  994 / 1000  : Train-loss =  40.591152794617045 , Val-loss =  36.86886275442023 , Time for epoch =  0.020076990127563477 s\n",
      "Epoch  995 / 1000  : Train-loss =  40.58361881062136 , Val-loss =  36.86105045519377 , Time for epoch =  0.01958441734313965 s\n",
      "Epoch  996 / 1000  : Train-loss =  40.5796406525003 , Val-loss =  36.85202086599249 , Time for epoch =  0.020825862884521484 s\n",
      "Epoch  997 / 1000  : Train-loss =  40.57600924389511 , Val-loss =  36.84492713526676 , Time for epoch =  0.019851207733154297 s\n",
      "Epoch  998 / 1000  : Train-loss =  40.57455906625521 , Val-loss =  36.83666590640419 , Time for epoch =  0.02011728286743164 s\n",
      "Epoch  999 / 1000  : Train-loss =  40.566861718387926 , Val-loss =  36.828575435437656 , Time for epoch =  0.019809722900390625 s\n",
      "Epoch  1000 / 1000  : Train-loss =  40.562833839890644 , Val-loss =  36.81955347563091 , Time for epoch =  0.01978278160095215 s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAAEWCAYAAADIJfYaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3X18XHWZ///XNZPJXVOapmnTexpo\nQ2nptpCKRV0FFFcUARVZuVG8YfErrugiLrrrrq5fcN11FZZd5ccuN+Lud5EVFBBcXCwgyyI3TWga\nmgbS0DRNmjZNM0kakkwyM9fvj3MmSdu06U1mpmc+1/PxmMfMuZkzn3dO4ZrPOWc+R1QVY4wxxmRG\nKNsNMMYYY1xihdcYY4zJICu8xhhjTAZZ4TXGGGMyyAqvMcYYk0FWeI0xxpgMssJrjDHGZJAVXpNT\nRKRFRN6X7XYYY8yhWOE15gQiInnZboMxJr2s8BpniMifiMhWEekWkcdEZL4/X0TkNhHpFJFeEdkk\nImf4yz4oIg0isk9E2kXkpkm2v8Vft0FEzvLnq4gsHbfeT0TkFv/1uSLSJiI3i8gu4D5/GxeNWz9P\nRLrGbW+diLwgIj0iUici545b99Mi8qbfhm0ictXU/hWNMcfLvl0bJ4jI+cDfAu8HNgP/APwMeLc/\n791AFdALLAd6/LfeA1yuqv8jIjOBykNs/+PAt4FLgQ3AqcDIETZvLlAGnIz3ZfhrwBXA4/7yPwK6\nVLVWRBYATwCfBJ4E3gs8LCLLgQHgDuBtqvq6iMzzt2uMOYFY4TWuuAq4V1VrAUTkG0BURJbgFcjp\neAX3ZVXdMu59I8AKEalT1SgQPcT2rwX+XlVf8ae3HkXbksC3VDXmt+0/gFdFpFhVB4Argf/w170a\n+LWq/tqffkpENgAfBB7yt3WGiLSqagfQcRTtMMZkgB1qNq6YD2xPTahqP7AXWKCqTwP/DPwI2C0i\n/yIiJ/mrfgyvqG0Xkd+JyDmH2P4ioPkY27ZHVYfGtW0rsAX4sIgUAxczVnhPBj7uH2buEZEe4F3A\nPFV9C/hj4P8AHSLyhN8TNsacQKzwGlfsxCtaAIjINGAW0A6gqneoajWwEu+Q89f8+a+o6iXAHOAR\n4D8Psf0deIeXJzIAFI+bnnvA8oluEfYA3uHmS4AGvxinPuffVLV03GOaqn7Pb+9vVPUCYB7QCPzr\nIdpkjMkSK7wmF0VEpHDcIw+vx/gZEVkjIgXAd4GXVLVFRN4mIm8XkQjwFjAEJEQkX0SuEpEZqjoC\n9AGJQ3zm3cBNIlLtX6y1VERShX4jcKWIhEXkA8B7jiDDz/DOPX+Bsd4uwL/j9YT/yN9eoX+B1kIR\nqRCRi/0vFTGg/zDtNcZkiRVek4t+DQyOe3xbVdcDfwU8jHfe81TgE/76J+H1DKN4h6P34l18Bd5F\nTC0i0od3CPfqiT5QVX8O3IpXJPfh9Y5TFzZ9Gfgw3gVbV/nLDss/P/t74B3Ag+Pm78DrBf8FsAev\nB/w1vP+WQ8BX8Xr33XgF/vrJPssYk1miOtFRLmOMMcakg/V4jTHGmAyywmuMMcZkkBVeY4wxJoOs\n8BpjjDEZFOiRq8rLy3XJkiXZboYxxgRKTU1Nl6rOznY7XBXowrtkyRI2bNhwTO9tbm7m1FMPNd5B\nbrLMbrDMbjiezCKyffK1TLo4e6i5rMy9seMtsxsssxtczJwr0lp4RaRURB4SkUb/VmfniEiZiDwl\nIk3+80x/XRGRO/zbtm1K3QItXQYGBtK5+ROSZXaDZXaDi5lzRbp7vP8IPKmqy4HVeAO/fx1Yr6rL\ngPX+NMCFwDL/cR1wZzobFgq519m3zG6wzG5wMXOuSNs5Xv/uLu8GPg2gqsPAsIhcApzrr3Y/8Cxw\nM94weD9VbyitF/3e8jx/6LwpF4lE0rHZE5pldoNldsNUZ66pqZmTl5d3N3AGDp+GnAJJ4LV4PH5t\ndXV150QrpPPiqlPwxpK9T0RWAzV4Y9ZWpIqpqnaIyBx//QV4486mtPnz0lJ4+/v7KS8vT8emT1iW\n2Q2W2Q1TnTkvL+/uuXPnnj579uxoKBSysYSPUTKZlD179qzYtWvX3Xi39DxIOr/V5AFnAXeq6pl4\nd335+mHWlwnmHbTzReQ6EdkgIhs6Ojro6uqio6OD9vZ2otEozc3NDA4O0tDQQDKZpLa2FoCamhoA\namtrSSaT9PT0MDg4SHNzM9FolPb2dlLba2lpob+/n8bGRuLxOHV1dfttI/VcX19PLBajqamJvr4+\nWltb6ezspLOzk9bWVvr6+mhqaiIWi1FfXz/hNurq6ojH4zQ2NtLf309LS8sxZ2poaDhspuLi4pzL\nNNl+Ki8vz7lMk+2nkZGRnMs02X7avXt3zmWabD+p6jFnOoQzZs+e3WdF9/iEQiGdPXt2L96Rgwml\n7SYJIjIXeFFVl/jTf4hXeJcC5/q93XnAs6p6mojc5b9+wF//9dR6h/qMtWvX6rH+nKixsZHly926\nR7hldoNldsPxZBaRGlVdO35eXV1dy+rVq7umpHGGurq68tWrVy+ZaFnaeryqugvYISKn+bPeCzQA\njwHX+POuAR71Xz8GfMq/unkd0Juu87s127v55ZtJXLsz09KlS7PdhIyzzG6wzCZI0n0C/UvA/xOR\nTcAavJuPfw+4QESagAv8afDuofomsBXv3qhpu4/oa+193PXcNtp7DnnIJSdt3rw5203IOMvsBssc\nfLt27QovX758xfLly1eUl5evnjNnzh+kpoeGhiY6FXmQyy67bEldXV3B0XxuRUXFH3R1dYWPrdXH\nJq0jV6nqRmDtBIveO8G6Cnwxne1JqT55JgA126MsnFmciY88IaxevTrbTcg4y+wGyxx8c+fOTTQ2\nNjYA3HjjjfNLSkoS3/nOd3aPXyeZ9I5UhsMT18mHHnqoJf0tPX5OXjK+fO50CvOEmu3RbDclo1IX\nWrjEMrvBMueu1157rWDZsmUrr7zyysUrV65c0draGrniiitOPuOMM05funTpyptuumleat3q6urT\nXnjhhaKRkRGmT5++5vrrr19w2mmnrVizZs3y9vb2STua3/zmNyuWLVu2ctmyZStvvfXWOQDRaDT0\n7ne/e9lpp522YtmyZSvvu+++mQCf//znF5566qkrq6qqVnzhC19YcDSZAj1W87HKC4dYu2QWG1rc\nKrzV1dXZbkLGWWY3WOap9bWH6ha9sWvflB4OrJo7feD7l63eMfmaB2tubi68++67t73nPe9pBbj9\n9tvbKioqEiMjI6xbt+60mpqaaHV19dD49/T394fPPffcfT/+8Y/br7322oU/+tGPyr/73e/uOtRn\nPPPMM8U///nPZ9XW1m6Jx+NUV1ef/r73vW/fpk2bChctWhR77rnnmgD27t0b3rFjR9769etnNDU1\nbQ6FQhztoWone7wA8/IHadzVR38snu2mZIwr35DHs8xusMy5bdGiRbH3vOc9o2Nk3nvvvWUrVqw4\nfeXKlSvefPPNwk2bNhUd+J7CwsLk5Zdf3gdQXV090NLSkn+4z3j22Wenf/jDH45Onz49OXPmzOSF\nF17Y88wzz5RUV1cPPvvsszOuv/76Bf/93/89bdasWYk5c+YkQqGQXnHFFSf/9Kc/LZ0+fXryaPI4\n2eMF+ODbV/Dzhldo2NnH2ZVuDDZuvQI3WGY3pDPzsfZM06WoqGi0sNXX1xfcddddFRs2bNhSXl6e\nuOSSSyoHBwcPuvgqLy9v9Gcr4XBYE4mEDA0NyZo1a04HuOiii6L/8A//MPrLmUP9yuWss84aqqmp\naXj44Ydn3HzzzYuefvrpnu9973u76urqtjzyyCMn/exnPyu76667Zv/v//5v05HmcbbH27WzFYCB\nYXd6vKkf6LvEMrvBMrujp6cnPG3atMTMmTMT27dvjzz33HMnHel7CwsLtbGxsaGxsbFhfNEFOO+8\n8/Y98cQTM/v7+6W3tzf05JNPlp5//vn927Zti8yYMSP5xS9+sfuGG27YvXHjxuJoNBqKRqPhK664\novfOO+/c0dDQcFSH5Z3t8Z568iJgNyMJd37LW1VVle0mZJxldoNldsc73/nOgWXLlg1VVVWtXLx4\ncay6urp/KrZ73nnnDXzsYx/be+aZZ64A+OxnP7vn7LPPHnzwwQdn/NVf/dWCUChEJBLRO++8c3t3\nd3f40ksvXTo8PCyqyi233HJURwjSNnJVJhzzyFV1D9L32+/ztj1/yW1XreODq+ZN/p4c0NTUxLJl\ny7LdjIyyzG6wzEfHRq5Kv6yMXHVCm17BSfua+Fz4vxhJHNU58UCrqKjIdhMyzjK7wTKbIHGz8J5y\nLr2z38bHws8xHHen8Pb09GS7CRlnmd1gmU2QuFl4gdjcs6iUXSQS7lxcVVhYmO0mZJxldoNlNkHi\nbOHVojJCosiQfWs0xhiTOc4W3pG86QCEBt0ZvWpoaGjylXKMZXaDZTZB4mzhLSn3htbMG+rOcksy\np7S0NNtNyDjL7AbLbILE2cLbOzDsvYi7861x9+7dk6+UYyyzGyxz8J199tmnPfzww/sNhvGd73xn\nztVXX734UO8pLi4+c6L5N9544/y//uu/PmEv+3a28M6b5/1216WLqxYvPuS/35xlmd1gmYPv4x//\n+N4HHnhgv/F7H3744bKrr7465w5LOlt4W9vaAUgkE1luSea88cYb2W5CxllmN1jm4PvkJz8ZXb9+\n/YzUuMuvv/56fmdnZ+Ttb3/7wDnnnFO1YsWK06uqqlb8+7//+1EdY3/hhReKVq9evbyqqmrFBRdc\ncOqePXvCALfccsuc1G39LrroolMAnnjiiZLly5evWL58+YrTTz99RTQaTUuNdHbIyKVLl8EzkIy7\nU3hXrVqV7SZknGV2g2WeYo98cRGdRzf+8KTmrBjg0h8dcmjFuXPnJlavXv3Www8/POPqq6/uuf/+\n+8suvvjiaElJSfKJJ57YWlZWluzo6Mh7+9vfvvzKK6/sCYWOrCZ++tOfrrzttttaP/ShD/V/5Stf\nmX/zzTfPv/fee3fccccdc7dv315fVFSkqdv6/eAHP5h7xx13bH//+9//Vm9vb6i4uDgtAz042+Nt\naPS/Lao7A2i4dBuxFMvsBsucGy6//PLuBx98cCbAL37xi7JPfvKT3clkUr7yla8srKqqWnHeeedV\ndXZ25re1tR1Rp3Hv3r3hffv2hT/0oQ/1A/zJn/zJ3hdffLEE4LTTThv8yEc+UvnjH/+4LBKJKMC6\ndev6b7rppkW33HLLnK6urnAkEklLTmd7vCtWrIT/AdSdHq/dOs0NltkNac18mJ5pOl111VU93/zm\nNxc9//zzxUNDQ6F3vetdA3fcccesvXv35tXX128pKCjQBQsWrBocHNyv0/ilL31pwVNPPTUDoLGx\nseFIPuuZZ55p+q//+q/pjzzySOnf//3fz29qanrtu9/97q5LL72099FHH53xjne84/Qnn3zyjTPP\nPHPKr8B1tse7ufF1AATr8eYyy+wGy5wbZsyYkVy3bt2+a6+9dslHP/rRboDe3t5weXn5SEFBgf7q\nV7+avnPnzoNuaP9P//RP7anb/Y2fP2vWrMRJJ52UePLJJ0sA7rnnnlnnnHNOfyKRoLm5Of/DH/7w\nvh//+Mdt+/btC/f29oY3b95ccPbZZw/eeuutu1atWvXWa6+9lpbhwZzt8a5ceQb8DiTpTuG1XoEb\nLLMbcjXzJz7xie5rrrnm1AceeOBNgGuvvbb7wgsvXHrGGWecvnLlyoHKysqj6oHed999277whS+c\nfMMNN4QWL14ce+CBB1ri8bhceeWVlfv27Qurqnz+85/fXV5envjqV786/4UXXjgpFAppVVXV4GWX\nXdabjoxu3hYQaHz+MZb/9pP8bPG3+cRn/2yKW3ZiqqurY/Xq1dluRkZZZjdY5qNjtwVMP7st4ASW\nLvNuIu3SoeaVK1dmuwkZZ5ndYJlNkDhbeLe3etcOiENXNW/dujXbTcg4y+wGy2yCxNnCO3eeN1az\nOHRV88KFC7PdhIyzzG6wzFMimUwmZao36iL/73jIXp2zhbc7dRPpAJ/jPlpdXe6dvrHMbrDMU+K1\nPXv2zLDie3ySyaTs2bNnBvDaodZx9qrmaSXebQFd6vGWlJRkuwkZZ5ndYJmPXzwev3bXrl1379q1\n6wwc7pRNgSTwWjwev/ZQK6S18IpIC7APSABxVV0rImXAg8ASoAW4XFWjIiLAPwIfBAaAT6tqbbra\nNuIPFenSOd6RkZFsNyHjLLMbLPPxq66u7gQuntKNmgll4lvNeaq6Ztyl618H1qvqMmC9Pw1wIbDM\nf1wH3JnORiXVO5ri0lXNSYd+s5ximd1gmU2QZONwwiXA/f7r+4FLx83/qXpeBEpFZF66GlFUPM17\n4VCPt7h4asc8DwLL7AbLbIIk3YVXgf8WkRoRuc6fV6GqHQD+8xx//gJg/Pigbf68/YjIdSKyQUQ2\ndHR00NXVRUdHB+3t7USjUZqbmxkcHKShoYFkMkltrXe0OjW8Wm1tLclkktebvEvxY4ODRKNR2tvb\nSW2vpaWF/v5+Ghsbicfj1NXV7beN1HN9fT2xWIympib6+vpobW2ls7OTzs5OWltb6evro6mpiVgs\nRn19/YTbqKurIx6P09jYSH9/Py0tLcecqaGhgcHBQZqbmyfM1NHRkXOZJttP3d3dOZdpsv3U3Nyc\nc5km20+pbeZSpsn2U0tLyzFnMtmV1pGrRGS+qu4UkTnAU8CXgMdUtXTcOlFVnSkiTwB/q6rP+/PX\nA3+uqocckPR4Rq4ajO6i6B9P45E5X+TS6797TNsImsHBQYqKirLdjIyyzG6wzEdnopGrTOaktcer\nqjv9507gl8DZwO7UIWT/udNfvQ1YNO7tC4Gd6WpbagANlw41b9u2LdtNyDjL7AbLbIIkbYVXRKaJ\nyPTUa+D9eL9regy4xl/tGuBR//VjwKfEsw7oTR2SToeq05Z77XTo4qrly5dnuwkZZ5ndYJlNkKSz\nx1sBPC8idcDLwBOq+iTwPeACEWkCLvCnAX4NvAlsBf4VuD6NbaOufjPg1s+JNm7cmO0mZJxldoNl\nNkHi7N2JiA/DLbP51azP8eEv/XBqG2aMMScwO8ebXc6OTlIz+m3RnR5vLt44ezKW2Q2W2QSJs4W3\nuvptAIQcOtScqzfOPhzL7AbLbILE2cJb++qrJBGnrmpO/bbPJZbZDZbZBImzhXfNmjUo4lSPd82a\nNdluQsZZZjdYZhMkzhbexsZGEoRw6RxvY2NjtpuQcZbZDZbZBImzhbeyshIlRMih2wJWVlZmuwkZ\nZ5ndYJlNkDhbeHfu3EmSEAT451RHa+fOtA0EdsKyzG6wzCZInC28ZWVl3jle3OnxlpWVZbsJGWeZ\n3WCZTZA4W3gHBgZISghxqMc7MDCQ7SZknGV2g2U2QeJs4Q2FUtHdKbxjmd1hmd1gmU2QOLvnIpEI\niuBS4Y1EItluQsZZZjdYZhMkzhbe/v5+FHHp2ir6+/uz3YSMs8xusMwmSJwtvOXl5eBYj9fL7BbL\n7AbLbILE2cLb1tYGgDhUeFOZXWKZ3WCZTZA4W3iXLl3qlVyHjjUvXbo0203IOMvsBstsgsTZwrt5\n82ZcO9TsZXaLZXaDZTZB4mzhXb16NSqS7WZk1OrVq7PdhIyzzG6wzCZInC283k2kxalDzS7eONsy\nu8EymyBxtvCO3UTancLr4o2zLbMbLLMJEmcLb01NjX9xVbZbkjkufkO2zG6wzCZInC281dXVKOLU\nz4lc/IZsmd1gmU2QOFt46+vrce2qZi+zWyyzGyyzCRJnC29VVRWIW0NGVlVVZbsJGWeZ3WCZTZA4\nW3hbW1v9V+5U3rHM7rDMbrDMJkicLbwVFRUobg0ZWVFRke0mZJxldoNlNkHibOHt6enxbgvo0LHm\nnp6ebDch4yyzGyyzCRJnC29hYSHexVXu8DK7xTK7wTKbIEl74RWRsIi8KiKP+9OVIvKSiDSJyIMi\nku/PL/Cnt/rLl6S7ba5d1WyMMSb7MtHj/TKwZdz03wG3qeoyIAp8zp//OSCqqkuB2/z10mZoaMg7\n1OyQoaGhbDch4yyzGyyzCZK0Fl4RWQh8CLjbnxbgfOAhf5X7gUv915f40/jL3+uvnxalpaUgIJpM\n10eccEpLS7PdhIyzzG6wzCZI0t3jvR34cyBV3WYBPaoa96fbgAX+6wXADgB/ea+//n5E5DoR2SAi\nGzo6Oujq6qKjo4P29nai0SjNzc0MDg7S0NBAMpmktrYWGBterba2lmQyyaZNm1CFRCJBNBqlvb2d\n1PZaWlro7++nsbGReDxOXV3dfttIPdfX1xOLxWhqaqKvr4/W1lY6Ozvp7OyktbWVvr4+mpqaiMVi\noz92P3AbdXV1xONxGhsb6e/vp6Wl5ZgzNTQ0MDg4SHNz84SZWltbcy7TZPtp9+7dOZdpsv30+uuv\n51ymyfZTql25lGmy/bR169ZjzmSySzRNV/WKyEXAB1X1ehE5F7gJ+Azwe/9wMiKyCPi1qq4Skc3A\nH6lqm7+sGThbVfce6jPWrl2rGzZsOKb2xWIxer+/mtdCp3H+Xzx6TNsImlgsRkFBQbabkVGW2Q2W\n+eiISI2qrp3iJpkjlM4e7zuBi0WkBfgZ3iHm24FSEcnz11kI7PRftwGLAPzlM4DudDXujTfewLst\nYLo+4cTjZXaLZXaDZTZBkrbCq6rfUNWFqroE+ATwtKpeBTwDXOavdg2Q6m4+5k/jL39a09UdB1at\nWuVfXOVO5V21alW2m5BxltkNltkESTZ+x3szcKOIbMU7h3uPP/8eYJY//0bg6+lsRE1NjXdxlUOF\n18XbiFlmN1hmEyRpO8ebCcdzjhdg960raaCS8/7y8SlslTHGnNjsHG92OTty1ei3xeB+7zhqLn5D\ntsxusMwmSJwtvNXV1c6d43XxxtmW2Q2W2QSJs4W3rq4OxK3Cm/qtoUsssxssswkSZwvvypUrAbdu\nk5DK7BLL7AbLbILE2cK7detWcOy2gF5mt1hmN1hmEyTOFt6FCxc6d4534cKF2W5CxllmN1hmEyTO\nFt6urq5sNyHjLLMbLLMbXMycK5wtvCUlJc5dXFVSUpLtJmScZXaDZTZB4mzhHRkZQRHEoXO8IyMj\n2W5CxllmN1hmEyTOFt5k0p378KZYZjdYZje4mDlXOFt4i4uLAXFqrGYvs1sssxssswkSZwtvd3c3\niEtl18/sGMvsBstsgsTZwjt//nznzvHOnz8/203IOMvsBstsgsTZwrtt2zb/lTuFdyyzOyyzGyyz\nCRJnC+/y5csBt+7Hm8rsEsvsBstsgsTZwrtx40b/d7zu2LhxY7abkHGW2Q2W2QSJs4X3rLPOAseG\njPQyu8Uyu8EymyA5osIrIqeKSIH/+lwRuUFEStPbtPSqqanxxmp2p+46eeNsy+wGy2yC5Eh7vA8D\nCRFZCtwDVAL/kbZWZUB1dTWIW7/jdfHG2ZbZDZbZBMmRFt6kqsaBjwC3q+qfAfPS16z0q62t9V+5\nU3jHMrvDMrvBMpsgOdLCOyIiVwDXAI/78yLpaVJmrFmzBtdGrvIyu8Uyu8EymyA50sL7GeAc4FZV\n3SYilcC/p69Z6dfY2IhbPyZKZXaLZXaDZTZBknckK6lqA3ADgIjMBKar6vfS2bB0q6yspEtAHKq8\nlZWV2W5CxllmN1hmEyRHelXzsyJykoiUAXXAfSLyw/Q2Lb127tyJa4eavcxuscxusMwmSI70UPMM\nVe0DPgrcp6rVwPvS16z0Kysrw7Xf8XqZ3WKZ3WCZTZAcaeHNE5F5wOWMXVwVaAMDAyBuneUdGBjI\ndhMyzjK7wTKbIDnSwvsd4DdAs6q+IiKnAE3pa1b6hUIh3Cq7qcxuscxusMwmSI5oz6nqz1X1D1T1\nC/70m6r6scO9R0QKReRlEakTkc0i8jf+/EoReUlEmkTkQRHJ9+cX+NNb/eVLji/a4UUiEXDstoBe\nZrdYZjdYZhMkR3px1UIR+aWIdIrIbhF5WEQWTvK2GHC+qq4G1gAfEJF1wN8Bt6nqMiAKfM5f/3NA\nVFWXArf566VNf3+/czdJ6O/vz3YTMs4yu8EymyA50mMV9wGPAfOBBcCv/HmHpJ7Uv4yI/1DgfOAh\nf/79wKX+60v8afzl7xVJX2UsLy9HHbuquby8PNtNyDjL7AbLbILkSAvvbFW9T1Xj/uMnwOzJ3iQi\nYRHZCHQCTwHNQI8//CRAG14hx3/eAeAv7wVmTbDN60Rkg4hs6OjooKuri46ODtrb24lGozQ3NzM4\nOEhDQwPJZHJ0WLXUgOK1tbUkk0leffVVUAWUaDRKe3s7qe21tLTQ399PY2Mj8Xicurq6/baReq6v\nrycWi9HU1ERfXx+tra10dnbS2dlJa2srfX19NDU1EYvFqK+vn3AbdXV1xONxGhsb6e/vp6Wl5Zgz\nNTQ0MDg4SHNz84SZ3nzzzZzLNNl+amtry7lMk+2nzZs351ymyfbTyy+/nHOZJttPjY2Nx5zJZJfo\nEZzjFJHfAj8BHvBnXQF8RlXfe0Qf4t3J6JfAX+P9HGmpP38R8GtVXSUim4E/UtU2f1kzcLaq7j3U\ndteuXasbNmw4kiYcJB6Ps/OOC9jZM8i677x4TNsImng8Tl7eEY2ZkjMssxss89ERkRpVXTvFTTJH\n6Eh7vJ/F+ynRLqADuAxvGMkjoqo9wLPAOqBURFL/WhYCqV+BtwGLAPzlM4DuI/2Mo7V582ZcG0DD\ny+wWy+wGy2yC5Eivam5V1YtVdbaqzlHVS/EG0zgkEZmdumeviBThDbixBXgGr3CDd9OFR/3Xj/nT\n+Muf1iPpjh+j1atXe+1M1wecgFKZXWKZ3WCZTZAczw/Bbpxk+TzgGRHZBLwCPKWqjwM3AzeKyFa8\nc7j3+OvfA8zy598IfP042japmpoa/6pmd3q8Lt442zK7wTKbIDmic7wTvlFkh6oumuL2HJXjOccL\n0Hrbe9kd7WPt37xMGi+gNsaYE4qd482u4+nxBrqr6H1b9IqtK2NouPgN2TK7wTKbIDlsj1dE9jFx\ngRWgSFWzehnhcfd4b7+Azu4ezvz2y4RD1uM1xrjBerzZddger6pOV9WTJnhMz3bRPV7eb+a8q5qT\njnR5U78TdIlldoNlNkHi7Cjhz5J6AAAdEklEQVTbVVVVIF7hdaTuepkdY5ndYJlNkDhbeFtbW/0h\nI0GDfbr6iLW2tma7CRlnmd1gmU2QOFt4KyoqRn/D60qPt6KiIttNyDjL7AbLbILE2cLb09Pj3KHm\nnp6ebDch4yyzGyyzCRJnC29hYSGMHmh2o/J6md1imd1gmU2QOFt4gbFzvG7UXWOMMScAZwvv0NAQ\nkjrUnO3GZMjQ0FC2m5BxltkNltkEibOFt7S0dPS1K7/jHZ/ZFZbZDZbZBImzhXf37t3OXVy1e/fu\nbDch4yyzGyyzCRJnC+/ixYtHz/G6cqx58eLF2W5CxllmN1hmEyTOFt433niD1JCRrpzl9TK7xTK7\nwTKbIHG28K5atQoR7wdFSTfqLqtWrcp2EzLOMrvBMpsgcbbw7n9bQDcqr4u3EbPMbrDMJkicLbzV\n1dUgOPVzourq6mw3IeMssxssswkSZwvvWI/XnauaXfyGbJndYJlNkDhbeL0er1t3J3LxG7JldoNl\nNkHibOGtq6tj9KpmN+qun9ktltkNltkEibOFd+XKlc4NoLFy5cpsNyHjLLMbLLMJEmcL79atW0df\nu3KoeXxmV1hmN1hmEyTOFt6FCxeOneN1o+56mR1jmd1gmU2QOFt4u7q6SJ3jdeUmCV5mt1hmN1hm\nEyTOFt6SkhLnzvGWlJRkuwkZZ5ndYJlNkDhbeEdGRkiNXOUKL7NbLLMbLLMJkrQVXhFZJCLPiMgW\nEdksIl/255eJyFMi0uQ/z/Tni4jcISJbRWSTiJyVrrYBJJPJ0bLrSo83mUxmuwkZZ5ndYJlNkKSz\nxxsHvqqqpwPrgC+KyArg68B6VV0GrPenAS4ElvmP64A709g2iouLRw81u3KOt7i4ONtNyDjL7AbL\nbIIkbYVXVTtUtdZ/vQ/YAiwALgHu91e7H7jUf30J8FP1vAiUisi8dLWvu7t77Bxvuj7kBNPd3Z3t\nJmScZXaDZTZBkpFzvCKyBDgTeAmoUNUO8IozMMdfbQGwY9zb2vx5aTF//ny8q5rduTuRl9ktltkN\nltkESdoLr4iUAA8DX1HVvsOtOsG8gyqiiFwnIhtEZENHRwddXV10dHTQ3t5ONBqlubmZwcFBGhoa\nSCaT1NbWAmMDitfW1pJMJnnllVdIJhVB6e3to729ndT2Wlpa6O/vp7GxkXg8Pjo0W2obqef6+npi\nsRhNTU309fXR2tpKZ2cnnZ2dtLa20tfXR1NTE7FYjPr6+gm3UVdXRzwep7Gxkf7+flpaWo45U0ND\nA4ODgzQ3NxONRg/K9Prrr+dcpsn207Zt23Iu02T7qa6uLucyTbaffv/73+dcpsn2U319/TFnMtkl\n6eztiUgEeBz4jar+0J/3OnCuqnb4h5KfVdXTROQu//UDB653qO2vXbtWN2zYcExtSyaTtN/3KZLb\nX2LkT2tZOmf6MW0nSJLJJKGQWxeyW2Y3WOajIyI1qrp2iptkjlA6r2oW4B5gS6ro+h4DrvFfXwM8\nOm7+p/yrm9cBvYcrusdr48aNuHaTBC+zWyyzGyyzCZK09XhF5F3A/wD1QOq697/AO8/7n8BioBX4\nuKp2+4X6n4EPAAPAZ1T1sN3Z4+nxAuy49xpk+/MMXL+Rqorc7/EaYwxYjzfb0nlV8/OqKqr6B6q6\nxn/8WlX3qup7VXWZ/9ztr6+q+kVVPVVVV01WdI9XTU0NKnmESTrT43XxxtmW2Q2W2QSJWydFxqmu\nrkbDESLEnfkdr4s3zrbMbrDMJkicLby1tbWIX3jjCTcKb+pKR5dYZjdYZhMkzhbeNWvWIOEIeSQY\nTiSy3ZyMWLNmTbabkHGW2Q2W2QSJs4W3sbGRkF94Y3E3xjxtbGzMdhMyzjK7wTKbIHG28FZWViKR\nfAokzvCIGz3eysrKbDch4yyzGyyzCRJnC+/OnTsJh/MBd26vtXPnzmw3IeMssxssswkSZwtvWVkZ\noUgEgJH4cJZbkxllZWXZbkLGWWY3WGYTJM4W3oGBgdEeb3zYjcI7MDCQ7SZknGV2g2U2QeJs4Q2F\nQoT9Hm98JJbl1mSGa2PZgmV2hWU2QeLsnotEIoQjBQAkHDnUHPG/aLjEMrvBMpsgcbbw9vf3E87z\nDzWPuFF4+/v7s92EjLPMbrDMJkicLbzl5eWEI24V3vLy8mw3IeMssxssswkSZwtvW1sbeX6PN+lI\n4W1ra8t2EzLOMrvBMpsgcbbwLl26lFCed47ElXO8S5cuzXYTMs4yu8EymyBxtvBu3rwZ/J8TJeJu\nDKCxefPmbDch4yyzGyyzCRJnC+/q1ash5PV4k470eFevXp3tJmScZXaDZTZB4mzhrampgXAeAOpI\n4XXxxtmW2Q2W2QSJs4W3urp6rMebcONQs4s3zrbMbrDMJkicLbxej9c7x6uOnON18RuyZXaDZTZB\n4mzhra6uHj3UnEy4cajZxW/IltkNltkEibOFt76+fvRQszpyqLm+vj7bTcg4y+wGy2yCxNnCW1VV\nBeFU4XWjx1tVVZXtJmScZXaDZTZB4mzhbW1thZB3qBlHzvG2trZmuwkZZ5ndYJlNkDhbeCsqKkYv\nriLpRuGtqKjIdhMyzjK7wTKbIHG28Pb09IweasaRc7w9PT3ZbkLGWWY3WGYTJHnZbkC2FBYWQijs\nTTjS4y0sLMx2EzLOMrvBMpsgcbbHC4z+nEgS8Sw3xBhjjCvSVnhF5F4R6RSR18bNKxORp0SkyX+e\n6c8XEblDRLaKyCYROStd7UoZGhoa/TmRqBs93qGhoWw3IeMssxssswmSdPZ4fwJ84IB5XwfWq+oy\nYL0/DXAhsMx/XAfcmcZ2AVBaWjp6cZU4cqi5tLQ0203IOMvsBstsgiRthVdVnwO6D5h9CXC///p+\n4NJx83+qnheBUhGZl662AezevRvCeSQJEXak8O7evTvbTcg4y+wGy2yCJNPneCtUtQPAf57jz18A\n7Bi3Xps/7yAicp2IbBCRDR0dHXR1ddHR0UF7ezvRaJTm5mYGBwdpaGggmUxSW1sLjI1rWltbSzKZ\nZHBwkMHBQeISIZwcpq2tjdT2Wlpa6O/vp7GxkXg8Tl1d3X7bSD3X19cTi8Voamqir6+P1tZWOjs7\n6ezspLW1lb6+PpqamojFYqOjzBy4jbq6OuLxOI2NjfT399PS0nLMmRoaGhgcHKS5uZloNEp7e/t+\nmWbNmpVzmSbbT4sXL865TJPtp3A4nHOZJttP0Wg05zJNtp8KCwuPOZPJLlHV9G1cZAnwuKqe4U/3\nqGrpuOVRVZ0pIk8Af6uqz/vz1wN/rqqHHQV87dq1umHDhmNqW319PatWrWLolkX8bGgdV377QfLz\ncvtas1Rml1hmN1jmoyMiNaq6doqbZI5QpivN7tQhZP+505/fBiwat95CYGc6G5L6B5sI5ZPPCMOJ\nZDo/7oTg2v+YwDK7wjKbIMl04X0MuMZ/fQ3w6Lj5n/Kvbl4H9KYOSadL6hBMMpRPgcSp25H7P0Z3\n8TZiltkNltkESdoONYvIA8C5QDmwG/gW8Ajwn8BioBX4uKp2i4gA/4x3FfQA8BlVnfQY8vEcak4Z\n+OGZPB2dw5+O3MAzN51LZfm049qeMcac6OxQc3al86rmK1R1nqpGVHWhqt6jqntV9b2qusx/7vbX\nVVX9oqqeqqqrjqToHq/Ut8WiomKqFxQTEvj6w5tIJtN3zjvbXPyGbJndYJlNkKT14qp0m4oeL/96\nPhTN5IGq2/jGL+r5P+85lZs/cBpeJ9wYY3KP9XizK7cv4z2M1OX/hAsgHuMTb1vEVW9fzP/3u2a+\n8uBG9uyLZbeBaTCa2SGW2Q2W2QSJsz3eeDxOXl4e/PRSGO6Ha39LMqn809Nb+aenmyjIC3HF2Yu5\n/G2LqKqYPsUtz47RzA6xzG6wzEfHerzZ5WyPd+vWrd6L4jJ4qwuAUEj48vuW8d9/9m7OWz6Hn7zQ\nwvtve44P3P4cd6xvomFnX6DPAY9mdohldoNlNkHi1lfEcRYuXOi9mLEItvwKkkkIed9DTpldwj9f\neRZd/TF+VbeTX9d38MOn3uCHT71BeUk+b1tSxhkLZrDKf8yclp/FJEduNLNDLLMbLLMJEmcLb1dX\nFyUlJVBWCYlheOlOOOtTUDB2WLm8pIDPvLOSz7yzkt19Qzz3xh6e39rFq609/Ndru0bXW1BaxKoF\nMzhl9jQWlRWzaGYxC2cWMb+06IQaDWs0s0MssxssswkSZwvv6D/YFZfCi3fCb/4C1v9fOO1CWPkR\nWPo+yC8eXb/ipEI+vnYRH1/rDbDVOzDCazt7qW/3Hg07+/jtlt3Exx2KDgnMPamQhX4hXjiziAUz\ni0an583IbGF28T9Sy+wGy2yCxNnCOzLi35GoqBS+8HvY8RLU/ydsfgQ2/wIixV7xPf3DsOz93nrj\nzCiO8M6l5bxzafnovHgiya6+Idqig+zoHmBHdJC26ABt3YO8tK2bRzYOMv4UsQhUTC8cV5C9oryg\ntGi0x1wYCU99ZodYZjdYZhMkzhbeZHLc2MyhEJx8jve48Puw/XloeBQafw1bHoNQBCr/EJZfBIvX\nwaxlkHfwed28cMjvzRaz7pRZBy0fSSTZ1esV5rboAG3RQdp7vNc126M8vqmDxAEXb82bUUhl+bSD\nHovKiomEj663vF9mR1hmN1hmEyTOFt7i4uKJF4Tz4JRzvccHfwDtG6DxcdjyODxxo7dOKALlVVCx\nAipWwpyVMLsKTloA4cghPzMSDnnngMuKgYMLczyRZPe+GG3dA35xHmT73rd4s+stHt/UQe/g2Dfc\ncEhYNLPIL8QlVJYXU1UxnVULZ1CcP/FuPWTmHGaZ3WCZTZA4W3i7u7uZOXPm4VcKhWDR2d7jfX8D\ne7fCzo3QuRl2N8D230P9z8fWlxBMn+ddKV26aP/n1Ov8Q48FnRcOsaC0iAWlRbx9guXRt4Z5s+st\ntnW9RYv//GbXW7z4ZjeDIwnAK8gnzyqmcpbfO57tPZ9SXkL/3r2TZ84xR7Sfc4xldoOLmXOFswNo\nDA4OUlRUdPyNGIxC5xavKPfsgN4d/nMr9O2EZHz/9YvK9i/GJ833HtPnwUnzYPp8iBQeVRNUlV19\nQ2zp6GNjaw9Nnf1s8wtzLD52OCoSFubNKGLejELmlxYxd0Yh82cUMqukgNKiCDOKI5QW51NaFKE4\nP5wTw2ZO2X4OEMvshuPJbANoZJezPd5t27axYsWK499Q0Uw4+R3e40DJBOzbtX8xThXnriZofgZG\n3ppgm2VjxXh6BZRUQMncca8rYPpciHj/0YmkCmoR5y+vGPv4pFeQt3W9xZt7+qnb2sZw3jQ6egd5\npaWbXb1DxJOKkKScXuZKlFnSy2zpZbb0URHex0mhIYpDcYplhCIZJhJKogrif25IvGcRCImMzpdQ\nmGQoQjKcTzJcAOECNJyPhgsgz5uWvHyIFCJ5BYTyCpC8QiRSgOR5j1CkkFDEXxYpJBwpJJRfQF6k\niFCkgLxIIeG8EHkhIS8khENy0JeFKdvPAWKZ3eBi5lzhbI83mUwSCmX5N7aqMNQL+zq83vG+Dujr\ngH07x577O72HJg5+f2GpX5zneo9ps2FaufdcXO79HEqT3mN4gOTAXkKDUXhrD/TtRHvbSfa2Eerv\nQA7smQPDoUJioWkMSz4xySdGPiM6dpW1+hFUFQXvim1VkgohEkR0hAgj5DNCgf+cT5wCRgjJ1Py7\ni2keMSIME2GYPIbJ96fzGZZ8hokwIvmMiDedkHxGQvnEJZ9EKEJcCoiH8kn4j2TqOVxAQvJJ5nnv\n0XABiXABhPNJhgvRcD7kFZIM5ZOXFyYkXvEPjfsSEPZfh0TIC8sRrZMfDlOUHybkf5Hxvkx4r0Pj\nvugcbrmqkhcOedOhsXVDMn5dRpfnghPiv+cMO57M1uPNLmd7vBs3buSss87KbiNEvJ8pFZXCnNMP\nvV4yAQPd0L8L+nd7vejRR4f33NUEA10QHzrkZkb/Ew3nw0nzkZMWEl7yDv9w9wLvedocKJkN02aT\nnz+NqRiTS1UZSSgjiSSxRJJ98QQjIyPEY0PEhweJjwyRGI6RGBkkOTyEJmLoSAyNew/8h8ZjSCIG\niWEkEUPiMcR/HUoME0qOPRclhilJxtDYWxSGBwknY0R0mHBymEh8mDwdIU+HCXH8XwCGNTxa8GPk\nEdMIMfIZxv9SoBF/mfcFIaYRBshjhDyGU88a8afD/nOEEc1jxJ+OEx57PW6+9wh7y/35idQ0YeLk\nESeEHmZ02MMVZhHvugHv9fgi7n8BCEH4oPeOex2CvFCI/HCI4oIw5SUF/lER77O9YyTjpke/B8i4\ndcaWCeOOrvjTIYHOzk7mza2A8e3zl3HAdOrLxlg7D97u6PYPeG9qnjCWL/Xeg9fd/0jQ+HVDBywb\nf/Rows8ZbY+//RDs3vYG7znHamcQOVt4s150j0Yo7BXDktnAqkOvp+rd8OGtLu8xMuC9V0KQV+iN\nS108C/JLxv8fLu1EhPw8OWCwkCLgpIy1YUKqkBiBxFhxJz7kPSfGTw97zwn/efy8eIz8RIz8eIyS\neAyND6Ej3pcHRrzpsW3vG92uJIYhOeJ9gUiMIBMd0ZhCSUIkQ3koYRKhPJKSeoRJSB5JwiQlj4T4\nz4T2Wxb3nxMS8p4JkUS89yHe9lPPKiQ0RJIQiUSIhApxhaEeJW/HPmbQRz4jhFRH3xnCey2o92VI\nIS4hEv5nJTTkf6EIjX6xiBMirt7nn6xhEi0ybt0QcRX/OfW+kN/u/V/HU/N0/+Wp5/iB8/TA7YTH\nbU/GXutEyw9uR9IrvUe9T2+59Iyp/4diMsLZwltTU0N1dXW2mzG1RLwhLwume0NhHsDLvCTz7cqi\nw+5nEe/32Hn5+w0VejyO7X+heEc1Ul8CEiN+kY95F+elppNx7zkxAskRf/4By5JxWlveZPGCef56\ncUjGCSVGCCVHIJkgknp/Mg6J+Njr0enUvMTY5ycHxtZJxr1lmvTPNfivR+eNW3bgvILp3pe/SJH3\nhVBCIGH/ERp7oGOfnxzXRk3s3wb/dXwkRp6Ivzwx9jwFRzQyQSXsP0Ko/7cYm84bne89e6/faP0E\nrLs52003x8DZc7zGGAckkwcXY03sP3+0oI//AnHAeyaal1p30vfHD9+O/d6fmGDdQ7y/+ho49fxj\n+rPYOd7scrbHW1tbG6zDzVPAMrvBMo8TCgGhww5sE1S1tbW4tZdzh7M9XrsK0g2W2Q2W+ehYjze7\n3PqXOk5jY2O2m5BxltkNltkNLmbOFc4W3srKgy8+ynWW2Q2W2Q0uZs4VzhbenTt3ZrsJGWeZ3WCZ\n3eBi5lzhbOEtKyvLdhMyzjK7wTK7wcXMucLZwjswMJDtJmScZXaDZXaDi5lzhbOF17UrIMEyu8Iy\nu8HFzLnC2T0XieTe7/omY5ndYJnd4GLmXBHo3/GKyB5g+zG+vRzomsLmBIFldoNldsPxZD5ZVWdP\nZWPMkQt04T0eIrLBtR+QW2Y3WGY3uJg5Vzh7qNkYY4zJBiu8xhhjTAa5XHj/JdsNyALL7AbL7AYX\nM+cEZ8/xGmOMMdngco/XGGOMyTgrvMYYY0wGOVd4ReQDIvK6iGwVka9nuz1TRUQWicgzIrJFRDaL\nyJf9+WUi8pSINPnPM/35IiJ3+H+HTSIS2Htqi0hYRF4Vkcf96UoRecnP/KCI5PvzC/zprf7yJdls\n97ESkVIReUhEGv39fU6u72cR+TP/3/VrIvKAiBTm2n4WkXtFpFNEXhs376j3q4hc46/fJCLXZCOL\nOTynCq+IhIEfARcCK4ArRGRFdls1ZeLAV1X1dGAd8EU/29eB9aq6DFjvT4P3N1jmP64D7sx8k6fM\nl4Et46b/DrjNzxwFPufP/xwQVdWlwG3+ekH0j8CTqrocWI2XPWf3s4gsAG4A1qrqGUAY+AS5t59/\nAnzggHlHtV9FpAz4FvB24GzgW6libU4gqurMAzgH+M246W8A38h2u9KU9VHgAuB1YJ4/bx7wuv/6\nLuCKceuPrhekB7AQ739I5wOPA4I3mk/egfsc+A1wjv86z19Psp3hKPOeBGw7sN25vJ+BBcAOoMzf\nb48Df5SL+xlYArx2rPsVuAK4a9z8/dazx4nxcKrHy9h/wClt/ryc4h9aOxN4CahQ1Q4A/3mOv1qu\n/C1uB/4cSPrTs4AeVY370+NzjWb2l/f66wfJKcAe4D7/8PrdIjKNHN7PqtoO/APQCnTg7bcacns/\npxztfg38/naBa4VXJpiXU7+nEpES4GHgK6rad7hVJ5gXqL+FiFwEdKpqzfjZE6yqR7AsKPKAs4A7\nVfVM4C3GDj9OJPCZ/UOllwCVwHxgGt6h1gPl0n6ezKEyupA98FwrvG3AonHTC4GdWWrLlBORCF7R\n/X+q+gt/9m4Rmecvnwd0+vNz4W/xTuBiEWkBfoZ3uPl2oFRE8vx1xucazewvnwF0Z7LBU6ANaFPV\nl/zph/AKcS7v5/cB21R1j6qOAL8A3kFu7+eUo92vubC/c55rhfcVYJl/NWQ+3gUaj2W5TVNCRAS4\nB9iiqj8ct+gxIHVl4zV4535T8z/lXx25DuhNHdIKClX9hqouVNUlePvyaVW9CngGuMxf7cDMqb/F\nZf76geoNqOouYIeInObPei/QQA7vZ7xDzOtEpNj/d57KnLP7eZyj3a+/Ad4vIjP9IwXv9+eZE0m2\nTzJn+gF8EHgDaAb+MtvtmcJc78I7pLQJ2Og/Poh3bms90OQ/l/nrC94V3s1APd4Vo1nPcRz5zwUe\n91+fArwMbAV+DhT48wv96a3+8lOy3e5jzLoG2ODv60eAmbm+n4G/ARqB14B/AwpybT8DD+Cdwx7B\n67l+7lj2K/BZP/tW4DPZzmWPgx82ZKQxxhiTQa4dajbGGGOyygqvMcYYk0FWeI0xxpgMssJrjDHG\nZJAVXmOMMSaDrPCanCMiKiI/GDd9k4h8Ow2f833/jjnfn+ptT/K5PxGRyyZf0xhzIsqbfBVjAicG\nfFRE/lZVu9L4OZ8HZqtqLI2fYYzJMdbjNbkoDvwL8GcHLhCRk0VkvX8P0/UisvhwG/JHBvq+fx/Y\nehH5Y3/+Y3hjBr+UmjfuPdP8e6u+4t/I4BJ//qdF5FEReVK8e0J/a9x7bvQ/4zUR+cq4+Z/y21on\nIv827mPeLSIviMibqd6viMwTkedEZKO/nT886r+cMSbtrMdrctWPgE0i8vcHzP9n4Keqer+IfBa4\nA7j0MNv5KN5IUauBcuAVEXlOVS8WkX5VXTPBe/4Sb5jCz4pIKfCyiPzWX3Y2cAYw4G/rCbwRxz6D\ndw9VwSvmvwOG/W29U1W7/HutpszDG61sOd7wgQ8BV+LdGu9W/97TxZP+lYwxGWeF1+QkVe0TkZ/i\n3UB9cNyic/CKKXhDDx5YmA/0LuABVU3gDVj/O+BtHH6M7/fj3bzhJn+6EEj1rJ9S1b0AIvILxob6\n/KWqvjVu/h/68x9KHS5X1fED/T+iqkmgQUQq/HmvAPf6N8t4RFU3TpLNGJMFdqjZ5LLb8ca7nXaY\ndSYbM3Wi26xNRoCPqeoa/7FYVbcc4vMOdSu31HYO1b7YAeuhqs8B7wbagX8TkU8dQ9uNMWlmhdfk\nLL+H+J94xTflBbw7GQFcBTw/yWaeA/5YRMIiMhuvsL08yXt+A3zJv5MOInLmuGUXiEiZiBThHeL+\nX/8zLvXvvjMN+AjwP3iD4l8uIrP87Yw/1HwQETkZ7/7E/4p3p6qzJmmnMSYL7FCzyXU/AP503PQN\neIdjvwbswTu3iohcjHeHl78+4P2/xDs8XYfX+/xz9W7Ndzj/F6+3vckvvi3ARf6y5/EOcS8F/kNV\nN/if/xPGCvrdqvqqP/9W4HcikgBeBT59mM89F/iaiIwA/YD1eI05AdndiYzJEBH5NF5x/9PJ1jXG\n5C471GyMMcZkkPV4jTHGmAyyHq8xxhiTQVZ4jTHGmAyywmuMMcZkkBVeY4wxJoOs8BpjjDEZ9P8D\nDGnu8eMqvrcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff149543f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.2 s, sys: 670 ms, total: 21.8 s\n",
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train([X_train, y_train, X_test, y_test], batch_size, [w1, w2], n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
